## Scraping PDFs with Tabula

[Scrape PDFs with Tabula Python library: Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a computer display showing a PDF document titled "This-is-PL-Interactive-Combined (2).pdf". The PDF appears to be related to the Premier League, as indicated by the document\'s title and a prominent "This is Premier League" logo on the visible page. \n\n**Key elements:**\n\n* **PDF Document:** The main focus is the open PDF document. It displays a group of soccer players, seemingly celebrating a victory or achievement. The players are wearing blue and white uniforms.\n* **Players:** The players are a mix of ethnicities. The central figure is a dark-skinned man kneeling with arms raised.\n* **Premier League Logo:** The Premier League logo is prominently displayed at the bottom of the PDF page. It is a green and white crest.\n* **Browser:** The PDF is open in a web browser. The tabs include Google Drive and several PDF files.\n* **Interface Elements:** The screenshot shows the standard interface elements of a web browser: address bar, tabs, zoom controls, and page navigation buttons. \n* **Video Conference:** In the bottom right corner, there is a small window showing a person in a video conference, suggesting the screenshot was captured during an online meeting.\n* **System Tray:** The bottom part of the screen shows the system tray with time, date and some icons.\n\n**Color Palette:** Primarily blue, white, and green. The blues come from the playersâ€™ uniforms, green from the Premier League logo, and white from the background and interface elements.\n\n**Overall, the image captures a moment of celebration within the context of the Premier League, possibly a promotional material or a digital publication.**](https://youtu.be_yDoKlKyxClQ)

You'll learn how to scrape tables from PDFs using the `tabula` Python library, covering:

- **Import Libraries**: Use Beautiful Soup for URL parsing and Tabula for extracting tables from PDFs.
- **Specify Save Location**: Mount Google Drive to save scraped PDFs.
- **Identify PDF URLs**: Parse the given URL to identify and select all PDF links.
- **Download PDFs**: Loop through identified links, saving each PDF to the specified location.
- **Extract Tables**: Use Tabula to read tabular content from the downloaded PDFs.
- **Control Extraction Area**: Specify page and area coordinates to accurately extract tables, avoiding extraneous text.
- **Save Extracted Data**: Convert the extracted table data into structured formats like CSV for further analysis.

Here are links and references:

- [PDF Scraping - Notebook](https://colab.research.google.com/drive/102Fv2Ji0J4mvao3mCse52E7Th8bZiuyf)
- Learn about the [`tabula` package](https://tabula-py.readthedocs.io/en/latest/tabula.html)
- Learn about the [`pandas` package](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html). [Video](https://youtu.be/vmEHCJofslg)
