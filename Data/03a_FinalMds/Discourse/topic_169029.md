# Topic: Project 2 - TDS Solver - Discussion Thread

Please post any questions related to Project 2 - TDS Solver.
Deadline: Monday, March 31, 2025 6:29 PM
If someone Scrapes the GA Questions with Answers , Can you Please Send them , All of us have might have different GAs (a lil bit maybe), so more data more helpful. PLEASE HELP‚Ä¶



Project 2 - TDS Solver - Shared Data Pool Tools in Data Science


Project 2 - TDS Solver - Discussion Thread
Creating this Thread to share answers and questions from your respective assignments
Why? 
If we can Train the LLM with these Questions already, we can easily do well? 
Too many Questions for LLM 
True we can use embeddings, map that stored in-system dictionary and use relevant questions from in-system data to send as context with answer 
What We need from YOU ü´µüèΩ
Get to scraping your respective Gra‚Ä¶
  

@all
is it possible to have written solutions to all 5 assignments , instead of just live sessions. I have certain pending questions from the first 5 assignements.
Please quickly arrange a live TDS session to explain this project. There are a lot of doubts and questions in our minds.
Please also give access to the answers for GAs. So that we can evaluate our api with the correct answers.
@carlton sir, is there any bonus marks for code uniqueness and extra tasks like project 1
If we use ngrok to create a tunnel to our API or Llamafile server, for how long should our terminal remain running? Should it be active only at the time of submission, or must it be continuously available until evaluation is completed?
Is it like only the questions from the portal will be sent to the api?
If yes, is this project just about finding which question is asked and accordingly match the answer send the answer as response?
Here\'s a detailed description of the image:\n\n* **Overall**: The image displays a dark-themed informational message on a black background.\n* **Text**:\n * The primary heading reads "Deploy your application" in a prominent, white font.\n * Below this is a descriptive sentence: "Deploy your application to a public URL that can be accessed by anyone. You may use any platform, including Vercel." in a smaller, white font.\n* **Layout**: The text is presented in a two-line format, with the heading above the descriptive sentence. There is a thin white horizontal line separating the two lines of text.\n* **Purpose**: The message appears to be an instruction or guidance on how to make an application accessible to the public, with Vercel mentioned as one possible platform.image935√ó173 6.54 KB
Hello Sir,
I understand that we can deploy on vercel. Can it be deployed on Heroku as well? I believe both serve the same purpose. Wanted to know your thoughts on the same sir.
Thanks and Regards
Shalini
If you use ngrok, ensure that it is running continuously until you get your results
Any question from first 5 Ga‚Äôs can be there and you would need to analyze which question it is, you can use function calling or prompting as well. Function calling is better approach here.
Hi @24f2006531
You can deploy it anywhere, just test how it works on Heroku, if it works(send request to api endpoint to your application and it should respond with answer)
Kind regards
will the asked question be same which was asked in my GAs (i mean there were variations in problem statements for diff-diff students.)
@Jivraj  sir
Was the variation because of the datasets? Or even the problem statement?
Mostly problem statement like different cities etc
Then it comes down to what the project demands, as in what kind of questions the llm will be tested on (like you said). Hope the team can give us a test set like in the first project.
my question is some graded assignments have image files as a answer, so should our api return files as the answer or like can you clarify what type of answers we need to work on?
I guess yes, our APIs should return photos if required
@all
Keep posting your doubts here we will have answers to all of your doubts   In Thursday‚Äôs session.
Kind regards
Sir will it answer deployment question? like what will be output link or anything else?
@Jivraj
Could we have a tutorial-type session, similar to the one provided for Project 1, just before the deadline?
There are a total of 57 questions in all 5 GAs(18+10+9+10+10).
Due to so many different formats of accepting questions and solving them, my main question is:
Is the main essence of this project related to deciphering cryptic js code in order to scrape it?
Some other doubts are

Some questions ask for you to access some hidden divs in the html page and use that for solving (like week 1 q11)
Some questions ask you for AIPROXY TOKENs (like week 3 q9)
Some questions required manual correction to get correct answers (like week 4 q2)
Some questions require file output (like week 2 q2)

How do we account for this? @Jivraj @s.anand @carlton
I have few questions just going through the Project 2 problem statement.

Are we supposed to use OpenAI api‚Äôs or locally/private hosted one?
Many of the questions need files or images or audio files as input, same api is expected to handle those also?
Can we work in a team and submit the project together?
If we are to use locally hosted llm system, our systems are not strong enough to run most of the good ones locally
Is it possible to get a TA to collaborate in our project as an observer?

awaiting a response.
Thank you‚Ä¶
LLM is god, if you dont know how to use llm in your work, you are failed students. unnecessary project statement.
Is it okay if my api only answers the questions which were asked  in my GAs ? @carlton  sir @Saransh_Saini
please confirm this query sir @Jivraj  because most of them are very hard to make automated.
@s.anand @carlton @Jivraj @Saransh_Saini
Dear Sir,
I have few questions. It is written in the Tools in Data Science that we can expose the api using vercel (the example given also uses vercel). But I don‚Äôt think vercel can handle/allow many operations, some of them are listed below.

In GA 1 ques 13 and  GA 2 Ques 7, we have to create github repo, then creating github actions and then retrieve the raw github file url. We can accomplish this using Github CLI gh  which we have to install in the vercel instance using apt package manager.
But, Vercel does not provide sudo access which is required to install packages.
In GA 2 ques 10, we have to use local LLM (Llamafile), will vercel allow that?
Also after that, we have to give answer as the ngrok public url for which we have to first install ngrok package.
In GA 2 ques 8,  uploading an image to Dockerhub requires docker package installed.
In GA 2 ques 6, Deploy a Python API to Vercel in a Vercel instance?
Many ques require writing and running FastAPI server to serve data with CORS enabled. Can Vercel allow/do that?
And many more

Most tasks mentioned above like installing packages etc. requires sudo privilages or may face restrictions set by Vercel.
Vercel does not provide sudo access or any form of root access to its hosting environment which is required to perform the above tasks.
Many of these task can be done in our local systems (exposing to internet using cloudflare tunnels/ngrok), but we cannot run our systems 24*7 during evaluation.
I can see only one option left that is renting a VPS from server providers like digitalocean, gcp, aws etc, which will provide us sudo access and 100% uptime.
Also, some ques requires external toolings like

In GA1 ques 5, it is written to explicitly use Excel and this will only work in Office 365.
In GA1 ques 6, we have to use Devtools to show/find the hidden element in the question. Now, the question parameter in the POST request will be plain text, so how the element can hide there?
GA 2 ques 4 and GA 2 ques 5 uses Google Colab specific python libraries like google.colab which can‚Äôt be installed locally.

How to solve these above questions that require explicit usage of external tools.
Also, handling POST request for some questions are not clear like

In GA 2 ques 2, we have to compress the image and upload the image as answer. So, now how to response such answer in json object. Should we encode the resultant compressed image as base64 string or Image URL or  Data URI.
Some ques have images in them. For those images in GAs, I right clicked and used ‚ÄúSave as‚Äù to save the images and then done the required computations. So, now when this question will be sent as POST request, will the image be included as the base64 encoded string in the question parameter of the POST request itself or as an optional file attachment?

Another concern is regarding the OpenAI API TOKEN, unlike Project 1, Project 2 does not have an API_TOKEN parameter in the POST request. Hence, the API TOKEN provided from https://aiproxy.sanand.workers.dev will be also used during evaluation. Now, what will happen if our API TOKEN credits gets end during evaluation. The LLM will throw errors then.
Please advise what we should do. please clarify Sir.
Can you provide with an evaluation file like we had for Project 1.
Can we have groups for this please? @Jivraj @carlton @s.anand
If you are talking about the parameters of those questions, then it would be better if you make your API capable of working with different parameters.
Well if your API is capable of solving those questions in your GAs with the expected answer, then that‚Äôs sufficient validation.
If you are indicating towards working collaboratively then,
Yes, we encourage you to collaborate with others and collectively work towards solving this project. Even if you are going for the relatively easiest approach of Function Calling, it would require you to code about 50 functions to solve all your tasks. Which is why it is sensible to work collectively.
Hello Sir,
I have a few questions. Would like your thoughts and suggestions over the same.


Currently answers that we have entered for GA‚Äôs 1 to 4 are not available and only for GA5 its available. It would be helpful for the project (when running the Curl command for each of the question) if the assignments can display the answers we‚Äôve entered as well for verification purposes.


The first question of GA1 q1 needs for us to run vs code but when executing it through vercel its not possible because vercel is a serverless environment. In this case, is it okay to manually enter the answer in the code, so when the question is triggered it takes the manual output from the code.


Can you provide some clarity as to how the question is supposed to be and structured ? Or should the code be able to handle multiple variants of the question? To address this concern, i tried to implement sentence_transformers using a lightweight model but the vercel application build failed saying that the data is too long and that Vercel serverless function deployment size exceeds the limit of 250 MB. Should i consider deploying elsewhere or change the approach?


How do we handle questions pertaining to Devtools - creating input box etc.


Thanks and Regards
Shalini
What does it mean to solve the question?
Everyone is asking that?
Do you yourself know what to do and to go about it?
Or just pull out something from your hAtSS at the last moment?
‚Äúand responds with the answer to enter in the assignment.‚Äù
From my understanding only those questions that are solved with a program and give an answer are to be considered‚Ä¶ For example it states in the project that 
" The response must be a JSON object with a single text (string) field: answer that can be directly entered in the assignment. For example:"
If you all still have not responded, then I‚Äôm honestly not sure if this is what y‚Äôall meant.
Last project was not clear to some extent, This time its even more vague.
I understand that y‚Äôall want to give different projects to help High Order Thinking skills, but if not executed properly, no one actually learns anything and we(I) just end by debugging the project statement code and question with no relevance to the project. If we wanted to do that, I could just go random GitHub repos and solve and create pull requests for a specific bug. Also we end up losing interest thinking most if the course instructors don‚Äôt what they are doing. I understand Anand Sir is extremely busy(like really busy lol), but what are the course instructors doing?
@Saransh_Saini @carlton
Sir is it possible to extend the deadline of this project 2 to Arpil. Because of Quiz2 and Vivas of project should be completed in march only as I am degree potential student. Extending the deadline wont be disadvantage also, project2 will be like ET preparation
Please consider this request sir
Thanks
I just want to know if you prefer using an existing language model application where we utilize an LLM (Large Language Model), train it, and format the output. For instance, I used the Gemini API key, integrated it with Python, and then formatted the results with the help of Copilot to achieve the desired outputs.
Alternatively, do you want us to create a new LLM model and train it with questions from graded assignments? I‚Äôm curious about your preference.
Additionally, would you like the LLM to provide specific answers regarding computer specifications, or should it give general specifications? For example, in Graded Assignment 1, there is a question about the editor: Visual Studio Code.
Your editor is the most important tool in your arsenal; that‚Äôs where you‚Äôll spend most of your time, so make sure you‚Äôre comfortable with it.
Visual Studio Code is, by far, the most popular code editor today. According to the 2024 Stack Overflow Survey, almost 75% of developers use it. We recommend you learn it well. Even if you use another editor, you‚Äôll likely work with others who use VS Code, so having some exposure is beneficial.
To get started, you can watch these introductory videos (totaling 35 minutes) from the Visual Studio Docs:

Getting Started: Set up and learn the basics of Visual Studio Code (7 min)
Code Editing: Learn how to edit and run code in VS Code (3 min)
Productivity Tips: Become a VS Code power user with these productivity tips (4 min)
Personalize: Personalize VS Code to make it yours with themes (2 min)
Extensions: Add features, themes, and more to VS Code with extensions (4 min)
Debugging: Get started with debugging in VS Code (6 min)
Version Control: Learn how to use Git version control in VS Code (3 min)
Customize: Learn how to customize your settings and keyboard shortcuts in VS Code (6 min)

AI Editors: Copilot, Cursor
Note: AI editors like Cursor, Cody, and GitHub Copilot use LLMs to help you write code faster. These tools are built on top of VS Code and have become standard in every developer‚Äôs toolkit. Please make sure to use them.
To install and run Visual Studio Code, open your Terminal (or Command Prompt) and type code -s, then press Enter. Copy and paste the entire output below.
What is the output of code -s? The output of code -s cannot be universally answered because it depends on the user‚Äôs system and the specific version of VS Code installed. The question requests the output of a command that is unique to each user.
As for the part about getting answers from the LLM model, I believe that may require using an AI agent. I am currently searching for a solution for this, and I would like to know your thoughts on it.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a screenshot of a web application titled "IIT Madras Assignment Helper." It appears to be a tool designed to assist students with data science assignments. \n\n**Key Elements & Details:**\n\n* **Header:** A prominent header reads "IIT Madras Assignment Helper" with a brief description stating the tool helps find answers to IIT Madras Data Science graded assignments.\n* **Question Input:** There is a designated area labeled "Ask a Question" where a user can input a query.\n* **Pre-filled Query:** Inside the input area, a specific SQL query request is already present: "Write a DuckDB SQL query to find all posts IDs after 2025-01-16T06:36.367Z with at least 1 comment with 5 useful stars, sorted. The result should be a single column called post_id, and the relevant posts IDs should be sorted in ascending order. Check the console for the result of your query."\n* **File Upload:** Beneath the query input, there is an option to upload an assignment file (optional) with a "Choose File" button and "No file chosen" displayed.\n* **"Get Answer" Button:** A large, green button labeled "Get Answer" is present, presumably to submit the query and receive a solution.\n* **"Answer" Section:** A section titled "Answer:" is displayed at the bottom of the image. It contains a complex SQL query, presumably the tool‚Äôs response to the query entered above.\n* **Color Scheme:** The website has a clean, minimalist design with a predominantly white background, green accents (like the "Get Answer" button), and text in shades of gray and black.\n\n\n\n**In essence, the image showcases a web-based tool where a user can input a data science assignment question (specifically a SQL query) and receive an automated answer.**image1214√ó831 34.8 KB
can we make this type of solution for above project

yantravid-git-main-vicky-kumars-projects-5400c012.vercel.app


IIT Madras Assignment Helper





and this is also working with simple question
Here\'s a detailed description of the image:\n\n**Overall:** The image shows a black screen with white text, indicating a command-line interface (CLI) output. \n\n**Details:**\n\n* **Command:** The first line displays a command utilizing `curl` with the `-X POST` method. The URL points to a Vercel app endpoint (`https://yantraid-glt-main-vicky-kumars-projects-5400002.vercel.app/api/`). It includes a data parameter `-d "question=What is 2+2?"`.\n* **Response:** The subsequent line displays a JSON response: `{"answer":"4"}`. This indicates the server processed the question "What is 2+2?" and returned the answer "4".\n* **Prompt:** The last line repeats a portion of the initial prompt `0: (yantraid@db)`.\n\n**In essence, the image demonstrates a simple API request (using `curl`) to a Vercel app that performs basic arithmetic and returns the result in JSON format.**
model='gemma3:27b' created_at='2025-06-13T16:58:43.312508063Z' done=True done_reason='stop' total_duration=56247942050 load_duration=18016995 prompt_eval_count=323 prompt_eval_duration=18556828459 eval_count=378 eval_duration=37672279782 message=Message(role='assistant', content="Here's a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a command-line interface (CLI), likely a terminal or console window. It contains a series of commands and their outputs, suggesting a data processing or scripting task.\n\n**Detailed Breakdown:**\n\n1. **Commands:** A complex sequence of commands is visible. These commands appear to involve:\n * Using `curl` to make a POST request to a specific URL related to a Git repository (`yamtavid/git-main-virky-kumars-projects-5400012.vercel.app/api`).\n * Downloading and extracting a zip file named `qmove.zip`.\n * Using `mv` (move) command to relocate files within a folder.\n * Renaming files by replacing digits.\n * Running `grep` with arguments to identify the moved files.\n * Sorting the results using `sort`\n * Generating a SHA256 checksum of the contents of a folder using `sha256sum`.\n\n2. **Output:** The CLI displays the output from these commands, including:\n * A JSON response from the URL.\n * Text related to the file operation, which implies a sequence of files being renamed.\n * A text response with the checksum of the content in `qmove.zip`.\n\n3. **Directory Path:** The path `D:\\yamtavid\\yamtavid\\` is visible, indicating the current working directory. `yamtavid\\test_data\\qmove.zip` is the input file.\n\n**In essence, the image depicts a data processing workflow involving downloading, extracting, renaming, and hashing files within a specified directory.**", thinking=None, images=None, tool_calls=None)image1260√ó149 8.95 KB
Sir, for GA-5 question number 3 the file is too large to send via request to vercel
possible solution is uploading on google drive or smth like that but how will u guys send such long files plus the project only mention sending files not url ‚Ä¶Kindly clarify regarding this.
model='gemma3:27b' created_at='2025-06-13T06:44:19.745477399Z' done=True done_reason='stop' total_duration=35858858172 load_duration=18599696 prompt_eval_count=323 prompt_eval_duration=18757582062 eval_count=175 eval_duration=17081875643 message=Message(role='assistant', content="Here's a point-by-point description of the image:\n\n* **Content:** The image displays a block of text on a dark green background. \n* **Text Description:** The text describes an API endpoint that an application exposes.\n* **API Endpoint:** The endpoint is defined as `https://your-app.vercel.app/api/`.\n* **Request Method:** The endpoint is expected to accept a POST request. An example of a request is provided: `POST https://your-app.vercel.app/api/`.\n* **Data Format:** The request can include a question and optional file attachments in the `multipart/form-data` format.\n* **Background:** The background color is dark green.\n* **Font Color:** The text is white/light yellow.", thinking=None, images=None, tool_calls=None)image1010√ó145 13.6 KB
Here, the questions entered after the endpoint will be exactly same as the GAs or be similar as the GAs ??
@Saransh_Saini  please look into my matter and please clear my doubt
@carlton @Jivraj @Saransh_Saini
I received this mail from TDS Google Group Announcement this morning at 10:30 am. The Project 2 submission date mentioned in the mail i.e. 15 March 2025 contradicts with submission date mentioned in Tools in Data Science and
Project 2 - TDS Solver - Discussion Thread i.e. 31 March 2025. Please clarify.
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of an email regarding eligibility for the final exam in a "Tools in Data Science" course at IITM (Indian Institute of Technology Madras). It outlines the criteria for attending the final exam and achieving a passing course grade, detailing the assessment components and their respective deadlines.\n\n**Key Elements & Details:**\n\n* **Email Header:** The email is from "donot.reply@study.iitm.ac.in" with the subject "Tools in Data Science ‚Äì Eligibility to write the final exam" and a List-Id.\n* **Eligibility Criteria:**\n * **To attend the end-term exam:** The average of the best 2 out of the first 5 weekly assessments must be ‚â• 40/100.\n * **To get the course grade:** Attending end-term exam is mandatory.\n* **Assessment Table:** A table lists the assessment components, their open dates, submission dates, and peer review dates:\n * **ROE1:** Remote Online Exam 1 (45 mins, objective) - Open and due on March 2, 2025.\n * **P1:** Take home project 1 (open internet) - Open on January 17, 2025, due February 15, 2025, peer review due February 25, 2025.\n * **P2:** Take home project 2 (open internet) - Open on February 21, 2025, due March 15, 2025, peer review due March 17, 2025.\n* **Grading Formula:** The email provides the grading formula:\n * Final course score T = 0.15GAA + 0.2 ROE1 + 0.2 P1 + 0.2P2 + 0.3F\n * Final course score T = 0.15GAA + 0.2 ROE1 + 0.2 P1 + 0.2P2 + 0.25F\n* **Notes:** It refers readers to grading documents for further details.\n* **Sender:** The email is from the IITM BS Team.\n* **Subscription Note:** There\'s a note at the bottom indicating the recipient received the email because they are subscribed to a Google Groups "Announcement" list for the course.\n\n**Overall, the image provides essential information regarding the assessment and grading scheme for the "Tools in Data Science" course.**image788√ó973 265 KB
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a webpage or document outlining the details of a project assignment. It has a dark background with white text, giving it a clean and professional look.\n\n**Key Elements and Details:**\n\n* **Title:** "Project 2 - TDS Solver" is prominently displayed at the top.\n* **Due Date & Results:** The project is due on March 31, 2025 (End of Day IST), with results announced by April 15, 2025.\n* **Support Link:** A link to a "Discourse thread" is provided for questions.\n* **Background Section:** A section titled "Background" provides context:\n * The user is described as a student enrolled in the "To learn Data Science" course at IIT Madras\' Online Degree in Data Science.\n * The goal is to build an LLM-based application to automatically answer graded assignment questions.\n\n**In essence:** The image is about a project assignment for a Data Science course, detailing the timeline, support resources, and the project‚Äôs objective (building an automated assignment solver).image1069√ó531 41.8 KB
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of an online discussion forum post, likely from a learning management system or similar platform. It is a pinned announcement regarding a project.\n\n**Key Elements:**\n\n* **Title:** "Project 2 - TDS Solver - Discussion Thread" is prominently displayed.\n* **Categories/Tags:** The post is categorized under "Courses" and tagged with "Tools in Data Science," "announcement," "term1-2025," and "tds-project-2."\n* **Author & Timestamp:** The post is authored by "s.anand Course\\_faculty" and was published 9 days ago.\n* **Content:** The main message requests users to post any questions related to "Project 2 - TDS Solver." A deadline of "Monday, March 31, 2025 11:59 PM" is specified.\n* **Engagement Metrics:** Below the message, there are stats indicating:\n * 530 views\n * 32 likes\n * 3 links\n * 24 users have engaged\n* **User Avatars:** A row of user avatars is visible, likely representing those who have interacted with the post.\n* **Read Time:** Indicates an estimated read time of ‚Äú6 min‚Äù.\n* **Pinned Indicator:** There‚Äôs a label indicating that the post was "Pinned on Mar 3".\n\n**Color Scheme:** The image uses a dark mode interface with light text and highlights.\n\n**Overall:** The image shows a typical announcement post in an online course, meant to facilitate student questions and discussions around a project.image1115√ó601 66.5 KB
The deadline is 31st March for Project 2. Please ignore the announcement email. We apologise for the confusion.
Kind regards
Is there any proxy_Ai token as provided earlier for the project 1..
Hi Ayush,
Just go the AI Proxy token issue page and re-issue it or use the same one. The limits get reset.
Kind regards
My Approach , is to

scrape and parse all the current question
create embeddings ,  of the questions.
create a test endpoint , just to check if i am able to correctly identify the questions
segregate numerical , string and json responses and see if these can be answered part of phase 1
Phase 2 , experiment with url based answers. need to see if an MCP server can come in handy
to deploy a server and return an url

Since the token is limited, I have thought to use the run llms locally,  to check for the accuracy of solving the question.

I want to know which LLM will be more closer to the one used for evaluating our project.
Does the model used for evaluation is capable for handling raw files, or we need to pass it in the text format..(As as I am to recall, the models are capable enough to handle the files..)
Thanks!

Does anyone willing to work with me..?
contact: whatsapp(8697454203)
Should we answer the questions and return the response to enter in the answer box(as stated in the question) or should we just provide instructions on how to go about solving the question? Some of the questions include pictures and we cannot use LLM for pictures.
Did you just Post your number on a public forum?
They(instructors) only don‚Äôt what to do it looks like, Anand Sir will tell them and they will tell you (with 25-50 percent lossy communication), just wait and keeping tagging Anand Sir. He will explain clearly, Ask everyone to push for a live session with Anand Sir , that 40 mins he explains will be worth its weight in gold, Hope he does that. Flattery gets me everywhere (not really, I really think Anand Sir is OP. Check out his YT )! @s.anand
A good video, with working code for OpenAI agents api .. https://www.youtube.com/watch?v=0Z7u6DTDZ8o
should we make the functions on the basis of the GAs or should we make it general so it will be able to perform the task but the data provided will be different.
@s.anand @carlton
The key learning objective for Project 2 is for you to be absolutely comfortable interacting with APIs and understanding how they work to perform tasks.
So there is very little need for the use of LLMs or agents.

Identify the the question being asked (how you do this is upto you, you can be as simplistic as using regex to look for some key words, or you can be clever and create embeddings out of the original question and calculate the similarity from the request)
Create a function that solves the question with the required parameters and inputs. Remember this does not have to be fancy. Just compute the answer. You do not need to do the task as the GA required. You ONLY want the answer. No tools required. Just a computed answer.
Give the answer back as specified.

Kind regards



 carlton:

You do not need to do the task as the GA required.


Does this mean this type of question won‚Äôt be paramaterized?
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a code editor or terminal window displaying code related to Stable Diffusion. It appears to be a prompt and its corresponding output.\n\n**Key Elements & Details:**\n\n* **Text-Based Content:** The entire image is composed of text, presumably code or command-line output.\n* **Stable Diffusion Prompt:** The top lines contain a prompt for Stable Diffusion, a text-to-image AI model. The prompt mentions "realistic vision," "current prompt," and specifics related to image details like "8k," "ultra detailed," and elements like "mountains," "volcano," "sunrise," "birds," etc.\n* **Code-Like Syntax:** The text includes bracketed parameters (e.g., `[mountains]`, `[birds]`) which suggest a structured format for defining image components or settings.\n* **Output Request:** Below the prompt is a line asking, "What is the output of `code-c-s`?". \n* **Color Coding:** Parts of the prompt and the output request are highlighted in pink, indicating potentially important keywords, parameters or specific instructions.\n* **Background:** The background is a dark, likely black, color which is common for code editors and terminals.\n\n**In summary:** The image depicts a request for generating an image using Stable Diffusion with a specified complex prompt and a follow-up request to view the generated code/output.
Like instead of code -s there won‚Äôt be any other command, otherwise it would require installation of VS Code inside a container to find the answer or this type of questions won‚Äôt be part of evaluation at all?
The same confusion is for these type of questions as well:
Here\'s a detailed description of the image:\n\n**Overall:**\n\nThe image displays a screenshot of a digital interface, likely a learning platform or quiz application. It presents two separate formula-based questions designed to test the user\'s knowledge of spreadsheet functions (specifically Google Sheets and Excel).\n\n**Top Question (Google Sheets):**\n\n* **Heading:** "Let‚Äôs make sure you can write formulas in Google Sheets. Type this formula into Google Sheets. (It won\'t work in Excel)"\n* **Formula:** `=SUM(ARRAY_CONSTRAINT(SEQUENCE(100, 15, 6), 1, 10))`\n* **Prompt:** "What is the result?"\n* **Input field:** A blank text field is provided for the user to enter their answer.\n* **Button:** A button labeled "Check" is located below the input field.\n\n**Bottom Question (Excel):**\n\n* **Heading:** "Use Excel (0.25 marks)" with a small icon to the left. "Let\'s make sure you can write formulas in Excel. Type this formula into Excel."\n* **Note:** ‚ÄúNote: This will ONLY work in Office 365.‚Äù\n* **Formula:** `=SUM(TAKE(SORTBY( {3,14,6,10,3,9,6,3,12,15,4,11,4,14}, {10,9,3,12,2,11,8,16,14,7,5,4,6,1,3,12}), 1, 9))`\n* **Prompt:** "What is the result?"\n* **Input field:** A blank text field is provided for the user to enter their answer.\n* **Note:** "Note: If you get #NAME? you have the wrong version of Excel. Find a friend for whom this works."\n* **Button:** A button labeled "Check" is located below the input field.\n\n**Visual Elements:**\n\n* The interface has a dark background, typical of many web applications.\n* The text is primarily white, providing strong contrast and readability.\n* The questions are clearly separated and labeled.\n* The buttons are a bright blue color.\n\n**In essence, the image is a screenshot of a practical exercise where the user is asked to input and evaluate spreadsheet formulas.**Screenshot 2025-03-18 at 5.43.34 PM1329√ó750 44.4 KB
A bit more clarity would be helpful. Thanks in advance.
@carlton @s.anand



 21f2000709:

Like instead of code -s there won‚Äôt be any other command, otherwise it would require installation of VS Code inside a container to find the answer or this type of questions won‚Äôt be part of evaluation at all?


there will not be any other command. This question can be solved with a hardcoded answer
Excel and Google sheet questions can be solved by just using python . No excel or google sheets required.
The question WILL be parameterised however. So the numbers might be different. You should just understand what the question is asking and solve it programatically to get the answer.
Guys, I have designed a new version of this project. Please ask questions related to the graded assignment and let me know if you observe any errors.
AI Question Answering
Means no github, image related, vs-code, vercel, etc. will be there
And the answer will be in string format ??
I am not sure how you came to that conclusion!
For example vercel question still requires a vercel endpoint that will respond.
What I said is some questions might not need you to use those specific tools. Your answers should still be legitimate answers that one can paste into the text box of a GA and still get it correct.
The only question that will not be asked is the LLM say yes question.
A github account would still need you to commit a file to it and provide the url that is reachable.
etc.
@carlton  1 small request.. can we have 2-3 more examples in the project2 description.. so that it gets a bit more clear
Prof. Anand Live Session Alert!

 Date &amp; Time: Wednesday, March 19, 2025 ¬∑ 9:00 ‚Äì 10:00 PM (IST)
 Speaker: Professor Anand
 Topic: Project 2 Q&amp;A + General Course Queries
 Google Meet Link: Join Here (https://meet.google.com/jdr-pquo-vza)
Or from the TDS Google Calendar

@all
Just to be clear the special Session is tonight Wed, 19th March at 9pm.
my small piece of code to evaluate the GA number parsing, it may be useful for some

import httpx, os
import json
import logging
import random

async def run(task: str):
    async with httpx.AsyncClient(timeout=30) as client:
        logging.warning(f"üü° Running task: {task.strip()}")
        data = {
                "question": task
            }
        files = {}
        response = await client.post("http://localhost:8000/api/parse", data=data, files=files)
        try:
            response_text = response.json()
        except json.JSONDecodeError:
            response_text = response.text
        if response.status_code &lt; 400:
            logging.info(f"üü¢ HTTP {response.status_code} {response_text}")
        else:
            logging.error(f"üî¥ HTTP {response.status_code} {response_text}")
        return response.status_code, response_text
    
async def evaluate(use_case: str):
    # file exists under test_data directory
    file_path = f"test_data/{use_case}.txt"
    if os.path.exists(file_path):
        with open(file_path, "r") as file:
            task = file.read()
        status_code, response_text = await run(task)
        if status_code != 200:
            return False
        
        # check the returned json matches the use case
        if "GA_No" in response_text and response_text["GA_No"] == use_case:
            return True
        else:
            return False
    else:
        #print("File does not exist.")
        return False
    

async def main():
    use_cases = [
        "GA1.1", "GA1.2", "GA1.3", "GA1.4", "GA1.5", "GA1.6", "GA1.7", "GA1.8", "GA1.9", "GA1.10", "GA1.11", "GA1.12", "GA1.13", "GA1.14", "GA1.15", "GA1.16", "GA1.17", "GA1.18",
        "GA2.1", "GA2.2", "GA2.3", "GA2.4", "GA2.5", "GA2.6", "GA2.7", "GA2.8", "GA2.9", "GA2.10",
        "GA3.1", "GA3.2", "GA3.3", "GA3.4", "GA3.5", "GA3.6", "GA3.7", "GA3.8", "GA3.9",
        "GA4.1", "GA4.2", "GA4.3", "GA4.4", "GA4.5", "GA4.6", "GA4.7", "GA4.8", "GA4.9", "GA4.10",
        "GA5.1", "GA5.2", "GA5.3", "GA5.4", "GA5.5", "GA5.6", "GA5.7", "GA5.8", "GA5.9", "GA5.10"
    ]
    use_cases = random.sample(use_cases, 5)
    a_score, a_total = 0, 0
    for use_case in use_cases:
        a_total += 1
        try:
            success = await evaluate(use_case)
        except Exception as e:
            logging.error(f"üî¥ {use_case} failed: {e}")
            success = False
        if success:
            logging.info(f"‚úÖ {use_case} PASSED")
        else:
            logging.error(f"‚ùå {use_case} FAILED")
        a_score += 1 if success else 0
        
    logging.info(f"üéØ Parsed: {a_score} / {a_total}")
    


if __name__ == "__main__":
    import asyncio
    import argparse

    parser = argparse.ArgumentParser(description="Evaluate GA No with configurable logging")
    levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
    parser.add_argument("--log-level", default="INFO", choices=levels, help="Set logging level")
    args = parser.parse_args()
    logging.basicConfig(level=args.log_level, format="%(message)s\n")
    
    asyncio.run(main())


Hi TAs,
I attended the meet which happened today. But I don‚Äôt clearly get one thing.
Most of the questions have a question text and a file: csv,zip,json,etc
My doubt is, will the request to the end point be :
curl -X POST "https://your-app.vercel.app/api/" \
  -H "Content-Type: multipart/form-data" \
  -F "question=question text" \
  -F "file=https://stats.espncricinfo.com/stats/engine/stats/index.html?class=2;template=results;type=batting"


my doubt :
Is this the only format or can there be other too ?

Hi @23f2000573
Yes this is correct format for the question, It will have 2 fields question and file.
You can send a file from local machine like this  -F "file=@abcd.zip" so here abcd.zip must be in current working directory.
Kind regards
Fine sir, this is clear. I have a few doubts in the file formats. When free, kindly address these to. I will try to cover most common doubts, so that you wouldn‚Äôt need to answer similar doubts again. Sorry if some of the doubts are basic / written incorrectly.
FILES
The data file sent to the api will always be in the requester‚Äôs local machine. When the api server receives the request, the file will be in binary format?
Or
Sometimes the api server receives the file in byte and some times, it will recieve a link like this :  https://exam.sanand.workers.dev/shapes.png
This link was take from GA2 Question 2
HTML AND TABLE
Some questions have html and tables. In this case will these two be in a file encoded in binary, or will it be a string.
Example for string. Consider the table




Col 1
Col 2




Row 1, Col1
Row 1 Col 2


Row 2, Col 1
Row 2 Col 2



Will this be something like this
"|Col 1| Col 2|\n|-|-|\n|Row 1, Col1 | Row 1 Col 2|\n|Row 2, Col 1|Row 2 Col 2|"

or something like
"&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Col 1&lt;/th&gt;\n&lt;th&gt;Col 2&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Row 1, Col1&lt;/td&gt;\n&lt;td&gt;Row 1 Col 2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Row 2, Col 1&lt;/td&gt;\n&lt;td&gt;Row 2 Col 2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;
"

HIDDEN BLOCK AND ANSWER : 2 TASKS
In one question, there were two tasks.

Find the answer to the question
Enable the disabled text block

In this question, what will the answer type be?
Should it just be the answer or should it be the html string which will have the disabled block enabled and also the answer string sitting inside the block
MORE THAN ONE FILE
Some questions have more than one file. For example, the last question of GA5, it has a png file in this link https://exam.sanand.workers.dev/jigsaw.webp and a table.
In this case, how will the curl request be? Is it some thing like this
curl -X POST "https://your-app.vercel.app/api/" \
  -H "Content-Type: multipart/form-data" \
  -F "question=question text" \
  -F "file= Image file" \
  -F "file= table file/ string" 

CORS HEADERS
Will the CORS headers asked in the question be the same or can it be different?
Hi,
In GA 2, q5, this is the code i got in the question.
import numpy as np
from PIL import Image
from google.colab import files
import colorsys

# There is a mistake in the line below. Fix it
image = Image.open(list(files.upload().keys)[0])

rgb = np.array(image) / 255.0
lightness = np.apply_along_axis(lambda x: colorsys.rgb_to_hls(*x)[1], 2, rgb)
light_pixels = np.sum(lightness &gt; 0.554)
print(f'Number of pixels with lightness &gt; 0.554: {light_pixels}')

Is this the code for others as well?
Thanks
So I was thinking to create the project 2 together and I was looking for collaboration, and for that we would require the following:
 ‚Üí the set of question-answers pairs at first
 ‚Üí All the questions of 2 distinct students to see which parameters changes in each questions
 ‚Üí Make the solution functional and parameterised based on previous step.
Till now I have created the following:
 ‚Üí Identification of the question, using embeddings
 ‚Üí extraction of parameters using llm for that particular question
 ‚Üí Implementation of 3 questions using this approach
If we come together, we all can reduce the workload and complete it on time.
*Those who resonate with my approach or have any different approach feel free to leave a DM. I might not respond immediately as I might not be online all the time 



 23f2000573:

The data file sent to the api will always be in the requester‚Äôs local machine. When the api server receives the request, the file will be in binary format?
Or
Sometimes the api server receives the file in byte and some times, it will recieve a link like this : https://exam.sanand.workers.dev/shapes.png


file format will be exactly same as corresponding GA.



 23f2000573:

"&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Col 1&lt;/th&gt;\n&lt;th&gt;Col 2&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Row 1, Col1&lt;/td&gt;\n&lt;td&gt;Row 1 Col 2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Row 2, Col 1&lt;/td&gt;\n&lt;td&gt;Row 2 Col 2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;



This is correct html table format.



 23f2000573:

Should it just be the answer or should it be the html string which will have the disabled block enabled and also the answer string sitting inside the block


It will be just answer.



 23f2000573:

Some questions have more than one file. For example, the last question of GA5, it has a png file in this link https://exam.sanand.workers.dev/jigsaw.webp and a table.
In this case, how will the curl request be? Is it some thing like this
curl -X POST "https://your-app.vercel.app/api/" \
  -H "Content-Type: multipart/form-data" \
  -F "question=question text" \
  -F "file= Image file" \
  -F "file= table file/ string" 



In last question of GA5 there is only one file(image), table is not coming through file, it will be kept same for project2.



 23f2000573:

Will the CORS headers asked in the question be the same or can it be different?


I didn‚Äôt get this question, could you point to exact question?
Hi @22f3001307
yes it‚Äôs same code.
Sir, a few things are not yet clear .



 Jivraj:

file format will be exactly same as corresponding GA.


Some questions have clickable html buttons. When we click that, the zipfile or json file, or csv gets downloaded
Some questions have image attached to the text. For this, we have to use right click ‚Üí download the image. Here, the image is take from some url. For example. in GA2, q2, the image displayed is taken from https://exam.sanand.workers.dev/shapes.png.
My doubt is, what will be the value of file attribute in curl command
Will it be

‚Äúfile=binary of zipfile/csv/json‚Äù for the first type and
‚Äúfile=https://exam.sanand.workers.dev/shapes.png‚Äù for the second type




 Jivraj:

This is correct html table format.


Will this table be in the ‚Äúquestion‚Äù attribute of curl or ‚Äúfile‚Äù attribute



 Jivraj:

In last question of GA5 there is only one file(image), table is not coming through file, it will be kept same for project2.


so, can I assume that the table will be given as a html element in the ‚Äúquestion‚Äù attribute and the image in the ‚Äúfile‚Äù attribute?
Sir
@Jivraj was yesterday (March 19) 's google meet recorded and
available  for replay..
@22f3002723





thanks a lot @23f1001231
Hi @23f2000573



 23f2000573:

Will it be

‚Äúfile=binary of zipfile/csv/json‚Äù for the first type and
‚Äúfile=https://exam.sanand.workers.dev/shapes.png‚Äù for the second type



Files will be exactly same as GA assignment, if there is url then it will be a url and if it get‚Äôs downloaded by clicking then it will come from requester‚Äôs machine.



 23f2000573:

so, can I assume that the table will be given as a html element in the ‚Äúquestion‚Äù attribute and the image in the ‚Äúfile‚Äù attribute?


For questions that have table they will either come as html code or as markdown. Keep a if else condition for identifying which case it is, if it‚Äôs a html then beautiful soup should be able to find table tag, if it‚Äôs markdown table then it can be identified with | characters.
Kind regards
For GA 1, question 2
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image shows a screenshot of a command-line interface (CLI) or terminal window. It appears to be part of an interactive coding or testing environment.\n\n**Text Content (Top to Bottom):**\n\n1. **Instruction 1:** "Running uv run --with httpie -- [URL] installs the Python package httpie and sends a HTTPS request to the URL."\n2. **Instruction 2:** "Send a HTTPS request to httpbin.org/get with the URL encoded parameter email set to 21f2000709@ds.study.iitm.ac.in"\n3. **Prompt:** "What is the JSON output of the command? (Paste only the JSON body, not the headers)"\n4. **JSON Data:** A JSON object is displayed, containing:\n * `"args"`: containing an object with a key `"email"` and a value `"21f2000709@ds.study.iitm.ac.in"`.\n * `"headers"`: containing an object with `"Accept": "*/*"` and `"Accept-Encoding": "gzip, deflate"`.\n\n**Visual Elements:**\n\n* **Background:** Dark background, typical of CLI environments.\n* **Button:** A blue button labeled "Check" is located at the bottom-left corner. \n\n**Context:** The screenshot likely demonstrates how to send a basic HTTPS request with parameters using the `httpie` Python package and how to interpret the resulting JSON response.Screenshot 2025-03-21 at 4.17.09 PM960√ó336 28.9 KB
The portal accept answers in strict json with double quotes. Now in the project we need to return the answer in string value which again has double quotes, so the best answer I could get is using \" inside the answer like this.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a screenshot of a terminal or command-line interface. The background is black, and text is displayed in a bright orange/amber color. \n\n**Details:**\n* **Text Content:** The screen is filled with numerous lines of text, which appears to be output from a command or program execution. The text is densely packed and primarily consists of alphanumeric characters, along with various symbols.\n* **Specific Text Snippets:** Notable snippets include:\n * "home:/home/user/data/tmp/test_image_tools/test_image_tools/test.py" indicating a file path likely related to a Python script.\n * "Using CPU Only" implying that the computation is being performed on the central processing unit (CPU).\n * "items: 100000, time: 0.0308s, time per item: 2.09e-07s" showing performance metrics with timings.\n* **Interface Elements:** There\'s a prompt-like indicator at the beginning of some lines ("home:"), suggesting an interactive shell environment.\n* **Purpose:** It seems like a program is being executed and the output is displaying information about the process, likely related to image processing, as implied by the file paths and the term "image" in the file names.\n\nIn summary, the image showcases the output of a script or application being run in a terminal, offering performance metrics and information about its execution.
But still the GA portal marks it as invalid json. What to do in this case?
@carlton @Jivraj
Hi @21f2000709
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a series of code interactions within what appears to be a Python interpreter or a similar coding environment. The interactions involve a string variable named "job" and the `json` library.\n\n**Specific Points:**\n\n* **Code Interactions:** Each line displays an "In" prompt (user input) and an "Out" prompt (the interpreter\'s output).\n* **Variable Initialization:**\n * `job` is initially assigned a JSON-formatted string: `"{\'name\':\'jivraj\'}"`\n* **`json.loads()`:** The `json.loads()` function is used to parse the string and convert it into a Python dictionary.\n* **Accessing Dictionary Values:** `json.loads(job)[\'name\']` demonstrates accessing the value associated with the key "name" within the parsed dictionary.\n* **Type Determination:** `type(job)` shows that the variable `job` is of type string.\n\n**Color Scheme:** The code elements (prompts and outputs) are displayed in green, indicating it\'s likely a terminal or console output. The background is black.image654√ó681 13.1 KB
This works, just send a string which can be loaded as json object.
The correct answer has to be with the escape sequence otherwise you cannot send a valid response back.
We never feed your response to the GA by copy pasting.
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a screenshot of a code execution environment, likely a Jupyter Notebook or similar interactive coding platform. It showcases a series of Python code snippets with their outputs, suggesting a demonstration of JSON data processing and string manipulation.\n\n**Detailed Breakdown:**\n\n1. **Initial JSON Data:**\n * The code begins by defining a Python dictionary named `response` containing a JSON-like structure. \n * The `response` dictionary has a key "answer" whose value is another dictionary containing a key "args" with the string "How can TDS ever hope to solve this problem?".\n\n2. **JSON Serialization:**\n * The code then imports the `json` module.\n * It uses `json.dumps()` to convert the `response` dictionary into a JSON-formatted string with an indent of 2 spaces for readability.\n * The `print()` statement displays the JSON string in the output.\n\n3. **JSON Deserialization:**\n * The code utilizes `json.loads()` to parse the JSON string (`send_response`) back into a Python dictionary, extracting the "answer" value.\n * The resulting dictionary is stored in the `tds_evaluator` variable.\n * The output shows the extracted dictionary: `{‚Äúargs‚Äù: ‚ÄúHow can TDS ever hope to solve this problem?‚Äù}`.\n\n4. **String Output:**\n * Finally, the code executes a `print()` statement that outputs a surprised, excited exclamation: ‚ÄúOH MY GOODNESS! I CAN‚ÄôT BELIEVE IT! THIS IS AMAZING!‚Äù.\n\n**In summary,** the image demonstrates a sequence of JSON data manipulation, parsing, and a final, enthusiastic output, likely as a reaction to the data processing result.Screenshot 2025-03-21 at 5.28.12 pm.png1744√ó1084 147 KB
So the questions expecting JSON will be jsonified separately before passing to the evaluator because in the current implementation in the text field idk why it is failing to load the json with \" however I could load the exact thing using json.loads in python.
hi @carlton @Jivraj !
could you please provide us with the correct answers for all the 57 GA questions, so that it would be really helpful for us to cross check if our app is returning the correct answer for each question. please consider sharing the correct answers for all the questions as they are not available in the seek portal as well
Hi @23f2003413
We won‚Äôt be sending codes for any of the questions, regarding validation part you can submit answer to portal and if that works.
All first 5 GA‚Äôs were conducted on anand sir‚Äôs proxy server portal,  so just enable check answers button and you can test answers.
can u please let me know on how to enable the check answers button? and which proxy server portal are you talking about. please help me out!
@Jivraj @carlton sir
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a web page, specifically a task or instruction set likely from an online course or challenge (likely related to web development). It provides instructions on how to publish a page using GitHub Pages.\n\n**Key Elements:**\n\n1. **Header/Navigation:** The top of the screen shows a standard mobile browser interface with time, network signal, and browser controls. It also displays "TDS 2025 Jan" and a website address ("anand.workers.dev").\n2. **Instructions:** The main content consists of text-based instructions.\n * It requests users to publish a page on GitHub Pages and verify their email address (`22f3000819@ds.study.iitm.ac.in`) is present in the page\'s HTML.\n * It mentions that GitHub Pages are served via Cloudflare, which obfuscates emails.\n * It shows how to wrap an email address in a specific code block.\n * It requests users to check the GitHub Pages URL.\n * It provides a way to bust the cache. \n3. **Code Snippets:** The image includes code examples of how to wrap the email address.\n4. **Button:** There\'s a prominent blue button labeled "Check".\n5. **Footer:** The bottom part of the image has a number "4" and text ‚ÄúUse Google Colab (0.5 marks)‚Äù.\n\n**Color Scheme:** The image primarily utilizes a dark mode interface with white text on a dark background. The "Check" button is blue.\n\n**Overall, the image depicts a technical instruction or task for users familiar with web development, specifically related to deploying content on GitHub Pages.**10001450151080√ó2340 234 KB
For questions like this (there‚Äôs a similar one in GA1 too, will the user send the USER and REPO of their GitHub account as parameters too?
Even if they do, my script may not get necessary authentication to create repo and make commit in their repository. In this case, would I have to implement GitHub OAuth flow?
If they don‚Äôt send those details but just the email and I am expected to just change the email in my own repo and commit, in the worst case making the same change repeatedly may be misconstrued as a DDoS attack by an automated script which may lead to my GitHub account being suspended, which does not seem ideal.
Can you please at least hint at a solution?
Edit: Same query for the GitHub actions question (GA2 Q7)
Another edit: A similar query for GA2 Q8. Repeated dockerimage pushes to Dockerhub with different tags.
Use the following script to enable answer boxes and check answers buttons:
inputs = document.querySelectorAll('input')
textboxes = document.querySelectorAll("textarea")
buttons  = document.querySelectorAll("button")
inputs.forEach(input =&gt; input.removeAttribute('disabled'));
buttons.forEach(input =&gt; input.removeAttribute('disabled'));
textboxes.forEach(input =&gt; input.removeAttribute('disabled'));

This was provided with the Mock ROE2 mail.
For GA-1 question 10,
we need to get the hash of the json, from the site JSON Hash,
I found that underneath it using sha-256 in a function inside the encrypt.js file but still when I implemented the same in python, it is giving a different hash. Can we get the hashing code in python?
@carlton @Jivraj
Update:

I was successful in getting the hash in js.

You won‚Äôt be required to update someone else‚Äôs repo.
Any github name, repo name is fine.
Just that it should have github pages with that particular email address.



 22f3000819:

Same query for the GitHub actions question (GA2 Q7)


Same for GA2 Quetion7 as well, you github url is required.



 22f3000819:

If they don‚Äôt send those details but just the email and I am expected to just change the email in my own repo and commit, in the worst case making the same change repeatedly may be misconstrued as a DDoS attack by an automated script which may lead to my GitHub account being suspended, which does not seem ideal.
Can you please at least hint at a solution?


In evaluation we will only send request one worst case twice or thrice if it fails from our end, so no issues with that.



 21f2000709:

I was successful in getting the hash in js.


I was thinking of same solution it would definetly work in js.
Okay. Thank you sir. I‚Äôll just do this after the rest for now.
Another question .. In GA1 Q6, will the hidden element be sent as an html file or will the tag be included in the question parameter?
@carlton and @jivraj,
Hello.. I am facing issue with zip file extraction function which is in many GA1 questions. e.g., for GA1 Q15, if I use 7-zip to extract files, it shows the correct total size when using Postman for local server. If I use python built-in function, it calculates a different value (which is incorrect). So, I used 7-zip. But I (with help from copilot agent) am not able to make 7-zip work on the vercel deployment. Can we just hard code the answers to GA1 questions, or is there a way to take answer from local server and use it for response in vercel (sorry, it doesn‚Äôt even make sense to me, but a lot of things are hard to understand anyway)? Or how do we resolve this 7-zip issue. Python built-in extraction did not work correctly even after hours of trying..
I have another question. Due to lack of time, if I just submit the Project 2, with question/answers to GA1, (and if these all work as expected on vercel), how much approx score can we get if I am not able to do other GAs at all for Project 2. Edit after posting: I can hard code questions and other answers from GA2 upto GA4 (I missed GA5, so don‚Äôt have those answers). Thank you.
I too want to know like by 5 questions at random, is it 1 random question per GA or 5 random questions from the entire 5 GAs?
In the later case, there would be no certainty unless all of our questions works and there aren‚Äôt any unexpected surprises at the evaluation.
in the GA 4 question 5 ( Find the bounding box of a city ) Will the OSM_id ending digits be provided. In the question body they are not there but on submission they come like in the attached screenshot.
Here\'s a detailed description of the image:\n\n**Overall Content:** The image is a screenshot of a web page, seemingly related to data analysis and urban planning, specifically regarding bounding box data for the city of Tianjin, China.\n\n**Key Elements and Text:**\n\n* **Heading:** The page starts with a heading "Impact" followed by text explaining how automating the extraction and processing of bounding box data benefits UrbanRide.\n* **Bullet Points:** Several bullet points outline the specific impacts, including:\n * **Optimize Routing:** Enhancing route planning for reduced delivery times and costs.\n * **Improve Fleet Allocation:** Effectively allocating vehicles across service zones.\n * **Enhance Market Analysis:** Gaining insights into regional performance for targeted marketing.\n * **Scale Operations:** Seamlessly integrating new cities with minimal manual intervention.\n* **Question:** A question is posed: "What is the minimum latitude of the bounding box of the city Tianjin in the country China on the Nominatim API?"\n* **Input Field:** There\'s a text input field with the value "38.566" entered.\n* **Error Message:** An error message is displayed below the input field: "Error: Incorrect latitude. Check OSM ID ending with 2877".\n\n**In essence, the image shows a data analysis interface where a user is prompted to enter the minimum latitude of a bounding box for Tianjin, China, and receives an error message indicating an incorrect value.**image1614√ó372 45 KB


github.com



Here\'s a detailed description of the image:\n\n**Overall:** The image is a screenshot of a GitHub repository page.\n\n**Key Elements:**\n\n* **Repository Name:** "Tusharisme/TDS\\_Project\\_2" is prominently displayed in large, dark text on the left. This indicates the repository belongs to the user "Tusharisme".\n* **Repository Icon:** A blue, abstract icon with grid-like patterns is visible to the right of the repository name.\n* **Statistics:** Below the repository name and icon, there are statistics for the repository:\n * **Contributor:** "1"\n * **Issues:** "0"\n * **Stars:** "0"\n * **Forks:** "0"\n* **GitHub Logo:** A small, white GitHub logo appears in the bottom right corner.\n* **Background:** The background is a light grey, providing good contrast for the text and icons.\n\n**Overall Impression:** This image appears to be a new or recently created GitHub repository, as indicated by the zero stars, forks, and issues.
GitHub - Tusharisme/TDS_Project_2
Contribute to Tusharisme/TDS_Project_2 development by creating an account on GitHub.






This is my project github repo link.I just wanted your guys suggestion with this‚Ä¶like am I going correct
@carlton @Jivraj @s.anand
I faced the same issue. Initially, I used geopy.geocoders to solve the question, and it provided the correct answer during the assignment submission. However, the same approach is now giving an incorrect result.
Instead of using geopy, try using this URL directly: https://nominatim.openstreetmap.org/search .
This worked for me.


I have a doubt like when I pass answers in string and in the questions about markdown will the \n characters be properly parsed before checking the correctness of the markdown or will it be directly checked for valid markdown? Because the raw string when pasted in the text box of the GA isn‚Äôt getting the markdown.


In case of image compression question, should I return the base64 encoding of the compressed image?
@Jivraj


@carlton @Jivraj @Saransh_Saini
Respected TDS Team,
I currently have Three doubts regarding Project 2:


As per the 19th March session, it was mentioned that the files would be the same for everyone, and only the parameters in the questions would vary. However, I have noticed that the files can actually be different. To support this, I‚Äôm attaching screenshots of the CSV files for GA5 Q1‚Äîone is mine, and the other belongs to a batchmate.
model='gemma3:27b' created_at='2025-06-13T16:24:30.622265538Z' done=True done_reason='stop' total_duration=46272592684 load_duration=17898792 prompt_eval_count=323 prompt_eval_duration=18341215137 eval_count=282 eval_duration=27912677267 message=Message(role='assistant', content="Here's a detailed description of the image:\n\n**Overall:** The image is a screenshot of a spreadsheet or table, likely from a data analysis or database program. It presents transactional data.\n\n**Columns:** The table consists of the following columns:\n* **TransactionID:** A unique identifier for each transaction (numbers 0001 to 0014).\n* **Customer Name:** The name of the customer associated with the transaction (e.g., John Doe, Frank Thomas).\n* **Country:** The country of origin for the customer (e.g., France, United States, UAE). Includes country codes (e.g. FRA, IND, AE).\n* **Date:** The date of the transaction in a YYYY/MM/DD format.\n* **Product/Code:** An alphanumeric code representing the product purchased in the transaction.\n* **Sales:** The sales amount of the transaction, expressed in USD (United States Dollar).\n* **Cost:** The cost amount of the transaction, also in USD.\n\n**Data:** The table contains 14 rows of transactional data, including customer names, countries, dates, product codes, sales amounts and costs. \n\n**Formatting:** The data is formatted as a standard table with clear column headers. The sales and cost values are presented numerically.", thinking=None, images=None, tool_calls=None)mydata939√ó401 18.3 KB
model='gemma3:27b' created_at='2025-06-13T04:48:34.389717544Z' done=True done_reason='stop' total_duration=51824508568 load_duration=17687066 prompt_eval_count=323 prompt_eval_duration=18750032414 eval_count=329 eval_duration=33056064314 message=Message(role='assistant', content="Here's a detailed description of the image:\n\n**Overall:**\n\nThe image is a screenshot of a spreadsheet or table. It appears to be a transaction log or sales record. \n\n**Columns:**\n\nThe table has the following columns:\n\n* **TransactionID:** A unique identifier for each transaction, ranging from 0001 to 0018.\n* **Customer Name:** The name of the customer making the purchase (e.g., Frank Thomas, Eve Wilson, Jane Smith).\n* **Country:** The country of origin for the customer, using abbreviations like IND, US, AE, Fra, U.K.\n* **Date:** The date of the transaction in YYYY/MM/DD format.\n* **Product/Code:** An alphanumeric code identifying the product purchased (e.g., Delta/tbakf3, Alpha/hknae9).\n* **Sales:** The sales amount for the transaction in USD.\n* **Cost:** The cost amount for the transaction in USD.\n\n**Data:**\n\nThe table contains 18 rows of transaction data with corresponding values for each column. The data appears to be numerical for the 'Sales' and 'Cost' columns, while the other columns contain text data.\n\n**Formatting:**\n\n* The table has clear column headers.\n* Data is aligned within each column.\n* The currency is consistently denoted as USD.\n\n**Purpose:**\n\nThe table is likely used to track sales transactions, identify customer purchase patterns, or analyze revenue data.", thinking=None, images=None, tool_calls=None)friend data938√ó465 20.5 KB
During the session, it was said that uploading files would take time, and the suggested solution was to pre-download the files on the server since they are supposed to be the same. But since the files are not identical for all students, this issue needs to be addressed.


In GA4 Q2, my task is to retrieve movie information from IMDb for all films with a rating between 3 and 5. I am scraping the correct movie names(for example 6th movie in given image), but the portal is accepting them differently. All movie names are provided in English, but the portal seems to be accepting some titles in other languages‚ÄîSpanish, Dutch, I believe.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of what appears to be a debugging or error message related to a data scraping or processing task, likely involving JSON data and potentially a web scraping tool for IMDB. \n\n**Key Elements and Details:**\n\n1. **JSON Data Block:** A rectangular block displaying JSON (JavaScript Object Notation) data. The JSON includes keys such as "id," "title," "year," and "rating." The "title" field contains the value "% Nadaniyani%".\n\n2. **Error Message:** Below the JSON block, a prominent red error message reads "Error: At [/title] Values don‚Äôt match. Expected: \'% Nadaniyani%\'. Actual: \'% Nadaniyani%\'." This suggests a comparison or validation is failing despite the values appearing identical.\n\n3. **IMDB Information:** Text below the error message indicates this involves IMDB search results. It warns that results may differ by region and provides a recommendation to manually translate the title. It also suggests the need to review the ‚Äúscraper code‚Äù.\n\n4. **"Check" Button:** A blue "Check" button is visible at the bottom left of the screen. This likely initiates some validation or testing process.\n\n**In essence**, the image depicts an error within a data scraping/processing pipeline where a title from IMDB is being checked against an expected value. Despite the values appearing identical, the error message indicates a mismatch, possibly due to hidden characters or data type inconsistencies.image1674√ó420 24.3 KB
Here\'s a detailed description of the image:\n\n* **Content:** The image is a screenshot from a streaming or database website listing movies or television shows.\n* **Layout:** It displays a list with numbered entries, each representing a title.\n* **Entry Details:** Each entry includes:\n * A poster image (in this case, for a film titled "Nadaanian").\n * The title ("Nadaanian").\n * Release year ("2025").\n * Duration ("1h 59m").\n * TV/Movie rating ("TV-14").\n * User rating ("3.0 (1.4K)").\n * A rate button.\n* **Plot Summary:** Below the "Nadaanian" entry is a brief plot synopsis: "A privileged Delhi socialite hires a middle-class student to pose as her boyfriend to maintain her social status. Their pretense becomes complicated when genuine feelings develop between them." \n* **Overall Impression:** The image showcases a platform where users can browse, rate, and view details about movies and TV shows.image1118√ó358 63.7 KB
Please check the issue in the images provided. How to handle this question.


In GA4 Q10, very few students were able to solve the question using LLMs or Python during the assignment. Most of us ended up solving it manually. At that time, @carlton sir had mentioned that the question would be revised.
Here is the thread link for reference.
How should we handle this question now?


Thankyou
// GA1 question 9:
    //     curl -X POST "http://localhost:8000/api/" -H "Content-Type: multipart/form-data" -F "question=Sort this JSON array of objects by the value of the age field. In case of a tie, sort by the name field. Paste the resulting JSON below without any spaces or newlines. 
    // [{\"name\":\"Alice\",\"age\":92},{\"name\":\"Bob\",\"age\":28},{\"name\":\"Charlie\",\"age\":16},{\"name\":\"David\",\"age\":56},{\"name\":\"Emma\",\"age\":70},{\"name\":\"Frank\",\"age\":67},{\"name\":\"Grace\",\"age\":36},{\"name\":\"Henry\",\"age\":94},{\"name\":\"Ivy\",\"age\":44},{\"name\":\"Jack\",\"age\":53},{\"name\":\"Karen\",\"age\":65},{\"name\":\"Liam\",\"age\":23},{\"name\":\"Mary\",\"age\":97},{\"name\":\"Nora\",\"age\":68},{\"name\":\"Oscar\",\"age\":57},{\"name\":\"Paul\",\"age\":88}]"
    {
        "answer": "[{\"name\":\"Charlie\",\"age\":16},{\"name\":\"Liam\",\"age\":23},{\"name\":\"Bob\",\"age\":28},{\"name\":\"Grace\",\"age\":36},{\"name\":\"Ivy\",\"age\":44},{\"name\":\"Jack\",\"age\":53},{\"name\":\"David\",\"age\":56},{\"name\":\"Oscar\",\"age\":57},{\"name\":\"Karen\",\"age\":65},{\"name\":\"Frank\",\"age\":67},{\"name\":\"Nora\",\"age\":68},{\"name\":\"Emma\",\"age\":70},{\"name\":\"Paul\",\"age\":88},{\"name\":\"Alice\",\"age\":92},{\"name\":\"Henry\",\"age\":94},{\"name\":\"Mary\",\"age\":97}]"
    }

Is it ok for GA 1 Question 9 answer output to look like this because it matches with the answer just it has the extra back slash‚Ä¶What should i do
def sort_json_array(json_array: str, sort_keys: list) -&gt; str:
    """
    Sort a JSON array based on specified criteria

    Args:
        json_array: JSON array as a string
        sort_keys: List of keys to sort by

    Returns:
        Sorted JSON array as a string
    """
    try:
        # Parse the JSON array
        data = json.loads(json_array)

        # Sort the data based on the specified keys
        for key in reversed(sort_keys):
            data = sorted(data, key=lambda x: x.get(key, ""))

        # Return the sorted JSON as a string without whitespace
        return json.dumps(data, separators=(",", ":"))

    except Exception as e:
        return f"Error sorting JSON array: {str(e)}"

{
            "type": "function",
            "function": {
                "name": "sort_json_array",
                "description": "Sort a JSON array based on specified criteria",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "json_array": {
                            "type": "string",
                            "description": "JSON array to sort",
                        },
                        "sort_keys": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "List of keys to sort by",
                        },
                    },
                    "required": ["json_array", "sort_keys"],
                },
            },
        },

@carlton @Jivraj

Hi @23f2003751
Short Answer: No
Long Answer:
Backslashes are usually not a problem when converting a string to JSON. But somehow the evaluation script isn‚Äôt taking this into consideration. Check this out.
This is my response
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a string of JSON (JavaScript Object Notation) data.\n* **Data Structure:** The JSON represents an array of objects. Each object contains two key-value pairs: `"name"` (string) and `"age"` (number).\n* **Data Values:**\n * The first object has `"name": "Bob"` and `"age": 11`.\n * The second object has `"name": "Emma"` and `"age": 11`.\n * The third object has `"name": "Grace"` and `"age": 14`.\n * The fourth object has `"name": "na"` and `"age": null`.\n* **Visual Characteristics:** The JSON data is presented as a string of text with a dark background, typical for code display. \n* **Text Overlay:** The image includes text overlay labels "Sorted JSON:" and "Correct."image1113√ó125 3.01 KB
which is shown incorrect just after adding 2 backslashes
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a line of JSON code with a syntax error highlighted.\n* **JSON Data:** The JSON appears to be an array of objects, where each object represents a person with a "name" and "age" property. The data includes entries for "Bob" (age 11), "Emma" (age 11), and "Grace" (age 14).\n* **Syntax Error:** A red underline and error message ("SyntaxError: Expected property name or \'}\' in JSON at position 16 (line 1 column 17)") indicates a syntax error within the JSON code. The error suggests an unexpected character or missing property name/closing curly brace at that position.\n* **Background:** The image has a dark background which highlights the error and the code itself.\n* **Text Label:** The image includes the text label "Sorted JSON:" at the top.image1107√ó122 4.01 KB
Note: It would be better to check your responses on the TDS portal before finalising the script. You can access the answer box and check button by removing the disable attribute.
@Saransh_Saini
it can‚Äôt be fixed actually, you would need the answer in the json format
{"answer": "actual_answer"}
but if the actual_answer needs to be string and if it happens to be of json type, it has to be represented using \"
Do we require open_api key like project 1 for this one too ? if yes from where we can get that?



 lakshaygarg654:

As per the 19th March session, it was mentioned that the files would be the same for everyone, and only the parameters in the questions would vary. However, I have noticed that the files can actually be different. To support this, I‚Äôm attaching screenshots of the CSV files for GA5 Q1‚Äîone is mine, and the other belongs to a batchmate.
model='gemma3:27b' created_at='2025-06-13T16:24:30.622265538Z' done=True done_reason='stop' total_duration=46272592684 load_duration=17898792 prompt_eval_count=323 prompt_eval_duration=18341215137 eval_count=282 eval_duration=27912677267 message=Message(role='assistant', content="Here's a detailed description of the image:\n\n**Overall:** The image is a screenshot of a spreadsheet or table, likely from a data analysis or database program. It presents transactional data.\n\n**Columns:** The table consists of the following columns:\n* **TransactionID:** A unique identifier for each transaction (numbers 0001 to 0014).\n* **Customer Name:** The name of the customer associated with the transaction (e.g., John Doe, Frank Thomas).\n* **Country:** The country of origin for the customer (e.g., France, United States, UAE). Includes country codes (e.g. FRA, IND, AE).\n* **Date:** The date of the transaction in a YYYY/MM/DD format.\n* **Product/Code:** An alphanumeric code representing the product purchased in the transaction.\n* **Sales:** The sales amount of the transaction, expressed in USD (United States Dollar).\n* **Cost:** The cost amount of the transaction, also in USD.\n\n**Data:** The table contains 14 rows of transactional data, including customer names, countries, dates, product codes, sales amounts and costs. \n\n**Formatting:** The data is formatted as a standard table with clear column headers. The sales and cost values are presented numerically.", thinking=None, images=None, tool_calls=None)mydata939√ó401 18.3 KB
model='gemma3:27b' created_at='2025-06-13T04:48:34.389717544Z' done=True done_reason='stop' total_duration=51824508568 load_duration=17687066 prompt_eval_count=323 prompt_eval_duration=18750032414 eval_count=329 eval_duration=33056064314 message=Message(role='assistant', content="Here's a detailed description of the image:\n\n**Overall:**\n\nThe image is a screenshot of a spreadsheet or table. It appears to be a transaction log or sales record. \n\n**Columns:**\n\nThe table has the following columns:\n\n* **TransactionID:** A unique identifier for each transaction, ranging from 0001 to 0018.\n* **Customer Name:** The name of the customer making the purchase (e.g., Frank Thomas, Eve Wilson, Jane Smith).\n* **Country:** The country of origin for the customer, using abbreviations like IND, US, AE, Fra, U.K.\n* **Date:** The date of the transaction in YYYY/MM/DD format.\n* **Product/Code:** An alphanumeric code identifying the product purchased (e.g., Delta/tbakf3, Alpha/hknae9).\n* **Sales:** The sales amount for the transaction in USD.\n* **Cost:** The cost amount for the transaction in USD.\n\n**Data:**\n\nThe table contains 18 rows of transaction data with corresponding values for each column. The data appears to be numerical for the 'Sales' and 'Cost' columns, while the other columns contain text data.\n\n**Formatting:**\n\n* The table has clear column headers.\n* Data is aligned within each column.\n* The currency is consistently denoted as USD.\n\n**Purpose:**\n\nThe table is likely used to track sales transactions, identify customer purchase patterns, or analyze revenue data.", thinking=None, images=None, tool_calls=None)friend data938√ó465 20.5 KB
During the session, it was said that uploading files would take time, and the suggested solution was to pre-download the files on the server since they are supposed to be the same. But since the files are not identical for all students, this issue needs to be addressed.


The file is just 341kb. it should take less than a second. So you do not have to pre download this file. Only very large ones that are not parameterised you can have a hard copy of.



 lakshaygarg654:

In GA4 Q2, my task is to retrieve movie information from IMDb for all films with a rating between 3 and 5. I am scraping the correct movie names(for example 6th movie in given image), but the portal is accepting them differently. All movie names are provided in English, but the portal seems to be accepting some titles in other languages‚ÄîSpanish, Dutch, I believe.


Questions that require manual intervention will be graded very liberally. In other words those questions will not have as strict a grading criteria as in the GA portal.



 lakshaygarg654:

In GA4 Q10, very few students were able to solve the question using LLMs or Python during the assignment. Most of us ended up solving it manually. At that time, @carlton sir had mentioned that the question would be revised.
Here is the thread link for reference.
How should we handle this question now?


Same as above.
Kind regards
the problem is not the url , if we provide the ending digits of osm_id then only we can match it as multiple cities are there in same country but osm_id is unique
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a code block within a Google Colab environment. It appears to be a Python script designed to retrieve user information from Google\'s OAuth2 API. \n\n**Key Elements & Code Breakdown:**\n\n1. **Import Statements:**\n * `import hashlib`: Imports the hashlib library for cryptographic hashing.\n * `import requests`: Imports the requests library for making HTTP requests.\n * `from google.colab import auth`: Imports the auth module from the google.colab library.\n * `from oauth2client.client import GoogleCredentials`: Imports the GoogleCredentials class from the oauth2client.client library.\n\n2. **Authentication & Credential Retrieval:**\n * `auth.authenticate_user()`: Authenticates the user, prompting for Google account access.\n * `creds = GoogleCredentials.get_application_default()`: Obtains default Google credentials.\n * `token = creds.get_access_token().decode(\'utf-8\')`: Retrieves the access token and decodes it as a UTF-8 string.\n\n3. **API Request:**\n * `response = requests.get("https://www.googleapis.com/oauth2/v1/userinfo", params={"alt":"json"}, headers={"Authorization": f"Bearer {token}"})`: Sends a GET request to the Google Userinfo API to retrieve user information.\n * `params={"alt":"json"}`: Specifies that the response should be in JSON format.\n * `headers={"Authorization": f"Bearer {token}"}`: Sets the authorization header with the access token.\n\n4. **Data Extraction & Hashing:**\n * `email = response.json()["email"]`: Extracts the email address from the JSON response.\n * `hashlib.sha256(f"{email} ({creds.token_expiry_year}").encode()).hexdigest()[:5]`: \n * Concatenates the email and the token expiry year.\n * Encodes the string as UTF-8.\n * Calculates the SHA256 hash of the encoded string.\n * Takes the first 5 characters of the hexadecimal representation of the hash.\n\n5. **Prompt/Instruction:**\n * "What is the result? (It should be a 5-character string)": Indicates the code is designed to produce a 5-character string as the output.\n\n6. **Colab Header:** The top of the screenshot shows a Colab message: "Let\'s make sure you can access Google Colab. Run this program on Google Colab, allowing all required access to your email ID: 23f10015240s.study.itme.ac.in"\n\n**Overall, the script appears to be part of a process to securely identify a user in a Google Colab environment by hashing their email address and the token\'s expiry year.** It\'s a common practice to ensure a user has authorized access before proceeding with further computations.image1613√ó554 32.9 KB
How to parameterise this function? It is really difficult to do this function with other parameter, please help. what is approach other than hardcoding it?
Did you get a solution for the Markdown question? I have the same issue.
@Jivraj @carlton @Saransh_Saini
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a text-based report titled "Step Analysis Report." It appears to be a data analysis output, likely generated from a Python script, detailing daily step counts and observations related to those counts.\n\n**Key Elements and Details:**\n\n* **Title:** The report is titled ‚ÄúStep Analysis Report‚Äù.\n* **Introduction:** It starts with an introduction about tracking daily steps and comparing results over time.\n* **Data Collection Method:** The steps were collected using a fitness tracker and recorded daily.\n* **Steps Walked Table:** A table lists the steps walked each day:\n * Monday: 8,500\n * Tuesday: 9,200\n * Wednesday: 10,000\n * Thursday: 9,600\n * Friday: 8,800\n * Saturday: 10,200\n * Sunday: 9,800\n* **Code Snippet:** A short Python code snippet using the pandas library (`pd.DataFrame`) to analyze the data is included. The code likely calculates descriptive statistics.\n* **Observations:** The report states that the highest step count was recorded on Sunday.\n* **Comparison with Friends:** It mentions analyzing steps with friends. Alice and Bob are cited with step averages of 10,500 and 9,800 respectively.\n* **Improvements:** Suggestions to improve step count tracking are listed, including increasing daily goals and using an advanced fitness tracker.\n* **External Link:** There\'s a link to a Healthline article related to daily steps.\n* **Formatting:** The text appears to be formatted with markdown, using headings and lists.\n\n**Overall, the image presents a concise analysis of daily step count data, including data collection methods, Python code, key findings, and recommendations.**image892√ó388 18 KB
Can we rather do PlainTextResponse for the markdown question?
@Jivraj @carlton @Saransh_Saini
Questions Requiring Clarification/Manual Intervention for Evaluation (As Discussed in Tuesday‚Äôs Session)
Respected TDS Team,
As per the discussion during the Tuesday session, and following @Saransh‚Äôs suggestion, I am creating this post to list the questions that may require manual intervention or are facing issues potentially due to portal-side behavior. Kindly verify these points before evaluation.

 Questions Requiring Manual Intervention / Portal-Side Issue


GA3 Q8

Issue: The question doesn‚Äôt mention all required queries. Although all mentioned queries were added, the portal seems to check for additional queries not stated, resulting in an incorrect answer flag.



GA3 Q9

Issue: This question asks to create an LLM prompt, but upon submission, a pop-up requests the AIPROXY_TOKEN.
Clarification needed: How are we supposed to handle token-based inputs for evaluation?



GA4 Q2 &amp; Q10

Issue: Previously encountered issues have been resolved.
Reference: GA4 Q2 and Q10 resolution



Output Formatting (Multiple Questions)

Issue: When using plain text, the answer is accepted. However, in JSON format, newline characters (\n) and backslashes are added.
Note: As per the project requirement, the output should be in JSON like {‚Äúanswer‚Äù: ‚Äúresult‚Äù}. But directly copy-pasting such a result with special characters leads to rejection by the portal.



Vercel / Docker Hub / Ngrok Deployment Questions

Issue: Some deployment-related questions require a **live-running server, which needs real-time manual deployment using platforms like Vercel or Ngrok.
Clarification needed: How is this expected to be evaluated?




Deployment-Related Issues (To Be Included in Thursday‚Äôs Session)
Please include discussion and solutions for the following deployment issues:


Platform Capability for GA Tasks

Which cloud platform (Azure, DigitalOcean, etc.) can handle all GA tasks reliably?
Note: Some platforms have limitations that block certain tasks or token usage.



File Upload Example via Platform API

Request: Please provide examples for both small and large file uploads using API from a cloud-deployed app.
This would help validate deployments for assignment questions involving file input.



General Observations on GA1-5
Output Accuracy: Approximately 80% of the questions in GA1-5 return correct output when tested on a local machine. However, about 20% either have portal-side issues or deployment-related problems.



Kindly review these points before final evaluation, and let us know if any additional clarification is required from our side.
Thanks a lot @23f2005702, we‚Äôll try to answer these questions in Thursday‚Äôs session.
Is their any way to solve this issue. @Jivraj
@carlton ( @Saransh_Saini ) @Jivraj , is it possible to extend the deadline by 2 days April 1st, since we can use the LLM api a little more and Most people(me atleast) have Their OPPEs and its combined syllabus (and the OPPE 1 did not go well, partly due to my inadequacies) , which has much more to cover, since this project involves more involved coding compared to the last project(ideally project one should have taken not more than a day , still messed it up though xD). Asking for extension for 2 days, if possible. Really need it not even want, like need
Summary: Please extend Project 2 deadline by 2 days(April 1st),
(actually 1 day extension is April 1st)
Hi @23f1002382 ,
Unfortunately it‚Äôs not possible for us to extend the deadline. Project 2 was released almost a month back, and that can be considered ample amount of time to complete the project. I can understand it must be hard to deal with it along with an upcoming OPPE, but this is what it is. Even if you are not able to cover all the 58 questions, try to cover the majority of them, as the evaluation involves sending just 1-3 questions for evals.
All the best for your OPPE and your Project 2 
@21f2000709 @23f2003751
Yes you are absolutely right. I confirmed this with Carlton and Anand sir, and yes you have to send the JSON responses as strings, which will automatically add those backslashes(\). I apologies for causing this confusion, and I hope I was able to clarify it.
Yes, your response seems correct. It should be a single string containing all the markdown.
@Saransh_Saini can you please confirm 5 Qs at random means 5 random Qs from entire 58 Qs or 1 random Q/GA for the evaluation of TDS Project 2.
Hi @21f3001993
You can use the zipfile library to extract and access zip files pretty easily. You can even make it so that you don‚Äôt even have to download the sent file either zip/csv/etc, in order to access it. All this will be discussed in Thurday‚Äôs [27-03-2025] Live Session. Kindly attend the session if you want a deeper understanding of it.
It can be any 5 questions.
It can be 1-5 random questions from all 58 question. Its not like a random question each from each GA. It‚Äôs even possible to get all those 5 questions from one single GA.
For GA 2 Question 10, how do we host an LLM on a free vm with very limited resources?
Ok, thanks. I won‚Äôt be able to attend the session live, but will watch the recording. Thanks for offering to discuss this in live session.
just to clarify if the llm is giving the output like this the evaluation script will mark it correct.
{
 "answer": "[{\"name\":\"Charlie\",\"age\":16},{\"name\":\"Liam\",\"age\":23},{\"name\":\"Bob\",\"age\":28},{\"name\":\"Grace\",\"age\":36},{\"name\":\"Ivy\",\"age\":44},{\"name\":\"Jack\",\"age\":53},{\"name\":\"David\",\"age\":56},{\"name\":\"Oscar\",\"age\":57},{\"name\":\"Karen\",\"age\":65},{\"name\":\"Frank\",\"age\":67},{\"name\":\"Nora\",\"age\":68},{\"name\":\"Emma\",\"age\":70},{\"name\":\"Paul\",\"age\":88},{\"name\":\"Alice\",\"age\":92},{\"name\":\"Henry\",\"age\":94},{\"name\":\"Mary\",\"age\":97}]"
 }

@Jivraj
Yes, it will. Just make sure that doing a json.loads() on this string should give you the desired output.
The GA portal marks it as wrong unless I manually insert new lines. I hope that won‚Äôt be an issue, will it?
Your markdown must have newline characters or spaces wherever necessary. Otherwise we will not be able to check if your answer is correct. Our parser will only work if encodings for the formatting are present in the response. If there are no encodings (invisible or visible) then we will not have the correctly formatted file.
Please review module 1 for a better understanding about how text is encoded. Especially invisible characters.
The browser is designed for user friendliness. Thats why the characters are invisible when you copy paste string with newlines. But it exists.
The programmatic strings show invisible encodings as escaped characters. (Usually)
To check if a string has invisible characters,
# Multi-line string
my_string = """Hello
World    with    spaces 
and some newlines
and a tab	"""

# Print ASCII values of each character
print([ord(c) for c in my_string])

e.g., newline = 10, tab = 9
This is a great way to check what we are receiving when you send us some response,
import requests
import json

# This is just an example server to see what we see.

url = "https://httpbin.org/post"

my_multiline_string_answer = """This is a multiline
string that spans
multiple lines    with    spaces 
and some newlines
and a tab	as well."""

response_to_send_to_tds_evaluator = {
"answer": my_multiline_string_answer
}

# Send the JSON data
response = requests.post (url, json=response_to_send_to_tds_evaluator)

# Check the response
print (response.status_code)
print (response.json ())
print (response.text)

# Do other checks as necessary... 

See what happens when I print the result
print (json.loads (response.text)['json']['answer'])

Here\'s a detailed description of the image:\n\n**Overall:** The image displays a terminal window with a multiline string printed to the console. The terminal is running on a macOS system (identified by the "MacBook-Pro" in the prompt).\n\n**Specific details:**\n\n* **Terminal Prompt:** The prompt reads `.venvcarland@Carlton-MacBook-Pro tds %` indicating a virtual environment named `.venvcarland` is active.\n* **File Name:** The string originates from a file named `test.py` which is located in the `/tds/` directory.\n* **Multiline String:** The console output consists of a single string spanning multiple lines. \n* **Content of String:** The string reads: "This is a multiline string that spans multiple lines with spaces and some newlines and a tab as well."\n* **Spacing/Formatting:** The string demonstrates the use of spaces, newlines and a tab character for formatting the output.\n* **Second Terminal Prompt:** Another terminal prompt is visible at the bottom of the image, matching the first.\n\nIn essence, the image showcases the output of a Python program (likely a simple print statement) displaying a multiline string in a terminal environment.Screenshot 2025-03-27 at 1.09.56 pm323√ó120 3.61 KB
Its a proper multiline correctly formatted text! The encodings are invisible just like in the original as well as in your clipboard when you copy paste into the GA.
Here is a json example:
json_answer = {
    "mary": "poppins",
    "age": 42
}

stringed_json = json.dumps (json_answer)
response_to_send_to_tds_evaluator = {
"answer": stringed_json
}

response = requests.post (url, json=response_to_send_to_tds_evaluator)

print (json.loads (response.text)['json']['answer'])

Look at the response. A perfect json.
Here\'s a detailed description of the image:\n\n* **Type**: The image is a screenshot of a terminal window.\n* **Prompt/Path**: It displays a command-line prompt indicating the user is "venvcarland" on a machine named "Carlton-MacBook-Pro". The current directory is "tds".\n* **File Name**: The file being referenced is "test.py".\n* **Output**: The output displayed is a JSON (JavaScript Object Notation) object with two key-value pairs:\n * "mary": "poppins"\n * "age": 42\n* **Indicators**: There are two symbols at the beginning of the lines, a blue dot and a diamond, indicating the current location within the directory structure.\n* **Color Scheme**: The terminal uses a dark background with green text, a common aesthetic for command-line interfaces.\n\nIn summary, the image shows a Python program ("test.py") executing and outputting a JSON object containing data related to a person named Mary and her age.
If you do not want spaces in the response then strip the spaces before you send the stringified response.
Kind regards
I would request the TDS team to please consider making the evaluation criteria for project 2 a bit more liberal.
5 random Questions with 4 marks each is quite harsh. I request you to make it more balanced like 2 Qs from each GA with 2 marks each or so. So that even if we can‚Äôt exhaustively cover the whole number of questions, it gives mercy for the partial completion.
5 random question is a kind of lottery or luck based unless our app is perfect. Thanks
@carlton @s.anand
Hey guys, I have designed the code, and it currently works for the first 11 GA1 questions and the sixth and third questions of GA2. I have accounted for all edge cases. Please check the code at this link:
https://4e52-43-230-106-58.ngrok-free.app/.
Let me know your thoughts!
@carlton , @Jivraj @Saransh_Saini

GA2 - Question 3: Publish a Page Using GitHub Pages



As part of the requirement, I successfully published a webpage using GitHub Pages that includes my email address 21f3001076@ds.study.iitm.ac.in in the HTML content. The page functions correctly and becomes accessible on my local system.


To automate the publishing process, I implemented a delay function that checks for the page‚Äôs availability after 5 seconds. Based on testing, GitHub Pages typically take around 10‚Äì20 seconds to go live after repository creation and HTML deployment. As a result, the complete process‚Äîfrom initiating the API call to verifying that the page is live‚Äîtakes approximately 30 seconds locally. This setup works reliably on my local machine.


However, when deploying the same process on Azure, I encountered an issue. Without the delay, the API responds too quickly‚Äîbefore the GitHub Pages site is actually live‚Äîresulting in a broken or non-functional link on the assignment portal. On the other hand, including the delay function causes Azure to throw a 502 Bad Gateway error, likely due to Azure‚Äôs request timeout limitations. The additional wait time slightly exceeds the platform‚Äôs allowed response duration.



GA4 - Question 9: Process PDF Files



A similar issue occurs in GA4 Question 9, where the task involves processing PDF files. While this works perfectly in the local environment, it leads to a 502 Bad Gateway error on Azure. This is due to the relatively long time required to parse and analyze the PDFs, which again exceeds Azure‚Äôs execution time limit.


Moreover, pre-processing the PDF files is not an option because the input varies for each user. Therefore, the PDFs must be processed dynamically, which adds to the delay and contributes to the timeout problem.


Currently, I am using Azure for deployment, and for the majority of tasks, it works reliably. Although these specific tasks face timeout issues, shifting to another deployment platform is not feasible at this point. I am not certain if alternative platforms will work consistently across all questions, and making such a change could introduce failures in other parts of the assignment where Azure performs well.
Below Image is showing response of local machine api request for GA2 Q3 which works fine.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image shows two separate windows or panes displaying information related to a GitHub Pages website. The left pane displays a technical server response, and the right pane displays a message about GitHub Pages being served via Cloudflare and a request to update a verification URL.\n\n**Left Pane (Server Response):**\n* **Request URL:** Shows a URL starting with "http://[2600:1700:...." obscured for privacy.\n* **Server Response:** Displays a 200 OK status code indicating a successful request.\n* **Response Body:** Shows a JSON object with a "owner" field, revealing a GitHub Pages URL: "https://[obscured].github.io/pages-20230127144635/".\n* **Response Headers:** Contains various headers like ‚Äúaccess-control-allow-credentials‚Äù, ‚Äúcontent-type‚Äù, and ‚Äúdate‚Äù.\n\n**Right Pane (Cloudflare & Verification):**\n* **Message:** States that GitHub Pages are served via Cloudflare and provides a link to the Cloudflare documentation.\n* **Email Obfuscation Request:** Instructs the user to wrap their email address within a specific code to avoid spam bots.\n* **Example Code:** Shows example code for email obfuscation with a placeholder email address.\n* **Possible GitHub Pages URL:** Displays a GitHub Pages URL: "https://[obscured].github.io/pages-20230127144635/".\n* **Confirmation Checkmark:** Includes a green checkmark to confirm a step.\n\n**Overall, the image depicts a technical process related to verifying and setting up a GitHub Pages website through Cloudflare, with a focus on email protection and domain verification.**image1854√ó493 55.9 KB
@s.anand
@carlton
@Jivraj @Saransh_Saini
Final Thoughts on Project 2
Project 2 has been a valuable yet challenging experience. I‚Äôd like to share a few reflections‚Äînot as criticism, but as constructive feedback with the intention to contribute positively to future iterations.

Organization &amp; Structure:
The project felt a bit unstructured at times, which may be expected given that this is possibly the first time such an initiative is being carried out. I‚Äôm not blaming anyone‚Äîjust sharing my thoughts. I hope positive insights can be drawn from this feedback.
Deployment &amp; Portal Limitations:
There are noticeable limitations on the deployment side (e.g., timeouts, platform constraints) and occasional issues on the assignment portal. While frustrating, these also led to some deep technical learning.
Time Constraints:
Balancing this project with ongoing coursework and other responsibilities has been quite demanding. The deadline of March 31st adds pressure, making it difficult to thoroughly test all 57 questions across different environments.
Sessions &amp; Support:
The sessions conducted were helpful in addressing specific topics, but in many areas, I had to rely heavily on GPT and self-guided exploration to move forward.
Deployment Variability:
Each GA‚Äôs questions seemed to expose different limitations depending on the deployment platform. This inconsistency made it hard to predict which questions would work reliably.
Effort Acknowledgment:
I sincerely appreciate the efforts of the TAs and instructors‚Äîit‚Äôs clear that a lot of hard work went into enabling and supporting this project. However, it‚Äôs also a bit disappointing that we, as students, are unsure which questions are expected to work and which may fail‚Äîeven the team might not have full visibility over this at the moment.
Feasibility in the Given Timeline:
Even for someone with a technical background, it‚Äôs difficult to troubleshoot and experiment across so many cases within the current timeline. Trying different approaches per question isn‚Äôt always feasible before the deadline.


I genuinely hope someone is able to complete all 57 questions successfully‚ÄîI‚Äôd love to learn from their experience and solutions.
Again, this post is meant in a positive and constructive spirit. If anything I said seems inappropriate or off the mark, please let me know‚ÄîI‚Äôm happy to edit or delete the post if needed.
Thank you for the learning opportunity
I have implemented till GA 4 q8 with few questions here and there like one with the llamafile, etc. If someone have the functions of GA 5 ready please ping me for collaboration.
@carlton How to do the GitHub Actions questions as it is a cron job based but need manual trigger for the eval script to verify. If done without cron job the portal complains.
If there is any plan for extension, I request the TDS team to announce it in advance as people would rush and submit, then, they come hear about the extension when they had submitted it already.
Happened to me like almost every time. We have OPPE this weekend, so if there is slightest possibility, I request to announce it in advance.
Thanks
@Saransh_Saini @carlton
Can someone reply to this? 
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a text-based document outlining the structure of an Apache web log file and specific data analysis tasks to be performed on it.\n\n**Content Breakdown:**\n\n1. **Heading:** "Your Task" is prominently displayed at the top.\n2. **Log File Information:**\n * The file is a Gzipped Apache log file of size 61MB containing 258,074 rows.\n * Each row represents a single web log entry for the website s-anand.net in May 2024.\n3. **Field Definitions (bulleted list):**\n * **IP:** The IP address of the visitor.\n * **Remote logname:** Usually "-".\n * **Remote user:** Usually "-".\n * **Time:** Timestamp of the visit in the format [01/May/2024:00:00:00 +0000].\n * **Request:** The HTTP request made by the visitor. (e.g., GET /blog/ HTTP/1.1). Broken down into Method, URL, and Protocol.\n * **Status:** HTTP status code. Codes 200 <= Status < 300 indicate a successful request.\n * **Size:** Response size in bytes (e.g., 1234).\n * **Referer:** The referring URL (e.g., https://s-anand.net/).\n * **User agent:** The browser used.\n * **Vhost:** The virtual host (e.g., s-anand.net).\n * **Server:** IP address of the server.\n4. **Data Format Notes:** The fields are separated by spaces and enclosed in double quotes (""), with escaped quotes represented as "\\".\n5. **Timezone:** All data is in the GMT-0500 timezone.\n6. **Task Instructions (numbered list):**\n * **1.** Filter log entries to include only requests where the URL starts with "/malayalamp3/" and made on 2024-05-15.\n * **2.** Aggregate data by summing the "Size" field for each unique IP address from the filtered entries.\n\n**Overall, the image provides a technical overview of an Apache web log file, its data fields, and a defined analytical task to be performed on it.**WhatsApp Image 2025-03-27 at 13.41.43_5bd0a1821600√ó1069 246 KB
Dear Sirs,
I have a question regarding Q3 and Q4 of GA5. When calling the API, should we pass the .gz file directly, or will the API accept a Google Drive link from which it can download the .gz file?
Specifically, will the API call be structured as follows?
Essentialy, will the API call look like so?

curl -X POST ‚Äúhttp://127.0.0.1:5000‚Äù 
-H ‚ÄúContent-Type: multipart/form-data‚Äù 
-F "question=Bandwidth Analysis for Regional Contents - anand.net is a personal website that had region-specific music content. One of the site‚Äôs key sections is tamilmp3, which hosts music files and is especially popular among the local audience. The website is powered by robust Apache web servers that record detailed access logs. These logs are essential for understanding user behavior, server load, and content engagement. By analyzing the server‚Äôs Apache log file, the author can identify heavy users and take measures to manage bandwidth, improve site performance, or even investigate potential abuse. Your Task: This GZipped Apache log file has 258,074 rows. Each row is an Apache web log entry for the site s-anand.net in May 2024. Each row has these fields:
IP: The IP address of the visitor.
Remote logname: The remote logname of the visitor. Typically ‚Äò-‚Äô.
Remote user: The remote user of the visitor. Typically ‚Äò-‚Äô.
Time: The time of the visit. E.g. [01/May/2024:00:00:00 +0000]. Note that this is not quoted, and you need to handle this.
Request: The request made by the visitor. E.g. GET /blog/ HTTP/1.1. It has three space-separated parts:
(a) Method: The HTTP method. E.g. GET.
(b) URL: The URL visited. E.g. /blog/.
(c) Protocol: The HTTP protocol. E.g. HTTP/1.1.
Status: The HTTP status code. If 200 &lt;= Status &lt; 300, it is a successful request.
Size: The size of the response in bytes. E.g. 1234.
Referer: The referer URL. E.g. https://s-anand.net/.
User agent: The browser used. This will contain spaces and might have escaped quotes.
Vhost: The virtual host. E.g. s-anand.net.
Server: The IP address of the server.
The fields are separated by spaces and quoted by double quotes (‚Äò-‚Äô). Unlike CSV files, quoted fields are escaped via \" and not ‚Äò-‚Äô. (This impacts 41 rows.)
All data is in the GMT-0500 timezone, and the questions are based on this same timezone.
Filter the Log Entries: Extract only the requests where the URL starts with /tamilmp3/. Include only those requests made on the specified 2024-05-23.
Aggregate Data by IP: Sum the ‚ÄòSize‚Äô field for each unique IP address from the filtered entries.
Identify the Top Data Consumer: Determine the IP address that has the highest total downloaded bytes. Report the total number of bytes that this IP address downloaded.
Across all requests under tamilmp3/ on 2024-05-23, how many bytes did the top IP address (by volume of downloads) download?" 
-F ‚Äúfile=@s-anand.net-May-2024.gz‚Äù

I would appreciate your clarification on whether the .gz file should be directly included in the API request or if a Google Drive link should be provided instead.
Thank you for your time and assistance.
Hello Everyone i have cread solution now just for graded 1 and graded 2

a240-43-230-106-58.ngrok-free.app


TDS - Tools for Data Science






ask question there is only one problem in one question like in one question  my code unable to match desired function so giving other function output
The endpoint a240-43-230-106-58.ngrok-free.app is offline.
Now Online check it is online
so I have a doubt whatever output my code gives for the ga question , if i copy it one to one and paste in the ga page and it says correct .Would it mean the same would happen with the evaluation method ? or is there any extra things i must add?
{
‚Äúanswer‚Äù : ‚Äúanswer inside string‚Äù
}



 lakshaygarg654:


GA4 - Question 9: Process PDF Files


A similar issue occurs in GA4 Question 9, where the task involves processing PDF files. While this works perfectly in the local environment, it leads to a 502 Bad Gateway error on Azure. This is due to the relatively long time required to parse and analyze the PDFs, which again exceeds Azure‚Äôs execution time limit.
Moreover, pre-processing the PDF files is not an option because the input varies for each user. Therefore, the PDFs must be processed dynamically, which adds to the delay and contributes to the timeout problem.



@carlton
I watched the last session. In that session, regarding the specific PDF question, you mentioned that the PDF is the same for everyone, so it can be preprocessed beforehand. However, I checked and found that the PDF is actually different for each user. So, we need to fetch it from the API endpoint.
How should we handle the timeout issue on the deployment platform? I even tried upgrading the plan, but it didn‚Äôt help.
@s.anand
@carlton @Jivraj
Also, many questions and doubts were addressed in the last two sessions. I can improve a lot and add the remaining questions, but the constraint is the 31st March deadline. Most students, including myself, will only get time after 30th March due to Viva and OPPE.
It would be really helpful if the TDS team could extend the deadline.
I believe it would strike a good balance‚Äîteam made us wait for the Project 1 results, but extending the Project 2 deadline would make up for that for some extent. Its request nothing else.
Hello sir,
My question is, the questions my endpoint will be evaluated are they the exact same ones with same parameters for my respective email as on the assignment portal ?
Essentially I am trying to understand there are certain questions where I don‚Äôt have to solve the question again and just return the hardcoded answers, would that be correct ?
Anyone please respond and also for ga 1 q 8 for instance where we have:
Let‚Äôs make sure you know how to use JSON. Sort this JSON array of objects by the value of the age field. In case of a tie, sort by the name field. Paste the resulting JSON below without any spaces or newlines.
[{"name":"Alice","age":67},{"name":"Bob","age":53},{"name":"Charlie","age":34},{"name":"David","age":89},{"name":"Emma","age":92},{"name":"Frank","age":37},{"name":"Grace","age":4},{"name":"Henry","age":49},{"name":"Ivy","age":30},{"name":"Jack","age":2},{"name":"Karen","age":2},{"name":"Liam","age":5},{"name":"Mary","age":32},{"name":"Nora","age":56},{"name":"Oscar","age":19},{"name":"Paul","age":22}]

Sorted JSON:
here would question be sent as text only or text + json file seperately?
Can Somebody please share the answers for GA 3 and 4, as I have missed those? Thank you
@carlton @Jivraj @Saransh_Saini
Hi @adi3,
The .gz file would be sent along with the API request. You can even read the file directly without even downloading it.
The API request would be sent containing the question text and the JSON file/files as a binary stream.
Hi @22f3002933
Files are less likely to change, but parameters are. For instance, GA1_Q12, the zip file is less likely to change but the symbols to perform the aggregate on would be changed.
Hi @lakshaygarg654,
Yes for GA4_Q9 the PDF files are different for everyone, but the workflow is exactly the same. Its a basic tabula read, with no particular need of any preprocessing. So, yeah you have to fetch it from the API request.
Unfortunately, we can‚Äôt extend Project 2 deadline, it was released on 3rd of March, and we believe ample amount of time was given for it. If you are lagging far behind in the race, we would encourage you to collaborate with other and get the project done.
Thanks for the answer sir.
I remember being told on the last session, that the question will be exactly the same we have on the assignment portal for my respective case, and the answer on the portal can be the same here as well.
Actually I am exploring a hardcoded answer route where if i return the answer which I already got after solving the questions on the portal (in certain qns with dynamic functions) , so thought of asking if method is alright.
Yes sending your GA answer as text as the JSON response can work if the question was not parameterized. I hope you are aware that parameters for some questions will be changed, resulting in different answers.
Thanks for your reply @Saransh_Saini
I‚Äôve figured out the solution to that particular question.
The deadline is still a concern, as many issues were only resolved during recent sessions‚Äîsimilar to the project 1 workflow‚Äîand This time there are many other things in the pipeline ( viva‚Äôs and oppe‚Äôs )
Anyway, I will complete this course with valuable learnings, but many others have been seriously affected by it.
Hi @Saransh_Saini @carlton ,
In the sample curl command
i.e.
curl -X POST "https://your-app.vercel.app/api/" \
  -H "Content-Type: multipart/form-data" \
  -F "question=Download and unzip file abcd.zip which has a single extract.csv file inside. What is the value in the "answer" column of the CSV file?" \
  -F "file=@abcd.zip"

It is given that only one file arguement is passed , can there be a usecase where multiple files are sent , for example GA-5 10th question Image reconstruction where there could be one file be the image another could be separate file with mapping, Although mapping can be given with question as well,
But still can you please confirm if there will be only one file or there can be multiple files send to API?
Multiple files can be sent in the API requestion. They would be sent as a list of files.
But in q10 will it be passed as the part of question only??
@carlton in GA 5 q10 the mappings table is sent as part of the question text or any other separate file?
@Jivraj @Saransh_Saini
Query about Week2 Q3 and  Q7 Publishing a page or action takes time to reflect the site or action performed in github. how to solve this timing issue ? Github repo creation and file /action addition completes immediately but publishing of file /action takes time causing the resulting URL to return 404 for a long time before it returns the correct 200 status and content in response.
Hello Sir,
I want to express my gratitude for the opportunity to work on this project. I have developed a mini chatbot backend using vicky_server.py, which handles question matching and execution internally, producing appropriate responses. My mini chatbot is capable of creating its own API using REST and can manage tasks such as image compression, repository management, workflows, and web scraping related to graded assignments. It can even calculate total marks for subjects like physics and convert PDFs into markdown content. Additionally, it is capable of downloading the Llama model and creating a tunnel using ngrok. Essentially, it can address the first four assignment questions.
However, there are some limitations to this project. Currently, it processes my local files instead of the uploaded PDFs. I am working on resolving this issue, but I have some confusion regarding the internal handling of uploaded files. When I pass a PDF or file through an upload method, how should the system proceed? I want to ensure that the file is treated as a PDF for the user rather than just being referenced as ‚Äúquestion.pdf.‚Äù How can I effectively manage this problem?
Furthermore, there is an issue with question matching. At times, the system incorrectly identifies questions containing the word ‚Äúcode‚Äù and executes first.py for GA1.
Thank you for the opportunity to work on this project!
Best regards,
vicky kumar
@s.anand @carlton @Saransh_Saini
my model at Vicky kumar tds
In GA5_Q10 the mappings would be sent as either a HTML or Markdown file along with the image. Both files would be send as a List.
@carlton
I am bit confused about  answer evaluation process. Can you tell which one  is correct process.
1st process ( I used json.dumps() to get my_response as json formatted string)
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image depicts a snippet of Python code and its output within what appears to be a coding environment (likely a Jupyter Notebook or similar). \n\n**Code Snippet:**\n* **Import Statement:** `import json` indicates that the `json` library is being imported.\n* **String Assignment:** `my_response = "{ \\"answer\\": \\"26272\\" }"` assigns a JSON-formatted string to the variable `my_response`.\n* **JSON Parsing and Printing:** `print(json.loads(my_response)["answer"])` parses the JSON string into a Python dictionary using `json.loads()`, then accesses the value associated with the key "answer" and prints it.\n\n**Output:**\n* Below the code is the printed output: `26272`. This confirms that the code successfully parsed the JSON string and extracted the value assigned to the "answer" key. \n\n**Environment Cues:**\n* The left side of the code snippet has a play button, suggestive of an interactive coding environment.\n* The output is displayed in a separate output area below the code.image726√ó224 4.68 KB
2nd process ( This one is Json object)
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a snippet of Python code and its output.\n* **Code:** The code imports the `json` library and defines a dictionary named `my_response`. This dictionary contains one key-value pair: `"answer"` with the value `"26272"`. The code then prints the value associated with the key `"answer"` in the `my_response` dictionary.\n* **Output:** Below the code, the output of the `print` statement is displayed: "26272". This confirms that the code successfully accessed and printed the value associated with the "answer" key.\n* **Environment:** The code appears to be executed in an interactive Python environment, potentially a Jupyter Notebook, as indicated by the "[14]" at the beginning, which likely represents the cell number.\n* **Color scheme:** The code is highlighted with a dark theme, while the output is in a light color.\nimage514√ó193 3.61 KB
or both are incorrect?
This is one more example of 1st process after json.loads() it gave me correct format for assignment portal answer:
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a close-up screenshot of computer code, likely Python, displayed in a text editor or IDE. The code appears to be related to sentiment analysis using the OpenAI API.\n\n**Specific Elements:**\n\n* **Code:** The dominant element is the code itself. It includes variable assignments, function definitions, API calls, and error handling.\n* **Import Statements:** The code begins with an `import json` statement.\n* **API URL:** There\'s a line defining the OpenAI API endpoint for chat completions: `"https://api.openai.com/v1/chat/completions"`\n* **Headers:** The code defines headers including `"Authorization"` (likely an API key) and `"Content-Type"` (set to `"application/json"`).\n* **Data Payload:** A `data` structure is defined, which includes a `model` (set to `"gpt-4o-mini"`) and a `messages` list.\n* **System Message:** The `messages` list contains a `"system"` role message instructing the model to analyze sentiment as "GOOD", "BAD", or "NEUTRAL".\n* **User Message:** There is a `"user"` role message whose content is partially visible.\n* **HTTP Request:** The code uses the `httpx` library to make a POST request to the OpenAI API with the defined data and headers.\n* **Error Handling:** A `try...except` block is used to handle potential exceptions during the API call.\n* **JSON Parsing:** The code parses the JSON response from the API using `response.json()`.\n* **Function Definition:** A function `analyze_sentiment()` is defined, likely to encapsulate the API call and sentiment analysis logic.\n* **Main Execution Block:** The `if __name__ == "__main__":` block suggests the code\'s main execution point.\n* **Printing Response:** The code includes a line to print the `"answer"` field from the JSON response.\n\n**Color & Style:**\n\n* **Color Scheme:** The code is displayed with a dark background and colorful syntax highlighting, common in many code editors.\n* **Font:** A monospaced font is used for the code, enhancing readability.\n\n**Overall:**\n\nThe image showcases a Python script that leverages the OpenAI API to perform sentiment analysis on given text. It demonstrates the process of constructing an API request, handling the response, and extracting relevant information.image927√ó466 20.8 KB
This is one more example of 2nd process without use of json.loads() it gave me correct format for assignment portal answer:
Here\'s a detailed description of the image:\n\n**Overall:**\n\nThe image shows a snippet of Python code displayed in a code editor or IDE. The code appears to be designed to perform sentiment analysis using an API.\n\n**Key Elements:**\n\n1. **Import Statements:** The code begins with `import json` and `import httpx`, indicating that it uses these libraries for JSON handling and making HTTP requests.\n2. **Variable Assignments:**\n * `my_response` is assigned a dictionary containing a key `"answer"` with a string value that seems to be a prompt or instruction for the sentiment analysis task.\n * `url` is set to the API endpoint: `https://api.openai.com/v1/chat/completions`.\n * `headers` is defined as a dictionary including authorization and content type information.\n * `data` is a dictionary containing the `model` parameter set to `"gpt-4o-mini"` and a `messages` list that defines the conversation context.\n3. **Sentiment Analysis Function (`analyze_sentiment`)**: This function constructs a request to the OpenAI API.\n4. **API Request**: The code uses `httpx.post()` to send a POST request to the OpenAI API endpoint with the specified URL, JSON data, and headers.\n5. **Error Handling**: Includes a `try...except` block to catch exceptions during the API request and print error messages.\n6. **Output**: The code prints the value associated with the `"answer"` key in the `my_response` dictionary.\n\n**Specific Details:**\n\n* The OpenAI API key is represented as `"Bearer dummy_api_key"`, indicating that the key needs to be replaced with a valid key for actual execution.\n* The prompt within the `messages` list instructs the model to analyze the sentiment of a given text and classify it as GOOD, BAD, or NEUTRAL.\n* The function `analyze_sentiment` is designed to handle the entire sentiment analysis process, from constructing the API request to processing the response.\n\n**In summary,** the image displays a Python script for performing sentiment analysis using the OpenAI API. The code is well-structured with clear variable assignments, a defined function, and error handling.image984√ó476 19.7 KB
@Saransh_Saini @carlton @Jivraj
The vercel api question in GA2, does the endpoint that we give you have to be a vercel url or just hosting it in anyway is alright?
@Saransh_Saini the field name ‚Äúfile‚Äù would remain same, I mean it won‚Äôt be ‚Äúfiles‚Äù right?
I am trying to create a student account on Microsoft Azure using my IIT Madras email ID (23f2004705@ds.study.iitm.ac.in), but I am encountering an issue. The system is showing a message that my email domain is not currently registered with them, and it is asking me to use another verification method.
@carlton @Jivraj Could you please guide me on how to proceed with the verification or if there is an alternative method to access Azure‚Äôs student benefits?
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a screenshot of a Microsoft Azure academic verification process. It appears to be a request for information to confirm educational status.\n\n**Key Elements:**\n\n* **Header:** The top left corner features the Microsoft Azure logo. The top right corner has an email address: "21MZ0470S@ds.study.itmu.ac.in" and "Sign out" options.\n* **Notification:** A light blue notification box at the top states: ‚ÄúYour email domain is not currently registered with us. You can choose another verification method.‚Äù\n* **Heading:** The section ‚ÄúAcademic Verification‚Äù is prominently displayed.\n* **Instructions:** Below the heading is a textual explanation guiding the user. It requests to enter the name and date of birth as per school records. It also asks for the school‚Äôs country and name.\n* **Purpose:** The text clarifies the email address will be used for communication during the verification process. It also requests the school-provided email address.\n\n**Color Palette:** The screenshot uses a color scheme dominated by shades of grey, light blue, and white, typical of Microsoft Azure interfaces.\n\n**Context:** The screenshot suggests a user attempting to verify their academic credentials with Microsoft Azure, possibly for access to educational resources or benefits.Screenshot 2025-03-29 1458011891√ó451 158 KB
Same goes with me also when I try for Academic Verification .
@carlton @Jivraj  Please look into it .
sir im having the same issue, i have tried so many times.
sir azure was asking me to fill in the last name which i didnt register  in my academic records.
i have just used my first name while starting this course . can this be a problem while verifying  this azure bcz it says last names field is must to fill in. @carlton @Jivraj
sir if the last name was not the issue then pls find us a soln as soon as possible bcz the deadline is in just two days ‚Ä¶
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a screenshot of an academic verification form, likely part of an application process for Microsoft.\n\n**Key Elements & Details:**\n\n* **Title:** "Academic Verification" is prominently displayed at the top.\n* **Instructions:** Text instructions explain the process, requesting the user\'s name as per school records, country, and date of birth. It also mentions email verification.\n* **Fields:** The form has several input fields:\n * **First Name:** Pre-filled with "shashikumar".\n * **Last Name:** Is an empty, required field.\n * **Country:** Has "India" selected in a dropdown menu.\n * **School Name:** Pre-filled with "Indian Institute Of Technology Madras (Chennai, Tamil Nadu)".\n * **Date of Birth:** An empty field awaiting input.\n* **Error Indicator:** A red text label below the "Last Name" field states "This field is required."\n* **Additional Text:** Text notes that the school name will help Microsoft with verification and that if a country is not listed, the offer is not available in that region.\n* **Link:** A "Learn More" link is provided for further information regarding unavailable regions.\n* **Header:** There is a header saying ‚ÄúYour email domain is not currently registered with us. You can choose another verification method.‚Äù\n \n\n**Overall, the image captures a standard verification form used to confirm academic credentials as part of an application process.**tds972√ó906 12.2 KB
In Web Scrapping Question The Website will change or it will be same website but the parameters will change of scrapping? @Saransh_Saini @carlton @Jivraj
bro ur also direct entry diploma student?  bcz im also having the same issu..
i guess the direct entry to diploma students have this problem in comman
Was the project hosting session recording posted? Carlton sir said he would post it. @carlton
Hi @lakshaygarg654
In both the scenarios you laid out, the second implementation is correct. Your response to our API request should be a JSON object {"answer" : "YOUR RESPONSE AS STRING"}. In any case the value of the "answer" key should be a string.
Hosting it anywhere is fine. Try to deploy on vercel first, if that doesn‚Äôt succeed you can use any other hosting technique.
This is a basic prototype function we would be using to send requests to your URL.
def run(question, file_path):
    url = "http://127.0.0.1:8080/api"
    questions = {'question': question}
    files = [
        ('file', open("abcd.zip", 'rb')),
        ('file', open("dcba.img", 'rb'))
    ]
    response = requests.post(url, data=questions, files=files)
    return response

or
curl -X POST "http://127.0.0.1:8080/api" \
  -H "Content-Type: multipart/form-data" \
  -F "question=question" \
  -F "file=@abcd.zip" \
  -F "file=@dcba.img"

NOTE: This is not the evaluation script.
HI @ripusudan
This has been a problem with all direct entry students. Unfortunately, there is no way we can help you with this problem. The best way out is asking a friend who is not a TDS student for this term to create a Azure VM for you.
Yes the websites would be the same.



 Saransh_Saini:

This is a basic prototype function we would be using to send requests to your URL.
def run(question, file_path):
    url = "http://127.0.0.1:8080/api"
    questions = {'question': question}
    files = [
        ('file', open("abcd.zip", 'rb')),
        ('file', open("dcba.img", 'rb'))
    ]
    response = requests.post(url, data=questions, files=files)
    return response



I couldn‚Äôt find this function on the Project Doc and I made the project based on the curl function calling.



 Saransh_Saini:

curl -X POST "http://127.0.0.1:8080/api" \
  -H "Content-Type: multipart/form-data" \
  -F "question=question" \
  -F "file=@abcd.zip" \
  -F "file=@dcba.img"



At this moment it can‚Äôt be changed as I am occupied with other things. Please keep the question parameter as ‚Äúquestion‚Äù and file parameter as ‚Äúfile‚Äù in the evaluation which is on the Project 2 page and the content type as multipart/form-data.
To clarify if I can handle any one of these 2 methods, I will be fine?
Edit:
Just now discovered that the field names are indeed ‚Äúquestion‚Äù and ‚Äúfile‚Äù only in both the cases. Sorry for the oversight.
@carlton @Saransh_Saini @Jivraj
@carlton @Saransh_Saini @Jivraj
I have a few queries. Even a yes/no response for each would suffice.
GA1:
Q13 - Use GitHub: Since the parameter is just my email, this question WILL NOT be tested against any other email, right? So I can just have a repo with my email in it, right?
GA2:
Q2 - Compress an image: Should my app‚Äôs response be like this
{
     "answer": "base64_encoding_of_compressed_image"
}

Q3 - Host your portfolio on GitHub Pages, Q7 - Create a GitHub action, Q8 - Push an Image to Docker Hub: Similar to GA1 Q13, these too have my email or roll number as parameter. These too WILL NOT be checked against any other email, right?
GA3:
Can you please give an example of how questions of this GA will be sent in the request, especially any of Q1 or Q2 or Q5 or Q6 or Q7 or Q8 which have code-blocks containing text crucial to the question? I just want to decide whether regex or function-calling would be more appropriate here.
GA4:
The links to the website are hyperlinks in the questions. When the question will be sent to my app, will the link of the website to be scraped be written as a full link in the question itself or will it be sent in some other way?
GA5:
No particular questions at the moment.
Please help me out by answering these asap
if you use github student account then no need to verfiy this and you can directly verify through github student account and got credit  i think 150 dollar so you can chose this path also
Hello @22f3001307, there is an error in the code that needs to be fixed as part of the question:
image = Image.open(list(files.upload().keys)[0]
with
image = Image.open(list(files.upload().keys())[0])
Sir but i am not a direct entry students
@Saransh_Saini
As per your reply time, I was in TDS session at that time.
And asked same doubt, @Jivraj said 1st implementation they will use. 
Session link ( watch at 26:55)
Kindly clarify this.
What Jivraj agreed was stringifying the answer and putting it in as the value of the "answer" key in the JSON object.
{ "answer" : "YOUR_STRINGIFIED_ANSWER" }
Just check the Project 2 page on the portal. It‚Äôs clearly mentioned a JSON object has to sent not a strigified version of the entire JSON object.
Here\'s a point-by-point description of the image:\n\n* **Content:** The image displays a JSON object.\n* **Structure:** The JSON object contains a single key-value pair.\n* **Key:** The key is "answer".\n* **Value:** The value associated with the key "answer" is the string "1234567890".\n* **Background:** The background is dark, likely black or a very dark shade of blue/grey.\n* **Text Color**: The JSON is written in white.\n* **Context:** There is text at the top of the image that reads, "The response must be a JSON object with a single text field: answer that can be directly entered in the assignment. For example:". This indicates the image is providing an example of the expected JSON format.\n\n\n\n```json\n{\n"answer": "1234567890"\n}\n```image1022√ó277 11.6 KB
@Jivraj kindly add-in your thoughts on this.
Response from api should be a string, which if we load using json.loads it should load json object with answer key.



 22f3000819:

Q13 - Use GitHub: Since the parameter is just my email, this question WILL NOT be tested against any other email, right? So I can just have a repo with my email in it, right?


Check with other student if they have a different email then it is a parameter and can change.



 22f3000819:

Q2 - Compress an image: Should my app‚Äôs response be like this
{
     "answer": "base64_encoding_of_compressed_image"



This is correct, make sure you test decoding base64 string before deadline.



 22f3000819:

Q3 - Host your portfolio on GitHub Pages, Q7 - Create a GitHub action, Q8 - Push an Image to Docker Hub: Similar to GA1 Q13, these too have my email or roll number as parameter. These too WILL NOT be checked against any other email, right?


Same answer as Q13 GA1



 22f3000819:

Can you please give an example of how questions of this GA will be sent in the request, especially any of Q1 or Q2 or Q5 or Q6 or Q7 or Q8 which have code-blocks containing text crucial to the question? I just want to decide whether regex or function-calling would be more appropriate her


We will take Q1 in this format, which is just copy pasting from portal```
One of the test cases involves sending a sample piece of meaningless text:
au7BK3 33 H 5   lKz6y4n  oQmbgoX 0  hNW3JH  68Q1u

Write a Python program that uses httpx to send a POST request to OpenAI‚Äôs API to analyze the sentiment of this (meaningless) text into GOOD, BAD or NEUTRAL. Specifically:

Make sure you pass an Authorization header with dummy API key.
Use gpt-4o-mini as the model.
The first message must be a system message asking the LLM to analyze the sentiment of the text. Make sure you mention GOOD, BAD, or NEUTRAL as the categories.
The second message must be exactly the text contained above.

This test is crucial for DataSentinel Inc. as it validates both the API integration and the correctness of message formatting in a controlled environment. Once verified, the same mechanism will be used to process genuine customer feedback, ensuring that the sentiment analysis module reliably categorizes data as GOOD, BAD, or NEUTRAL. This reliability is essential for maintaining high operational standards and swift response times in real-world applications.
Note: This uses a dummy httpx library, not the real one. You can only use:

response = httpx.get(url, **kwargs)
response = httpx.post(url, json=None, **kwargs)
response.raise_for_status()
response.json()


[quote="22f3000819, post:173, topic:169029"]
The links to the website are hyperlinks in the questions. When the question will be sent to my app, will the link of the website to be scraped be written as a full link in the question itself or will it be sent in some other way?
[/quote]

[quote="22f3000819, post:173, topic:169029"]
The links to the website are hyperlinks in the questions. When the question will be sent to my app, will the link of the website to be scraped be written as a full link in the question itself or will it be sent in some other way?
[/quote]

Full link will be part of question.
Thanks for the help @Jivraj sir
Dear Sir
Is there any limite for request on tokens. because now my model does not generate any output. for any question also not showing any error. could you please explain.
When i hit  request on this (curl -X POST ‚Äúhttp://localhost:8000/api/‚Äù 
-H ‚ÄúContent-Type: multipart/form-data‚Äù 
-F "question=Let‚Äôs make sure you can write formulas in Google Sheets. Type this formula into Google Sheets. (It won‚Äôt work in Excel)
=SUM(ARRAY_CONSTRAIN(SEQUENCE(100, 100, 1, 9), 1, 10))
What is the result?") this is not showing any kind of output or error not only on this request any other also.
As per the portal, we have to return a JSON object as a response from the API. However, if we load a JSON object directly using json.load(), it will throw an error. We need to first convert it into a JSON string and then load it using json.loads( ). For clarity I add image below.
This question has been stretched for too long‚Äîit‚Äôs not that big.
I guess @Jivraj is right.
Here\'s a detailed description of the image:\n\n**Overall Content:** The image displays a Python code snippet within what appears to be a Jupyter Notebook or similar interactive coding environment. It shows code that attempts to load a JSON object and extract a value. The code initially produces a `TypeError` and the corrected version successfully prints a value.\n\n**Key Elements and Observations:**\n\n1. **Code Snippet 1 (Error):**\n * **Import Statement:** `import json` imports the JSON library.\n * **JSON Object:** `my_response = {"answer": "26272"}` creates a Python dictionary representing a JSON object.\n * **Attempt to Load & Access:** `print(json.loads(my_response)["answer"])` attempts to parse the dictionary (which is *already* a Python object) as JSON using `json.loads()` and then access the "answer" key.\n * **Error Message:** A `TypeError` is displayed, indicating that the `json.loads()` function expects a string, bytes, or bytearray as input, but it received a dictionary.\n\n2. **Code Snippet 2 (Corrected):**\n * **`json.dumps()` usage**: The code has been modified to include `my_response= json.dumps(my_response)`.\n * **Correct Execution:** This snippet successfully prints the string `"26272"`, extracted from the "answer" key of the JSON object.\n\n3. **Environment:**\n * The code is within a Jupyter Notebook or similar environment (indicated by the `[1]` and `[2]` prefixes).\n * Output: The output section shows `"26272"` after the code correction.\n\n**In summary:** The image illustrates a common error when working with JSON in Python‚Äîtrying to parse an already parsed JSON object. The corrected code demonstrates the use of `json.dumps()` to convert the Python dictionary to a JSON string before parsing it with `json.loads()`.image562√ó700 23.4 KB
@Jivraj @Saransh_Saini
Hi,
while trying to creating podman image of my application, it is being created as 7.2GB file. Any idea what should i do?
Also, I can sign up for azure student pack, are there any way to deploy my application?
Thanks
Subject: Request for Uniform Evaluation Process in Project 2 - TDS Solver.
Hello @s.anand @carlton @Jivraj @Saransh_Saini sir.
We truly appreciate the effort you put into designing and evaluating our graded assignments and projects. We understand that any five random questions will be selected for evaluation, and we fully respect this approach.
However, we kindly request that the same set of five questions be used for all students to ensure a uniform and unbiased evaluation process. This way, the difficulty level remains consistent across all evaluations, providing a fair assessment of our understanding.
Thank you for considering our request. We appreciate your guidance and support.
Best regards,
Digvijaysinh Chudasama.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a set of instructions for a data analysis task, specifically focused on extracting data from the IMDb website. It also includes a visual example of the expected JSON output format.\n\n**Key Elements:**\n\n1. **Heading:** "Your Task" in a prominent font.\n2. **Instructions (Numbered List):** A list detailing the steps for the task:\n * **Source:** Utilizing IMDb\'s search page (`https://www.imdb.com/search/title/`)\n * **Filter:** Filtering titles with ratings between 2 and 8.\n * **Format:** Extracting ID, title, year, and rating for up to 25 titles. The task indicates the movie ID is part of the URL after "tt" in the `href` attribute.\n3. **JSON Example:** A code snippet presenting the desired structure for the extracted data in JSON format:\n * An array containing JSON objects.\n * Each object includes keys: "id", "title", "year", and "rating".\n * Two example objects with placeholder values (e.g., "Movie 1", "2021", "5.8") are provided.\n * An indication "// ... more titles" suggests that the complete array would contain more objects.\n4. **Submission Instruction:** A final instruction "4. Submit: the JSON data in the text box below.".\n\n**Color Scheme & Style:** The image is a dark-themed screenshot with white text and code highlighting. This is typical of development or documentation screenshots.\n\n\n\nIn essence, the image is a task assignment for a data analyst, detailing how to scrape data from IMDb and format it into a specific JSON structure.image698√ó405 17.4 KB
For this question, The answer which we get is not same as the expected answer which the portal fetch through proxy fetch
model='gemma3:27b' created_at='2025-06-13T08:39:53.755347195Z' done=True done_reason='stop' total_duration=52695576331 load_duration=18117030 prompt_eval_count=323 prompt_eval_duration=18415143807 eval_count=353 eval_duration=34261344118 message=Message(role='assistant', content="Here's a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a snippet of code, likely JavaScript, within a code editor. The code appears to be designed to fetch data from IMDb (Internet Movie Database) and extract information about a movie or TV show. \n\n**Key Elements & Details:**\n\n* **Code Structure:** The code utilizes `async/await` for asynchronous operations, indicating that it's fetching data from a network.\n* **IMDb URL:** A URL containing ‚Äúwww.imdb.com/search/title/user_rating‚Äù is present, suggesting that the code searches for movie or TV show information on IMDb and retrieves user ratings.\n* **Data Parsing:** The code utilizes `DOMParser` and `querySelector` to parse the HTML content retrieved from IMDb and extract specific elements like `id`, `title`, `year`, and `rating`. \n* **Variable Assignment:** Variables `m`, `b`, `S`, and `w` store extracted data.\n* **Return Object:** The code concludes with a `return` statement that creates an object containing the extracted `id`, `title`, `year`, and `rating`.\n* **Error Handling:** The code includes error handling for when it's unable to fetch the data from IMDb, throwing an error message with the status code.\n* **Text Color Coding:** The code is displayed with syntax highlighting, where keywords, variables, and strings are displayed in different colors for readability.\n* **Background:** The background is a dark blue/grey color, typical for code editors.\n\n**In essence, the image showcases a code snippet for web scraping IMDb data to extract movie/TV show details.**", thinking=None, images=None, tool_calls=None)image733√ó201 38.2 KB
let h = await fetch('/proxy/‚Ä¶) ------------&gt; here
@Jivraj @carlton sir because of this mismatch we have to edit manually after clicking check button again and again
please guide me how to solve this
@carlton @Saransh_Saini @Jivraj I just wanted to bring to your attention that in GA4 question 2, the answer evaluation script expects the movie title as ‚Äú17. Kraven: The Hunter‚Äù but it is actually listed on the IMDb page as ‚Äú17. Kraven the Hunter‚Äù, resulting in the correct one being marked wrong.
No questions here just wanted to bring it to attention so that it does not affect the project evaluation script.
Its unusual to have a docker container worth 7 GBs of space. Here is what you can do

Remove unused libraries from your requirements.txt. Sometimes having resource demanding libraries like SentenceTransformers can install large sub-dependency packages.
Exclude your virtual environment folder from the container creation
Create a .containerignore file to have an exception for those folders you want to skip.
Clear your package cache and any vscode cache you might have.

Hi @21f2000588,
Your concerns sound genuine and we will put this point up during our discussion sessions. Whatever would be the decision we will inform you guys.
Regards,
Saransh Saini
In the previous replies, you‚Äôve mentioned that for Github questions ‚Üí actions, pages (GA2) that if the email changes for everyone it means that its parameterised. However, in one of the live sessions this week, Carlton had mentioned that for these questions, it wont be parameterised as this is very individual specific. The same goes for the docker hub question of GA2 as well. KIndly clarify on the same.
For GA2 Q9 ‚Üí I have given an input file via post request and my fastapi server can handle get requests and its as follows. Kindly confirm if my url is good to go for this specific question.
image1932√ó1748 225 KB
@carlton @Saransh_Saini @Jivraj
@Jivraj @Saransh_Saini
Sir, in GA4 Question 7, the portal gives the boundary of ultra-new user as the exact time when it was opened, right?
Here is a detailed description of the image:\n\n* **Content:** The image displays a dark-themed interface, likely from a web application or data analysis tool.\n* **Text at Top:** The top portion lists three points:\n * "Competitive Intelligence: Stay updated on emerging trends within local developer communities and adjust talent acquisition strategies accordingly."\n * "Efficiency: Automating repetitive data collection tasks, frees up time for recruiters to focus on engagement and relationship-building."\n * "Data-Driven Decisions: Leverage standardized and reliable data to support strategic business decisions in recruitment and market research."\n* **Input Field:** Below the points, there is a text input field with the prompt: "Enter the date (ISO 8601, eg. \'2024-01-01T00:00:00Z\') when the newest user joined GitHub."\n* **Search Instruction:** Under the input field, there\'s a line of text providing search instructions: "Search user creation: and followers: filters, sort by joined descending (fetch the first url), and enter the created_at field. Ignore ultra-new users who JUST joined, ie. after 3/18/2025, 7:21:18 PM."\n* **Color Scheme:** The overall color scheme is dark with white text, commonly found in interfaces designed to reduce eye strain.\n\nIn essence, the image showcases a tool or section within an application focused on GitHub user data analysis, likely for recruitment or market research purposes. It prompts the user to input a date to filter and sort user data based on the time they joined GitHub.image1602√ó275 34.1 KB
So, will this boundary for ultra-new user be sent as parameter in the question or can my app use datetime.now() to set the ultra-new user boundary?
Hi @22f3000819
Thanks for bringing this into light, we‚Äôll keep this in mind while creating the evaluation script.
This will be sent as a parameter in along with the API request.
Okay sure, thank you so much. I hope you take this into consideration.
Thanks and Regards
Digvijaysinh Chudasama
@Jivraj @Saransh_Saini @carlton
For GA4, Q9 on Tabula - Tabula requires Java Runtime to install. How to deploy it on Vercel?
@Jivraj @Saransh_Saini
Please give us some clarification on this query
@Jivraj @Saransh_Saini @carlton please give us some clarification on this query.
@Jivraj @Saransh_Saini please clarify
please provide clarification on this as deadline is close.
@carlton , @Saransh_Saini , @Jivraj
@jivraj @Saransh_Saini
same issue‚Ä¶ What are your final thoughts?
sir GA10 i have designed it as this output of that quesiton is Successfully reconstructed the image. Saved to: E:\data science tool\GA5\output\reconstructed_jigsaw.png
is this correct or we have to show image directory or folder or image
You have to return the image output as base64 encoded data
model='gemma3:27b' created_at='2025-06-13T08:40:56.39918518Z' done=True done_reason='stop' total_duration=57239682309 load_duration=21154018 prompt_eval_count=323 prompt_eval_duration=18613274424 eval_count=395 eval_duration=38602004010 message=Message(role='assistant', content="Here's a detailed description of the image:\n\n**Overall Impression:**\n\nThe image depicts a futuristic cityscape at night, characterized by towering skyscrapers and a network of elevated highways. The scene is vibrant with neon lights in shades of blue, pink, and purple, creating a cyberpunk aesthetic.\n\n**Key Elements:**\n\n* **Skyscrapers:** The city is densely populated with extremely tall, futuristic skyscrapers. The buildings have complex architectural designs and are illuminated with bright neon lights.\n* **Elevated Highways:** A network of multi-tiered, elevated highways and roadways cuts through the city, with trails of light from vehicles traveling along them.\n* **Vehicles:** Fast-moving vehicles with light trails are visible on the highways, suggesting a high-tech transportation system.\n* **Lighting:** The image is dominated by neon lights, creating a vibrant and energetic atmosphere. There's a mix of blue, pink, and purple hues, with some white and yellow lights.\n* **Atmosphere:** A slight haze or fog obscures the more distant buildings, adding to the futuristic atmosphere.\n* **Flying Vehicles:** Several sleek, futuristic flying vehicles are visible in the sky, further emphasizing the advanced technology of the city.\n* **Billboards/Digital Displays:** Large digital displays and billboards are integrated into the skyscrapers, showcasing advertisements and information.\n\n**Color Palette:**\n\nThe image is primarily composed of cool colors like blues and purples, with accents of pink and white. The overall color palette is vibrant and creates a sense of energy and excitement.\n\n**Style & Tone:**\n\nThe image has a distinctly cyberpunk style, characterized by advanced technology, urban density, and a futuristic aesthetic. The tone is energetic and optimistic, suggesting a thriving and technologically advanced society.\n\n\n\nIn summary, this image presents a visually stunning and immersive depiction of a futuristic city with a focus on advanced technology, vibrant lighting, and urban density.", thinking=None, images=None, tool_calls=None)reconstructed_jigsaw500√ó500 476 KB
through this i got this image in my file output directly
and is your internal server capable of extracted from given location or we have to handle this internally
I am going to clarify this once and for all
The response should be a JSON Object with the value of the "answer" key as a string.
{ "answer" : "YOUR_ANSWER_AS_STRING" }

This is the way we are expecting your responses.
However, due to the heavy confusion among students and will be considering responses with entire JSON objects stringified. We don‚Äôt want anyone to loose their marks for such a miniscule error.
So,
"{\"answer\": \"YOUR_ANSWER\"}"

is also valid.
means {‚Äòanswer‚Äô:‚ÄòE://data science too//GA5/output/vicky.jpg‚Äô} right or we have to do you said output as base64
@Algsoch We should receive your images as base64 encoded within your response JSON object.
No, we won‚Äôt be able to access your images from your local machine address.
i cannot use github as file goes to 18gb what is solution for it as you are asking for github
but i created repo there is only main file vicky_server.py,copy_tds.py
can you explain how to solve this problem and i will use ngrok so we have to open that till you check and how i know that you will check my api that time or when
as vercel don‚Äôt supported it
@Saransh_Saini @Jivraj @carlton
Sir, I have an issue in GA5 Q3
What is the number of successful GET requests for pages under /telugu/ from 11:00 until before 20:00 on Mondays?
For this, I have used two python scripts to get the answer, one written completely by me and another from someone else‚Äôs solution; both give the same answer - 2698
However, the portal says it‚Äôs incorrect. No modifications resulting in different answer are being accepted either and the modifications themselves seem to break the bounds of the question.
Please check the scripts and tell me where I am going wrong.
My script:
import subprocess
from datetime import datetime

def isDay(dtobj, day):
  return dtobj.weekday() == day

def isTime(dtobj, l, u):
  return l &lt;= dtobj.hour &lt; u

step1 = subprocess.run("cat data | grep -i 'GET /telugu/'", capture_output=True, shell=True, text=True)
subprocess.run("rm -f forstep2.txt", shell=True)
with open('forstep2.txt', 'a') as f:
  for line in step1.stdout.splitlines():
    try:
      status = int(line.split()[8])
    except Exception as e:
      status = 400
    if 200 &lt;= status &lt; 300:
      f.write(line + '\n')
step2 = subprocess.run("cat forstep2.txt | cut -d ' ' -f4", capture_output=True, shell=True, text=True)
count = 0
for line in step2.stdout.splitlines():
  log_datetime = datetime.strptime(line.strip('['), "%d/%b/%Y:%H:%M:%S")
  if(isDay(log_datetime, 0) and isTime(log_datetime, 11, 20)):
    count += 1

count

I had extracted and uploaded the data after extraction using gzip into colab and then executed the script.
The other script:
import pandas as pd
import gzip
import re
import os
from datetime import datetime
import hashlib
from google.colab import files

# Function to compute SHA-256 hash
def compute_hash(text):
    return hashlib.sha256(text.encode()).hexdigest()

# Function to parse Apache log entries
def parse_log_line(line):
    log_pattern = (r'^(\S+) (\S+) (\S+) \[(.*?)\] "(\S+) (.*?) (\S+)" (\d+) (\S+) "(.*?)" "(.*?)" (\S+) (\S+)$')
    match = re.match(log_pattern, line)
    if match:
        return {
            "ip": match.group(1),
            "time": match.group(4),
            "method": match.group(5),
            "url": match.group(6),
            "protocol": match.group(7),
            "status": int(match.group(8)),
            "size": match.group(9),
            "referer": match.group(10),
            "user_agent": match.group(11),
            "vhost": match.group(12),
            "server": match.group(13)
        }
    return None

# Upload file
uploaded = files.upload()
file_path = list(uploaded.keys())[0]  # Get uploaded file name

# Load and parse the log file
def load_logs(file_path):
    if not os.path.exists(file_path):
        print(f"Error: File '{file_path}' not found.")
        return pd.DataFrame()

    parsed_logs = []
    with gzip.open(file_path, 'rt', encoding='utf-8') as f:
        for line in f:
            parsed_entry = parse_log_line(line)
            if parsed_entry:
                parsed_logs.append(parsed_entry)
    return pd.DataFrame(parsed_logs)

# Convert time format
def convert_time(timestamp):
    return datetime.strptime(timestamp, "%d/%b/%Y:%H:%M:%S %z")

df = load_logs(file_path)

if not df.empty:
    df["datetime"] = df["time"].apply(convert_time)
    df["day_of_week"] = df["datetime"].dt.strftime('%A')
    df["hour"] = df["datetime"].dt.hour

    # Filter conditions
    filtered_df = df[
        (df["method"] == "GET") &amp;
        (df["url"].str.startswith("/telugu/")) &amp;
        (df["status"] &gt;= 200) &amp; (df["status"] &lt; 300) &amp;
        (df["day_of_week"] == "Monday") &amp;
        (df["hour"] &gt;= 11) &amp;
        (df["hour"] &lt; 20)
    ]

    # Compute hash of the result
    result_hash = compute_hash(str(len(filtered_df)))

    # Output the count and hash
    print("Successful GET requests for /telugu/ on Mondays (11:00-7:59 AM):", len(filtered_df))
else:
    print("No log data available for processing.")

Both give the same output: 2698. Please help me identify the error, if any.
can anyone help me ,
Here\'s a detailed description of the image:\n\n**Overall:**\n\n* The image is a screenshot of an online academic verification form, likely part of an application process (possibly for Microsoft). It appears to be a data input field where a user is asked to enter their academic details.\n\n**Specific elements & Data Input Fields:**\n\n* **Header/Notification:** At the top, there‚Äôs a message stating "Your email domain is not currently registered with us. You can choose another verification method." suggesting a potential issue with email verification.\n* **Section Title:** "Academic Verification" is a bolded section title.\n* **Instructions:** Beneath the title, text instructs the user to enter their name and school details as per school records.\n* **Data Entry Fields:**\n * **First Name:** Filled with "VIKASH".\n * **Last Name:** Filled with "PRASAD".\n * **Country:** A dropdown menu is set to "India".\n * **School Name:** Filled with "Indian Institute Of Technology Madras (Chennai, Tamil Nadu)". \n* **Additional Text:** There is text at the bottom noting that school name will help provide Microsoft with additional information for verification.\n\n**Overall Impression:** The image depicts a step in an application or verification process, where the user is providing their academic information to confirm their educational background.Screenshot 2025-03-31 0645381172√ó815 101 KB
Here\'s a point-by-point description of the image:\n\n* **Content:** The image displays a field labeled "School email address" with a corresponding email address provided.\n* **Email Address:** The email address shown is "21f3002277@ds.study.iitm.ac.in".\n* **Format:** The email address is presented within a rectangular field, suggesting it\'s a form input or a displayed data point.\n* **Background:** The background appears to be a pale gray or off-white color.Screenshot 2025-03-31 064552913√ó119 3.63 KB
Hi,
i deployed the application the application in render. It is free for 750 hours per month. But it is saying if the application is inactive mode, it will be go spin-off mode and take some 50 seconds to respond to the first query from inactive mode.
is that ok?
@Jivraj @Saransh_Saini
do we have additional sample question request formats available then what is listed on the project description page? kindly assist. thank you.
Here is a detailed description of the image:\n\n**Overall:** The image displays a configuration panel for inbound port rules, likely within a cloud platform or virtual machine management system.\n\n**Key Elements:**\n\n1. **Title:** "Inbound port rules" is at the top, indicating the purpose of the panel.\n2. **Descriptive Text:** Below the title, there‚Äôs text stating it selects which virtual machine network ports are accessible from the public internet, and users can specify more limited access on the Networking tab.\n3. **Public Inbound Ports Options:** \n * A radio button labeled "None" is available, meaning no ports are open to the public.\n * A radio button labeled ‚ÄúAllow selected ports‚Äù is selected.\n4. **Select Inbound Ports Dropdown:**\n * A dropdown menu with "SSH (22)" selected, implying that SSH access is being configured for the virtual machine.\n5. **Warning Message:**\n * A yellow triangle warning icon is displayed.\n * The warning text states that allowing the selected port will allow **all IP addresses** to access the virtual machine. \n * It\'s recommended for testing and suggests using advanced controls to limit inbound traffic to known IP addresses.\n\n**In essence:** The image shows a configuration screen where a user is configuring access to their virtual machine via SSH. The system is warning the user that opening SSH to all IP addresses is a security risk and should only be done for testing.Screenshot 2025-03-31 0748451267√ó351 16.2 KB
is the port is correct @Jivraj
@s.anand
@carlton @Jivraj
Respected Sir,
We kindly request a one-day extension for Project 2, as we finished with vivas and OPPE yesterday only. The circumstances this time have been more challenging than in Project 1, making it difficult to meet the deadline.
We would be extremely grateful if you could consider this request. Your support would be highly appreciated.
Thank you for your time and consideration.
Best regards
Yes please extend the deadline for project 2, as it was very lengthy and we have other exams as well with that.
@s.anand ,
@carlton
@Jivraj , @Saransh_Saini
@Jivraj @Saransh_Saini @carlton
Respected Sirs,
Please consider the extension for Project 2 submission‚Ä¶
Good morning sir,
Could you please extend the deadline for Project 2 as today(31/03/2025) is the last day of submission and it clashes with ‚ÄúEid al-Fitr‚Äù. I have small portion of work left but it won‚Äôt be possible as there is frequent visit of guests and friends. Could you please extend the deadline till 02/04/2025, this will give us enough amount of time to complete the project after our festival.
Thank you
@carlton, please this much support we deserve from you
Pls sir extend the deadline it‚Äôs very hectic schedule for all of us  to complete by today. @Jivraj @carlton @s.anand
Sir, could you please extend the deadline by one day? I‚Äôm facing some issues with deployment, and with Eid celebrations at home, it‚Äôs been a bit difficult to manage everything. I would really appreciate your consideration. Thank you!
@carlton @Saransh_Saini @Jivraj @s.anand
Sir many of us had OPPEs and Programming projects due this weekend and thus an extension in the deadline will be helpful
hi sir. Im also on the same boat.
hello please say on ngrok i want to share ngrok method ‚Äò‚Äô but i have to open all days right on
Hi. I got a new laptop and was wondering how to recover my AIPROXY token. How do I get it? If I remember correctly it has something to do with my iiim email
@Saransh_Saini @Jivraj @carlton
What is the request timeout for each question, especially for the question on YouTube video transcription? I request the timeout to be at least 40-60 seconds as yt-dlp and faster-whisper take take to download the audio, load the model and run it on cpu and get the transcription.
For 259.7 to 351.8 seconds, it is taking around 1.5 mins, but it is giving the correct answer.
So I request you to shorten the length of the audio or increase the request timeout or both in moderation.
Question ‚Äî&gt; the ‚Äúquestion‚Äù sent to the api will have the youtube video link, right? Or since the video is same for everyone, can I just have the audio file ready in the project? Will the api be tested against any YouTube video other than the Mystery Story Audiobook link given in the GA question?
Edit: Even with a preprocessed audio file (mp3, speech optimized, 32K), what‚Äôs taking the longest time is joining the transcribed sentences into a single string. That alone is taking &gt;50 seconds. Please suggest a way to make it faster.
Regards,
Shivaditya
For the FastAPI type questions, my endpoints are like http://ip:port/endpoint. But while testing using the portal it expects HTTPS instead of http. But nothing of that sort is given in the question. Will the evaluator also expect a https url or is a http url enough for it to hit the endpoint?
@Saransh_Saini @carlton @Jivraj
Yes we‚Äôll take that into consideration.
For GA 5 - Q10 - do we have to return base64 encoded image or the url of the image?
Base64 encoded string
@Jivraj @carlton @Saransh_Saini
q-vercel-python.json will be same or different?
Here\'s a detailed description of the image:\n\n**Overall:** The image is a screenshot of a dark-themed text-based instruction set, likely from a coding tutorial or documentation.\n\n**Content Breakdown:**\n\n1. **Instruction 1:** Instructions to download a JSON file named "vercel-python.json" containing marks for 100 imaginary students.\n\n2. **Instruction 2:** Instructions to create and deploy a Python app to Vercel, exposing an API endpoint. The instructions also define the expected response to a GET request with parameters for names \'X\' and \'Y\', which should return a JSON response containing the marks for those names in the same order. \n * A code snippet showcasing the expected JSON format is included: `"marks": [10, 20]`.\n\n3. **Instruction 3:** Indication that Cross-Origin Resource Sharing (CORS) should be enabled to allow GET requests from any origin.\n\n4. **Instruction 4:** A question prompts for the Vercel URL. The expected format for the URL is given as `https://your-app.vercel.app/api`.\n * An example Vercel URL is also provided: `https://vercel-tdc-one.vercel.app/api`.\n\n**Visual Elements:**\n\n* The text is white against a dark background.\n* Code snippets and URLs are visually highlighted using a light blue background.\n* The interface style suggests a command-line environment or a dark-themed code editor.\n\n\n\nIn summary, the image presents a series of instructions for setting up a Python-based API endpoint on Vercel, emphasizing the expected input and output format.image1548√ó391 39.2 KB
Will the llamafile be same?
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a terminal or command-line interface displaying text instructions and a URL. The background is dark, typical for such interfaces.\n\n**Text Content (from top to bottom):**\n\n1. **"Download Llamafile. Run the Llama-3.2-1B-Instruct.Q6\\_K.llamafile model with it."** ‚Äì This is a command instructing the user to download Llamafile and execute a specific model.\n2. **"Create a tunnel to the Llamafile server using ngrok."** ‚Äì Another command telling the user to create a tunnel using the ngrok tool.\n3. **"What is the ngrok URL? It might look like: https://[random].ngrok-free.app/"** ‚Äì This line explains that the following line will display a unique ngrok URL, which might look like the sample provided.\n4. **"https://aafb-2405-201-4007-c068-eb1d-b640-5d42-2493.ngrok-free.app"** ‚Äì A generated ngrok URL, highlighted with a yellow background. It is a long, unique address indicating a tunnel created using the ngrok service.\n\n**Overall, the image provides instructions and a resulting URL for setting up and accessing a Llamafile model using ngrok, a tool for creating secure tunnels to local servers.**image780√ó221 21.5 KB
hello i want to know about this currently I am using approach like you provide HTML page URL and my internal approach and run hidden value or you provide URL website
Here\'s a detailed description of the image:\n\n* **Content:** The image shows a simple webpage-like interface.\n* **Text:** There are two lines of text:\n * "Just above this paragraph, there‚Äôs a hidden value."\n * "What is the value in the hidden input?"\n* **Input Field:** There\'s a rectangular input field, likely for the user to type in an answer. The field is currently empty.\n* **Button:** A blue rectangular button labeled "Check" is present at the bottom of the image. \n* **Overall Impression:** The image appears to be a prompt for a challenge or puzzle, involving a hidden value that the user needs to determine and input. It is a simple, minimalist design.\n\n\n\nimage788√ó325 9.21 KB
hello for this question i am using approach like initially i login and saved seession now it is giving output like it login internally to website of college ga1 and then find
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a question or prompt related to CSS selectors and data attributes.\n* **Text:**\n * "Let\'s make sure you know how to select elements using CSS selectors. Find all ``s having a `foo` class in the hidden element below. What\'s the sum of their `data-value` attributes?"\n * "Sum of `data-value` attributes:"\n * A blank input field is positioned below the question.\n * A button labeled "Check" is visible at the bottom of the image.\n* **Layout:** The text is formatted as a question-and-answer prompt with an input field for the user to provide a response. \n* **Overall impression:** The image is part of an interactive exercise or quiz to test a user\'s understanding of CSS selectors and how to access data attributes in HTML elements.image974√ó281 14.5 KB
I asked this question in the gmeet. They said html will be provided in the question and u have to find the hidden input from there. Same for css selectors
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a table from a SQLite database, showcasing data related to customer bids for concert tickets. \n\n**Table Structure:**\n* **Columns:** The table has three columns labeled "type," "units," and "price."\n* **Data:** The table contains several rows of data.\n * **Type:** The "type" column shows the different ticket types (e.g., "bronze," "Silver," "SILVER").\n * **Units:** The "units" column contains numerical values likely representing the quantity of tickets bid for.\n * **Price:** The "price" column holds numerical values probably representing the price per ticket.\n* **Data Sample:**\n * The first row shows a "bronze" ticket type with 297 units and a price of 0.6.\n * The second row shows a "Bronze" ticket type with 673 units and a price of 1.62.\n * Further rows indicate "Silver" and "SILVER" ticket types with varying units and prices.\n* **Ellipsis:** An ellipsis ("...") indicates that there are more rows in the table not visible in the image.\n\n**Additional Text:**\n* At the top, the image includes a textual description explaining that the table represents a SQLite database with "type," "units," and "price" columns for customer bids.\n* Below the table, there\'s a question: "What is the total sales of all the items in the "Gold" ticket type? Write SQL to calculate it."\n* There is a black box at the bottom of the image.\n\nIn summary, the image presents a snippet of a database table containing information about concert ticket bids, along with a request to calculate the total sales for "Gold" tickets using SQL.image859√ó556 23 KB
do you know answer of this that time i got answer
but i got wrong answer
@carlton
Could you please consider the above request for an extension? There are still many updates needed, and the project is close to completion. I am confident you will be pleased with the final results.
Here is a detailed description of the image:\n\n**Overall Impression:** The image depicts a user interface for an "AI Assignment Solver," designed to help users with their assignments. It has a clean, modern design with a light purple background.\n\n**Key Elements:**\n\n* **Title:** At the top, it reads "AI Assignment Solver" in bold, white text.\n* **File Upload Section:**\n * A "Choose File" button is visible. The text indicates that no file has been chosen yet.\n * Below it is an "Upload" button, which is currently inactive (presumably until a file is selected).\n * A message "No file uploaded" appears under the upload button.\n* **Question Input Section:**\n * "Ask a Question" is written above an empty text input field.\n * A "Submit" button is located below the text input field.\n* **Answer Area:**\n * At the bottom of the interface, a placeholder text "Answer will appear here." indicates where the AI-generated answer will be displayed.\n\n**Visual Style:** The interface uses rounded corners for the buttons and input fields, and the color scheme is primarily white and a light shade of purple. The design is simple and intuitive.\n\n\n\nimage439√ó459 28.4 KB
Sir, I have created the frontend app like an html page with the fastapi utilizing the chatgpt-o3 , instead of Api key. I managed to get api keys but ended up in only text mining without file handing (not able to do multipart-form data). So, I have made to use  the model and designed a frontend which also takes the input from the file uploaded, So, it will be ideal for assignment solver, Isn‚Äôt it , Sir? @carlton @Karthik_POD
Here\'s a detailed description of the image:\n\n**Overall:**\n\n* The image is a screenshot of a text-based calculation. It appears to be a list of numerical values (presumably financial) with a final sum indicated.\n* The background color is a muted purple.\n\n**Content Breakdown:**\n\n1. **Initial List of Values:** A series of numbers are listed, many of which are negative. These include:\n * -2,400.00\n * -0.00\n * -1,234.00\n * -10,000.00\n * -20.00\n * -2,000.00\n * -0.00\n * -0.00\n * -20,03,030.00\n * -1,000.00\n * -1,000.00\n * -1,000.00\n * -1,000.00\n\n2. **Calculation Start:** Text states: "Now, let\'s calculate the total:"\n\n3. **Values Used in Sum:** The same values as above are listed once more.\n\n4. **Subsequent Values:** There is a line indicating "5,000.00 (total of subsequent similar entries)".\n\n5. **Summation:** A mathematical expression displays the addition of all listed values, culminating in "2,073,684.00".\n\n6. **Final Statement:** The text concludes: "Thus, the total value of complaints is **2,073,684.00**".\n\n**Key takeaway:** The image presents a numerical calculation that determines the total value of complaints, which is calculated to be 2,073,684.00.image643√ó576 36.1 KB
This is the output Sir @carlton @Karthik_POD . Also my project-1 has not been scored .. till now .. Please review that also. Project 2 - TDS Solver - Discussion Thread - #240
Hi @22f3000370
We appreciate the efforts you have put in. But, for the project we aren‚Äôt expecting a full-stack app with an integrated frontend. We just need an API endpoint on which we would be able to send requests in the given format. For more info check the TDS course page. Tools in Data Science
@Saransh_Saini Is answer in this form acceptable..
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a command-line interface (CLI) displaying the results of an API request. The request appears to be related to a customer feedback analysis system.\n\n**Key Elements and Details:**\n\n1. **CLI Window:** The primary content is a dark-themed CLI window.\n2. **Request URL:** At the top, the request URL is displayed: `"http://127.0.0.1:8000/api/"` This indicates a local server is running on port 8000.\n3. **Request Command:** The initial command used for the request is shown, including the use of `curl` with parameters like `-X POST`, `-H "Accept: application/json"`, `-H "Content-Type: multipart/form-data"`, and a data payload related to a question for "ShopSmart."\n4. **Server Response Section:** This section is divided into "Code" and "Details".\n * **Code:** Shows a status code of "200", indicating a successful request.\n * **Details:** This displays the JSON response body from the API.\n5. **JSON Response Body:** This is the most substantial part of the image and contains the analysis results. \n * It includes an `"answer"` field, which contains Python code. The code is a function to calculate the cosine similarity between pairs of embeddings.\n * The response also contains a lengthy list of embeddings represented as numerical vectors.\n * There are a variety of embeddings (numerical values) included.\n\n**In essence, the image demonstrates a data analysis process where a question is sent to an API, and the API returns a Python function for calculating similarity between data points (embeddings) along with example embeddings.**image2726√ó1489 463 KB
what is the problem in my Dockerfile it‚Äôs not working and crashing my system
# Use Ubuntu 22.04 as the base image
FROM ubuntu:22.04

# Set environment variables
ENV PYTHON_VERSION=3.11

# Install system dependencies
RUN apt-get update &amp;&amp; apt-get install -y \
    python3.11 \
    python3-pip \
    python3-dev \
    git \
    curl \
    wget \
    ffmpeg \
    imagemagick \
    build-essential \
    libpq-dev \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

# Ensure python3.11 is the default python version
RUN ln -sf /usr/bin/python3.11 /usr/bin/python

# Install NodeJS
RUN curl -sL https://deb.nodesource.com/setup_22.x -o nodesource_setup.sh &amp;&amp; \
    bash nodesource_setup.sh &amp;&amp; \
    apt-get install -y nodejs &amp;&amp; \
    node -v &amp;&amp; \
    npm install -g prettier@3.4.2


# Copy dependencies file first to leverage caching
COPY re.txt ./

# Install Python dependencies
RUN pip install --no-cache-dir -r re.txt

# Install `uv` package manager from Astral
COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/

# Create and set working directory
WORKDIR /app

# Copy application files
COPY main.py .
COPY llm_functions.py .
COPY llm_tools_functions_calls.py .
COPY server.py .

# Set default command to start the FastAPI server with `uv`
CMD ["uv", "run", "main.py"]


@carlton @Jivraj
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a web service dashboard, likely from a platform like Render or a similar cloud deployment service. It shows details about a deployed application named "TDS-Project-2" built with Python.\n\n**Key Elements:**\n\n* **Application Name:** "TDS-Project-2" is prominently displayed, indicating the name of the deployed web service.\n* **Status:** The service is labeled as "Free," suggesting it\'s currently on a free tier.\n* **URL:** The service\'s URL is given as "https://tds-project-2.prlm.render.com" and an external link icon.\n* **Warning Message:** A yellow warning message indicates the free instance may spin down due to inactivity, causing request delays. A button to "Upgrade now" is visible.\n* **Deployment Information:**\n * A deployment is "In Progress" with a timestamp of "March 31, 2023 at 4:38 PM".\n * The commit hash/message is listed as "5989251, Final Commit".\n * A button to "Cancel deploy" is visible.\n* **Footer:** A row of icons and text appears at the bottom of the screen.\n * A dropdown menu for ‚ÄúAll logs‚Äù and a search bar are located at the bottom-left of the screen.\n * The bottom-right of the screen indicates ‚ÄúLive tail‚Äù and shows ‚ÄúGMT+5:30‚Äù.\n\n**Color Scheme:**\n\nThe interface uses a dark theme with purple and yellow accents for highlighting important information and warnings.image1454√ó433 30.4 KB
I have deployed the project on render so the first request in evaluation takes around 50 to 60 second is that okay
I deployed my API using Railway.app, but Jio ISP is blocking requests to .up.railway.app. I tested it with five other ISPs, and the API endpoint works perfectly. Could you please consider that some ISPs may be blocking certain domains?
@Jivraj @carlton
Error code: 401 - {‚Äòerror‚Äô: {‚Äòmessage‚Äô: ‚ÄòYour authentication token is not from a valid issuer.‚Äô, ‚Äòtype‚Äô: ‚Äòinvalid_request_error‚Äô, ‚Äòparam‚Äô: None, ‚Äòcode‚Äô: ‚Äòinvalid_issuer‚Äô}}
This error is persisting despite many attempts.
you have given diffrent variable name in environment and in app
@carlton @Jivraj @Saransh_Saini
Can you pls confirm on timeline
since azure take money so till when do we have to turn on our deployment portal services
Also if we are using ngrok , how long do we have to keep it running
Yup, this is correct. All we need is the JSON object.
We‚Äôll try to keep this in consideration while developing the evaluation script. But to be on the safer side keep sending requests to your server on such intervals that it doesn‚Äôt go inactive.
@Saransh_Saini @s.anand @carlton @Jivraj
Please extend the deadline for TDS Project 2. The MAD 1 project and two OPPEs have taken up all my time. I have completed my TDS project up to the Week 3 assignment solutions, and only two weeks remain to complete Weeks 4 and 5.

We won‚Äôt be able to extend deadline, if we do, then evaluations will get delayed.
I completely understand the need to keep evaluations on schedule. In that case, would it be possible to grant just a one-day extension? I‚Äôve completed up to Week 3 and just need a little extra time to wrap up Weeks 4 and 5 properly. A single day would really help me submit a more polished project without causing significant delays
I think it should be given many had their OPPE also
Sir, please reply. Otherwise, all my hard work up to Week 3 assignment will go to waste.
Even Im getting the same error. Did you find a resolution for this?
are you sure api requests are going through the IITM AI Proxy and not OpenAI directly?
I am facing this issue can any one help
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays an error message indicating a crashed serverless function. The background is a light grey.\n\n**Textual Content (Point-by-Point):**\n\n* **Headline:** "This Serverless Function has crashed."\n* **Status Messages:**\n * "Your connection is working correctly."\n * "Vercel is working correctly."\n* **Error Details (within a grey rectangle):**\n * "500: INTERNAL_SERVER_ERROR"\n * "Code: `FUNCTION_INVOCATION_FAILED`"\n * "ID: `bom1::48ghr-1743430791127-d99a1b77819a`"\n* **Instructions/Help:**\n * "If you are a visitor, contact the website owner or try again later."\n * "If you are the owner, learn how to fix the error and check the logs."\n\n**Key takeaways:** The message indicates that while the connection and platform (Vercel) are functioning, the serverless function itself has failed with an internal server error. It provides different guidance depending on whether the user is a website visitor or the website owner.\n\n\n\nimage717√ó572 25.9 KB
Please check the logs.
Hi @s.anand and @carlton Sir,
It would be really  great if the deadline for submission could be extended by one more day. While we understand your reasons, we kindly request you to consider our situation as well.
Trailing Slash redirect error (Used next.js)
Questions that have access hidden divs, how would the parameters be provided
? @Jivraj @Saransh_Saini @carlton
Sometimes the server shuts down, what would happen then? @Jivraj @Saransh_Saini
For this the HTML file would be provided to you and you have to find the given element.
@Saransh_Saini can you provide us the time frame for evaluation so that we know when to run ngrok. Vercel isn‚Äôt an option right now as i‚Äôm having issues deploying.
Sir, I sincerely request an extension of the deadline by just one day. I have completed the coding part, but I am facing some issues with the deployment of the project. I would really appreciate your consideration.
@carlton @Jivraj @Saransh_Saini

Stay tuned @all
What issues are you having? I am having an issue deploying due it either using up all the memory while installing dependencies or hitting some other limit. I gave up and am now hosting it on render.
@carlton @Jivraj @Saransh_Saini @s.anand
URGENT IMPORTANT QUESTION : should the link we will submit in the gform have /api in it or not :,) [ PLS DONT SCOLD IF ITS A SILLY QUESTION ]



 Saransh_Saini:

this the HTML file would be provide


same
PLEASE INFORM
S
S
S
S
please tell how long approx will evaluations will last
it depends on what ur post endpoint is , if its (‚Äú/api‚Äù ) then give that
@Jivraj @Saransh_Saini same question
same here , It worked fine for a while and once the dependencies grew and varied it started showing serverless function crashed though it was running fine locally
I noticed that ngrok disconnects after two hours, so I‚Äôm wondering if we can continue using it.
If your team was aware of this, I‚Äôd like to understand why it was allowed to deploy on ngrok. I typically use Vercel for deployment, but as you know, Vercel doesn‚Äôt support certain features.
what to do now
Just extend the deadline for one day please it will be a great help for many students
ngrok will give me 0 marks right because when ever your system try to evaluated it get offline message
still i am very thankful for this project i created mini chatgpt
without using any llm api
instead of prompt engineer
pls sir extend the deadline by 1 day
it wont disconnect in 2hours , if u login using ur id to ngrok and start ur server with auth id , it will keep running as long as ur pc is on
use screen package to keep it running
yes me too
Thank You for some sleepless nights(now I have some dark-circlesüòë) and this wonderful experience@s.anand @carlton @Saransh_Saini @Jivraj

Thank you @21f2000709 @trebhuvansb @ItsMeAlex
without you guys, i don;t know what i would have done. THANK YOU
Ah, the true mark of a dedicated developer‚Äîwhen even your dreams come with syntax errors!  This project was a rollercoaster of caffeine, code, and existential debugging at 3 AM. But hey, we survived, and now even my subconscious is running python main.py on repeat. On to the next adventure‚Ä¶ after some well-earned sleep (hopefully bug-free)!
Hello Sir,
I hope you‚Äôre doing well. On behalf of all the students in our course, I wanted to request a deadline extension for the project 2. We‚Äôre all putting in our best effort, but we need a little more time to complete it properly.
If it‚Äôs possible to grant an extension, we would really appreciate it. Please let us know if you can consider this request.
Thank you for your time and understanding!
Saksham
Please sir  !
image417√ó406 31 KB
yess sir same with me can u just extend 2hrs like that
i used ngrok. i need to change it to vercel or someother thing. so sir kindly extend the deadline for a day‚Ä¶ please sir. this is a kind request from every student
anybody there?..???..???..???..?
Respected Sir,
I kindly request a deadline extension of at least 3 minutes for the project submission, similar to what was done for ROE. Due to slow internet connectivity and the absence of WiFi, my submission took longer than usual. As a result, I was only able to upload it at 12:01 AM instead of the regular 11:59 PM deadline.
PLEASE Sir, As I‚Äôm a standalone student and this is my primary degree after 12th, please do accept it.
Thank you
tom1000√ó750 328 KB
sir kindly extend the deadline for a day sir, kind request from tds students. kindly consider our pleadings.
sir i was trying to upload it but due to net issue it got submitted at 12:01.
the google form is saying the response is recorded. so  my response is recorded right?
Hi @s.anand and @carlton Sir,
It would be really great if the deadline for submission could be extended by one more day. While we understand your reasons, we kindly request you to consider our situation as well.
Hi @carlton @Jivraj
I have submitted my fastapi endpoint without the /api at the end.
Would this be a problem?
@carlton @Jivraj @s.anand
Sir i also didn‚Äôt addd /api/ at the end of the url. Will this cause a peoblem?
My project is hosted on render, because vercel refuses to cooperate with me, as a result the free version of render takes a minute to respond, and not only that but might also give internal server error until the 2nd or 3rd try. There is nothing I can do to change this except for maybe sending requests every now and then like it was suggested for another student using render. I just want to know if this is okay for evaluation.
@carlton @Jivraj @Saransh_Saini @s.anand
@carlton @Jivraj @Saransh_Saini sir,
I also have submitted my fastapi endpoint without /api at the end, please reply if this would be a problem?
@carlton @Jivraj @Saransh_Saini @s.anand
Can you please say when the project 2 be evaluated?? since i am using ngrok it is very hard to keep my laptop running and also the result time is given as 15th. no possile way i could run my laptop more than a couple day. kindly provide a solution for ngrok users or please extended a day or so to change from ngrok to someother. this is a kind request. and kindly reply as soon as possible.
me too ,please inform how long will it take .
are we free to edit the google response , to update the ngrok link if it changes cuz in the free version if the laptop restarts so will the link
@carlton @Jivraj @Saransh_Saini @s.anand
Yesterday, I don‚Äôt mention /api at the end of my dns while submitting the form and I come to know to day we have to add /api at the end of the it. So I edited my response please consider the latest one.
@carlton @Jivraj
I have a curious question.
I have my project running from azure and code in GitHub repository.
What is stopping me from making further change to my deployment because my end point will be same. Anyway my code checksum for the deployment and GitHub code won‚Äôt match as I haven‚Äôt pushed the token to GitHub.
Thanks,
Vinil
I did the same mistake and I am just realising it. Will my submission be discarded in that case? Please clarify.
@carlton @Jivraj
I reuesting to all my teachers @s.anand, @carlton, @Jivraj, @Saransh_Saini please reply me.
What is this going on? Is it joking? Our teachers don‚Äôt have enough time to make a separate video for project to explain what to do and how to do? I already have done two project courses and they taught us, even they made 2 - groups just only for discussions in which one is personal and also made a YouTube playlist especially for project. They explained what should be your approach? How to make project? And here, they took only one session just only for show off. And they organised that single session when too many student requests too many times? Are we studying in IIT - The top institute of India or in a cheap and lower than third class government schools. It is the responsibility of our teachers to explain the project, but they are just showing off. Even they never provided the solutions for assignments also. Is it not our right to get solutions so that we can know where we did mistake? They don‚Äôt have time to make solutions, they just made an assignment checker which checks the assignments automatically. I don‚Äôt think so that they really made any effort in our course. In project-2 also, we need solutions for all graded assignments and so many students request for solutions but our the great teachers ignores the request and didn‚Äôt provide the solutions. I think they provide the projects whatever comes in their dreams during sleeping. In weekly study material, don‚Äôt have their notes, even they have a very few videos made by them, they just render to other YouTuber‚Äôs Youtube videos and online websites. Are we paid just only for these YouTube videos ? If we can understand everything just only from YouTube then why we are studying from the India‚Äôs top Engineering institute - The IIT Madras? I have much more better videos than that are provided on YouTube and created by other YouTubers. They only have some points copy pasted from documentations, but they never tried to explain them. Just read, copy and paste in your program. What is it, why it is used for, don‚Äôt ask anything.
Some students request for extending the time limit of [roject-2 just only for one day, but what was their excuse- "We won‚Äôt be able to extend deadline, if we do, then evaluations will get delayed. ". I want to ask them, where is the result of Project-1? The first date of result declaration was 26-Feb, then their another date was 16-March, but until now on 2-Apr, we do not get our results. It is more than 45 days, what is this going on? Nobody tried to ask with our great teachers. But on extending the deadline of project-2 just only for one day, their evaluation will be late. In project-2, we have to continue running our project until they will not evaluate, whether they take more than 1, 2 or more months. Either we have to host online by paying or run our own system for 24x7 unto when, we also don;t know as their result date is also not fixed, it is just a combination of letters and numbers showing on portal. It is our tales it is my right to get solutions for every weekly assignment, but don‚Äôt ask them to make efforts. Just pay and do assignments at own risk even you have not understand anything from the copy-pasted material. Just use AI‚Äôs or read whatever and wherever you want to read.
It is my kind request, our term is going to be completed, but please make some efforts in next term.
Thankyou to all my respected ‚ÄòThe Great Teachers‚Äô.
hi,
I dont share your views.
i feel it was one of the best course in whole of Diploma.
I have learned a lot in these projects and even in ROE preparation.
all the things we are learning here are open in market and the course contents are great direction towards learning and practicing them.
I agree it is stessful, my whole team were in a 9-hour g-meet call on Saturday night. but we have found solutions, shared ideas, try-outs, made fun of each other.
but at the end of the day we all agree that we have learnt lots of new things.
Regarding Project1 delay: if we think, atleast 1GB of docker image per students for 700+ students. even if parallalize the execution 5 students at a time you still need a very powerfull system to download and amount of data downloading etc‚Ä¶ At the end of the day we got a very good result and report with logs to verify
for GA‚Äôs: it is upto you to copy solutions or learn something out of each GA sections
All in all I am happy with the course.
Totally Agree with @23f2004837
Best course so far from learning POV.
Dear Shahzada,
You joined Discourse almost a year ago Jun 8th, 2023. In all that time you have read 832 posts. And never interacted with anyone on discourse. You finally decided to interact once and that was today and this is your first post (your second if we count that you deleted your first post)
The first step to receiving help is communication. If you do not communicate, no one can help you.



 23f2002668:

What is this going on? Is it joking?


I am not sure what your question is. I am not sure what you are referring to. Please be clear in your questions.



 23f2002668:

Our teachers don‚Äôt have enough time to make a separate video for project to explain what to do and how to do?


We have made several hours of videos on Project 2 and have demonstrated multiple ways to solve it. However, we are not going to ever create it for you. We do teach you all the core technologies you can leverage to create it yourself.



 23f2002668:

I already have done two project courses and they taught us, even they made 2 - groups just only for discussions in which one is personal and also made a YouTube playlist especially for project.


Not sure which courses you are referring to, but those are standalone courses. Here project is part of the course and is meant to take you roughly a few days to create. We gave students more than one month for Project 1 and the solution for it takes a few hours to create. (which we have shared)



 23f2002668:

They explained what should be your approach? How to make project?


Yes these were explained if you

either took part in any live session or
watched the recorded video




 23f2002668:

And here, they took only one session just only for show off. And they organised that single session when too many student requests too many times?


I am not sure what you are referring to because several sessions were conducted for Project 2 spanning nearly 2 weeks.



 23f2002668:

It is the responsibility of our teachers to explain the project, but they are just showing off.


Project 2 was explained. I can summarise it in these words:
Create a server api that receives a request.
The request would be any question from the first 5 GAs.
The response has to be a json response as specified in the Project page.
Multiple demonstrations were done of this workflow in sessions.



 23f2002668:

Even they never provided the solutions for assignments also. Is it not our right to get solutions so that we can know where we did mistake?


Since this is your first post, you‚Äôve never ever asked for solutions to any assignments. We have never provided solution notebooks for TDS. It defeats the learning process.
If you want solutions, there are several options:

Ask for help (since you have never posted before, you missed the opportunity to receive it)
Collaborate with others (a bigger goal of TDS, because in the real world one man bands almost certainly fail with extremely high probability, barring a few exceptions, human progress is built on collaboration)
Join live sessions, where we have provided solutions to almost every assignment question that students have asked (and not asked)
Watch the live sessions, we have even created neat Q &amp; A summaries for them on the TDS portal (something which no other subject does at the moment)




 23f2002668:

They don‚Äôt have time to make solutions, they just made an assignment checker which checks the assignments automatically.


This is one of the most loved features by our students. No other GA in any other course gives you the option to check your answers in real time and better yet correct them before submitting.
The biggest clue for solutions is in this nugget. If you take the opportunity, and enterprise and get some fellow students together, you are actually able to obtain the solution script from the GA page itself. It takes some effort, but that is how learning occurs‚Ä¶ with effort. Studies repeatedly show that zero effort results in nearly zero learning.



 23f2002668:

Are we paid just only for these YouTube videos ? If we can understand everything just only from YouTube then why we are studying from the India‚Äôs top Engineering institute - The IIT Madras? I have much more better videos than that are provided on YouTube and created by other YouTubers.


If you had better resources available, you have hardly been the paragon of virtue, because we always encourage people to share their learnings. We learn from you, just as you learn from us. If someone makes a better video than us and give it for free, we are happy enough to learn from them. Why should we reinvent a video that is poor quality and force students to watch it when there are better videos? We are not so egoistic to take that approach and worse it does not benefit our students to satisfy our ego. There are a million videos out there on you Tube, how do you find the best one? We curate it. So that you do not have to spend hours finding a good video.
But feel free to find better videos. More power to you, but what would be even better? Share with others so that we can build each other up.
What are the best videos to learn linear algebra? Probably MIT. Why bother with substandard videos when you can just get the best for free? Its just that watching MIT videos will not give you an undergraduate degree from MIT. And it costs Rs. 2.7 crores, provided you even get a seat in the first place. Here you get a 4 year degree for Rs 3.5 lakhs. So you are paying for that.
I absolutely 100% agree with you, if you think you can get a better degree for Rs 3.5 Lakhs then definitely do that. There is no point in wasting time and money on something that is not delivering good value to you.



 23f2002668:

They only have some points copy pasted from documentations, but they never tried to explain them. Just read, copy and paste in your program. What is it, why it is used for, don‚Äôt ask anything.


Reading documentation is a skill you have to pick up. Having said that, we have always explained something that students have asked.  Just ask anyone who attended the sessions. More significantly, most of the new things we learnt, were self taught. Unless you pick up this lifelong habit, you will struggle in the real world.
Now is a good time to start.



 23f2002668:

Some students request for extending the time limit of [roject-2 just only for one day, but what was their excuse- "We won‚Äôt be able to extend deadline, if we do, then evaluations will get delayed. "


That is correct. We do not want to evaluations for Project 2 to be delayed as end term is very close. Is your complaint that you want evaluations to be delayed? Also its not an excuse. Its a fact. Delaying submissions, delays evaluations. Its just basic logic.



 23f2002668:

I want to ask them, where is the result of Project-1?


They have already been sent to all those who passed the prerequisites. Yours did not pass the first time.
Luckily for you, our first priority is always to do our best for students. So not being satisfied with the validation script that was run which was stricter, we created a new one that was more forgiving. You should get a 0 based on the stricter criteria, but you passed on our more lenient check and now you will soon be getting a normalised 7/20 score (we have not decided the normalisation yet because its a matter of deciding how lenient to be).



 23f2002668:

The first date of result declaration was 26-Feb, then their another date was 16-March, but until now on 2-Apr, we do not get our results. It is more than 45 days, what is this going on? Nobody tried to ask with our great teachers.


If you had attended the live session you would have seen Anand explain the reason for the delay. And we do not mind when students ask why and we freely tell them why. So I do not understand how you came to this conclusion.



 23f2002668:

In project-2, we have to continue running our project until they will not evaluate, whether they take more than 1, 2 or more months. Either we have to host online by paying or run our own system for 24x7 unto when, we also don;t know as their result date is also not fixed, it is just a combination of letters and numbers showing on portal.


Anand invited students to write the evaluation script in his live session. And since you claim it is so easy you could have written it and gotten full marks. I am not sure why you did not take this easy option. You complained about it, but decided not to create a solution?
Also if you watched the sessions, we never asked you to run your server for 2 months or 1 month  etc. Its generally a bad idea to make assumptions that have no basis in reality. Project 2 is easy to evaluate. We expect it will take a few days, possibly by this weekend to finish evaluation and push a score. So why you came to the conclusion it would take months, is a mystery, given that you already rightfully explained that its easy to write a script.
But validation takes time. We want to make sure there are no bugs and errors and a lot of edges are possible when students are running various deployments. So we want to give them the best chance of actually scoring. Unless you prefer we do a rush job and give them zeros. You would have received a zero in your project 1 had we not caught a few edge cases in our testing regime.
You can take a poll and ask fellow students if they prefer your approach. We are always happy to make changes based on feedback.



 23f2002668:

It is my kind request, our term is going to be completed, but please make some efforts in next term.
Thankyou to all my respected ‚ÄòThe Great Teachers‚Äô.


I am glad you decided make a kind request, although by all the personal insults and attacks and your ending sign off its clear that neither respect nor kindness is evident in your post.
But thank you for your feedback.
One final note: Do interact more, its healthy. We make mistakes, and we learn. There are many things we want fix for next term. Its not at all our desire to delay evaluations. The complexity of project 1 evaluations was unexpected. So we do apologise for that. We have done so repeatedly, even in our sessions and in discourse posts. The scripts that we released for everyone, probably showed how challenging it was to get it right so that everyone who could get a score, got a score.
And when writing posts or emails or any communication, try to stay on point and professional. We are always happy to learn what we can change and improve.
Kind regards,
TDS team
Hi, I have a few things to say
My background :
I have completed all the courses in diploma except TDS. I have secured reasonably good grades in all the courses. However, I failed TDS the last term and I am likely to fail in this term too. The reason is, I got bad marks in both ROE and I have never submitted any project, i.e., I have not submitted 3 TDS projects in the last two terms and did badly in the first project of the previous term.
My Initial Disappointments with this Course
In one of the orientation session, I heard Andrew sir say this (subject to correction):

The video lectures are the primary content. It is not compulsory to attend the live sessions, but it is highly recommended.


Here, the most important resource are the live sessions. I did not like it. Till now, I have managed all the courses with faculty lectures alone. I rarely watch live sessions. I didn‚Äôt like watching live sessions. I felt it was against what is pointed out in the previous paragraph
ROE is just for forty five minutes, with around 10 questions. I felt that this is rubbish and unthoughtful.
There are not many videos explaining the tools (from IIT side). Only a few videos. Most of the tools are explained through text. I felt that a the purpose of a college course is to explain things in a simple way so that we can learn it easily.

Why did I fail?
Last Term
I dumped myself with a 3 more courses, projects and nptel courses. I didn‚Äôt practice the GAs properly. So I failed ROE. I will come to the projects soon.
This term.
I made sure that I do all the GAs properly. But I did better than last time in ROE but still bad. This time because, other than GAs, I didn‚Äôt allocate time for ROE. Also, I didn‚Äôt submit both the projects.
In both the terms I didn‚Äôt collaborate with anyone. I felt that I shouldn‚Äôt earn my marks be talking help from someone. I felt it is not fair.
Me Understanding about the Course Now
This one line changed my view about ROE.



On another topic

What does this RoE evaluate? Implicit learning.


I am reasonably ok with python and all the tools in this course. But in ROE, I was not able to write a nested for loop, which was needed for some question. It is not that I don‚Äôt know how to write a simple nested loop. I discovered the fact that I have not coded enough.
I scored 100 in all the OPPEs : python, java, PDSA, DBMS. I knew the concepts. But the questions were not difficult and the time was ample. This is not the case in TDS.
Now I realize that  I am not good in SQL or DSA. It is just the questions were easy and was accompanied with ample time.
In MLP, I score just 40 in OPPE 1, this was because of me not practicing SKLearn. Then I practiced and got 90 in the second OPPE.
This course has made me realise that till I need to learn relearn these things in an implicit way.
This is the exact reason why I have not been able to complete the projects. I still know most of the things required for project 1 and 2. But I was not able to practically sit and write the code.
I have understood that this is not a traditional course. I feel that we must expect something different from this course. Especially not just marks
I have understood that the limited amount of recorded lectures for is a way to make the students to practically go through the documentation. Understand the complex phrasing of some functionalities, etc.
I am most likely to take this course again. I feel extremely bad to have wasted 15000 rupees. But this course has been a wake up call for me. I still feel that I have the potential to do this course way better than this. What I would have to do is a lot more coding of what I have already learnt.
From the other project courses, I had a wrong assumption that projects are about applying what we have learnt. This was also a reason why I didn‚Äôt do my projects in TDS. I felt that the course team didn‚Äôt cover all the essentials of a projects. I have now realized that projects are about applying what we know and also learn new things which will enhance our projects.
Since this is not a traditional course, I also feel that it is fine to collaborate and seek help, at the same time, strive to contribute to others too.
Thanks to @s.anand , @carlton , @Jivraj  and @Saransh_Saini

Just two suggestions


I feel that MAD 2 and MLP should be corequisites.
While introducing the projects, kindly include a video where the flow of the project is explained. Also, address few questions in the video itself which are likely to be asked by us.

true but I wish they can inform how quickly they can evaluate for those using paid platforms / ngrok
@carlton @Jivraj @Saransh_Saini
Hello Carlton,
When are you guys likely to test the API endpoints for Project 2?
I have hosted it on Microsoft Azure, and I only have $92 left out of the free $100 credit. It would be great if you could do this within a week. It is decreasing rapidly.
@carlton @Saransh_Saini same issue
I only have $80 left out of the free $100 credit. It would be great if you could do this within a week.
@parthivn28 @Harshjayswal-2003 @23f2004912
Evaluations will start before this weekend, with some sampling done possibly even tonight and most evaluation runs tomorrow.
Also we will prime the target first by sending a dummy request so it gets ‚Äúwarmed up‚Äù because some of you have reported time to respond to first request takes time for the server to spin up.
Then once we know its responding, we will send requests for evaluation.
Kind regards
@carlton lord carlton 
Yess, I too did the same , previously submitted on 11.55 and edited my response on 12.01 with /api . Hope u will consider it . @carlton @Saransh_Saini @Jivraj
hello can you share ip address whenever you hit our api then we know you hitting it please
@carlton @Jivraj @Saransh_Saini @s.anand sir, I have noticed that sometimes our vm based application gets stuck and on verifying every request using FastApi have noticed that best way to check is run and get your answer post that RESET it back and then run another query and it works perfectly fine, not sure have other faced this issue or not, but it would be great if you could take note of this while evaluating just for safety.
Hope you take note of this and take this into consideration.
Thanks &amp; Regards,
Digvijaysinh Chudasama
@carlton @Jivraj @s.anand yes same issue
@carlton @Jivraj @s.anand
Sirs, I too am facing this issue..



 21f2000588:

check is run and get your answer post that RESET it back and then run another query


I couldn‚Äôt get what this part means?
Okay so basically sometimes what happens is while verifying on FASTApi ‚Äì it gives errors like missing paramaters like‚Ä¶ So basically sometimes it needs resetting the request parser and then it works perfectly fine.
{
  "detail": "execute() missing 1 required positional argument: 'file_bytes'"
}

Which is incorrect, so if we press the RESET button and execute it works properly.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a user interface likely from an API testing tool or a similar software. It depicts a request body configuration form. \n\n**Key Elements & Details:**\n\n* **Header:** The top of the image displays "Parameters" with "Cancel" and "Reset" buttons in the upper right corner. The text "No parameters" is present, indicating no URL parameters are being used.\n* **Request Body Section:** The central area is dedicated to defining the request body, labelled as "Request body" with the "Required" field visible. The body type is set to "multipart/form-data" using a dropdown menu.\n* **Form Fields:**\n * **"question"**: A text field labelled "question", marked as "required", contains the text "Download and use multi-cursors and convert it into a single".\n * **"file"**: A file upload field labelled "file", with a "Choose File" button and a placeholder filename of "multi-cursor.json.txt". It is indicated as a string and binary type.\n* **Buttons**: At the bottom of the request body section, there is an "Execute" button followed by a "Clear" button.\n* **Response Section:** A section below labelled "Responses" shows a text field for the Curl code.\n\n**Color Scheme:** The interface has a light green color scheme.\n\n**Context:** This image likely represents a configuration screen for sending a request to an API endpoint, with a request body that includes a textual question and a file upload.image1775√ó721 21.8 KB
Correct output image ‚Äì
Here\'s a detailed description of the image:\n\n* **Type:** Screenshot of a server response window.\n* **Layout:** The image shows a rectangular window with a light green header bar labeled "Server response." Below are two tabs: "Code" and "Details". The "Details" tab is selected.\n* **Content:** The main body of the window is a black rectangle containing white text. \n* **Text:** The white text appears to be a long alphanumeric string, likely a response token or key of some sort. The string begins with "swap:" followed by a long sequence of numbers and letters.\n* **Elements:** There is a "Download" button in the bottom right corner of the black rectangle.\n* **Bottom area:** The bottom part of the image features a label "Response header".\n* **Overall:** The image likely represents a successful server response, displaying a token or key returned to the user.image1806√ó235 10.1 KB
Hope you get my point which i‚Äôm trying to convey sir.
@23f2004912
Just a brother trying to help students gain valuable skills.
Nothing more brother.
The success of students‚Äô future, is the best reward.
Sometimes it takes a bit longer because some lessons are harder than others. And we all make mistakes. But if you‚Äôve learnt something valuable on the journey, then you are better prepared for what comes next regardless of whether you could clear the obstacle the first time or not.
Kindest regards,
Just Carlton
(nothing more).
The way we test your api is not through a front end.
We send a request to the endpoint directly. We have demoed it in live sessions.
We have even posted on discourse snippets of what this looks like.
As long as your endpoint responds to a request that we send, it will be fine.
Kind regards
sir @carlton  currently iam facing an issue sir.  just now in order check weather my api is working fine or not . i  just tried curl some question but unexpectedly i got timeout error from vercel. i have deployed my app in vercel only. when i checked out i found that in vercel for free account the request timeout is 10s. what to do sir some times gpt take more time to respond. The same endpoint after an hour i tried works fine . will this be an issue sir .
@carlton
i also edited my form due to /api/ after deadline on monday
can u tell atleast whats the status on this query
Dear @Carlton and @S.Anand,
I successfully deployed my project on Vercel, and it works perfectly when tested using curl commands. Each task installs its required packages and runs as expected. However, I encountered an issue with Vercel‚Äôs free version, which has a 250MB limit. While my project‚Äôs size without installed packages is approximately 34MB, the size exceeds the limit once packages like Pandas, NumPy, Pillow, Whisper, and Uvicorn are installed, causing the server to crash.
Could you kindly suggest any alternatives or solutions for this issue? I would greatly appreciate your guidance, as I fear all my hard work might go to waste without a resolution.
We are in the processing pipeline. You will have to wait till it completes. Basically if your endpoint works when we send it a request you will be evaluated. We will use the timestamp of your latest endpoint before the deadline.
Hope that answers your question.
The alternative is to use vercel purely as an endpoint service that processes most things without large libraries, and for more heavy duty backend work forwards the request to another system that handles it and sends it back to your vercel function which then relays the answer to the request.
in spreadsheet edit response modify previous response with timestamp, how you can access that timestamp response?? So how can u have my end point before deadline one since i updated it after deadline.
Also the before deadline one end point is
/api which i changed to /api/ after deadline so if u somehow have access to my old url pls consider adding 1 (slash) / :')
gform allows multiple submissions. i would have to check with @s.anand if its been enabled, i almost certain he has configured it for multiple submissions.
I understand your point but what I am saying is that when I edited my end point after deadline it changed my timestamp to after deadline one so that is my concern that my submission might not be even considered
you can have multiple submissions with multiple timestamps in gform. (unless you chose to edit your response, in that situation i have not tested what actually happens).
I have edited after deadline from /api to /api/
I did not resubmit
:

 From Problem to Platform: Building ‚ÄúVicky‚Äù ‚Äì A Smart Data Science Assistant for TDS @ IIT Madras
 Project Demo Website: https://app.algsoch.tech
During our college course Tool for Data Science (TDS) at IIT Madras, we were tasked with a challenging but exciting project: to build a platform that can take in natural language questions and execute corresponding solutions through an API.
 The Mission:
Create a tool that behaves like a chatbot, accepts user queries (text or file-based) via web or API, processes them intelligently, executes the appropriate code, and returns accurate results‚Äîlike a real data science assistant.

 The Journey: From Fails to Final
At first, the natural choice was to try LLM agents‚Äîthey sounded magical. But in real-world usage, they were slow, unreliable, and lacked precision. Most failed to parse or execute even moderately dynamic queries. 
Then I thought‚Äîwhat if I manually mapped questions and answers using a static JSON structure? That quickly broke when users passed different parameters, different files, or queried in non-standard formats like ‚Äúcode -s‚Äù or ‚Äúcode -v‚Äù.
The next idea: write individual Python scripts per question from our Graded Assignments (GA1‚ÄìGA5). But that lacked flexibility and reusability. Creating multiple files became unmanageable and non-scalable. 

 The Breakthrough: Dynamic Function Mapping
After multiple iterations and failed prototypes, I finally found the right architecture:
 Centralized engine in vicky_server.py
 Uses regex-based pattern matching to detect question types, extract parameters, and identify the correct solution
 Each solution is a structured Python function like ga1_first_solution(query=None)
 Supports dynamic parameter injection, command-line variations, file-based queries, and more
 Acts like a mini compiler for data science tools

 Presenting Vicky ‚Äì The Mini Chatbot for TDS 
Vicky is a smart, modular chatbot built specifically for Tool for Data Science at IIT Madras. It‚Äôs packed with real functionality‚Äînot just templates.
Key Features:
 Graded Assignment Solver
Handles dynamic, real-world questions from GA1 to GA5 like:

code -s / code -v ‚Üí VS terminal commands
Create FastAPI API for CSV with filtering/searching
GitHub automation: repo creation, GitHub Actions setup
Data cleaning, scraping from IMDb, image compression

 File Upload with Query Matching
Users can upload a file (CSV, JSON, Excel) and ask file-specific queries. The system understands context and dynamically links the query to the uploaded file.
 HTML Viewer + Base64 Decoder

View any website in rendered &amp; source format using CORS proxy
Upload Base64 string ‚Üí Get original image back

 Webhooks Integration

Live notifications via Discord &amp; Slack whenever /api endpoints are accessed
Monitors server status (online/offline) and sends real-time updates

 LLM Download + Auto Tunneling

Downloads LLaMA models
Dynamically finds available ports
Creates and exposes tunneled endpoints

 Live Web UI at app.algsoch.tech

Ask any TDS question
Upload and query with files
Image decoder
Graded assignment slider navigation
HTML viewer
API health status


 Built With:

FastAPI for blazing fast APIs
Regex &amp; Pattern Matching for dynamic input detection
GitHub Copilot + my Python debugging and architectural thinking
Full webhook and status monitoring system
Modular backend (vicky_server.py) and web frontend (vicky_app.py)

I want to extend a huge thank you to @s.anand for their guidance on this project. I‚Äôve learned what prompt engineering is and how we can leverage large language models (LLMs). One interesting takeaway is that while these technologies won‚Äôt replace our jobs‚Äîespecially for those who understand programming‚Äîthey will create new job opportunities instead.
Now I am capable of how fastapi work and more things and how to structure code and how to design code and most important what to think for project
Dear Sir,
I would like to clarify the situation regarding my previous submission. Initially, I provided an ngrok link, but due to an error with ngrok, it stopped working. I then found an alternative solution using Cloudflare with a custom domain that I obtained through the GitHub Student Pack. I successfully created a tunnel, and it is currently functional. I can shut down my laptop, and it still works with the same URL when I restart.
I hope you will consider my case. I submitted my work at that time because I learned about this solution from a fellow student on Discord. I only changed the URL and made no other modifications.
Thank you for your understanding
Hi @carlton
The same issue has affected several of us. During the last Google Meet session, we explained the situation to @Saransh_Saini.
It seems that when we edit our responses, the timestamp with other values updates not submitted as new response. However, the position of the response in the form remains unchanged. For instance, we submitted our response at 11:30 PM on March 31st, and someone else submitted theirs at 11:45 PM. Even after editing our response the next day, our entry still appears above theirs.
We just wanted to clarify: Will responses edited or submitted on April 1st still be considered, given that the form remains open? If not, is there any way we can show proof of our original submission? Currently, we have email confirmations for both the initial and the edited responses.
We hope this won‚Äôt be a major issue, especially not on the level of Project 1 concerns. Looking forward to a positive resolution from the TDS team.
Thank you
Lakshay
Dear @carlton @s.anand Sir
‚ÄúI‚Äôve deployed my project to Microsoft Azure through GitHub, and my Azure for Students account was verified today. Could you kindly review this project instead of the previous link I shared? While I did not make any changes to the code, you can access and review it directly on GitHub.‚Äù
My Azure credits are burning out. It is giving me unwanted pressure.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a web page displaying the balance of an Azure sponsorship account. The page is part of the Microsoft Azure Sponsorships platform.\n\n**Key Elements and Details:**\n\n* **Page Title:** The title bar displays "oft | Azure Sponsorships".\n* **Sponsored Section:** The main section displays the status of a sponsorship offer, which is currently active and expiring in 349 days.\n* **Donut Chart:** A donut chart visualizes the usage of the sponsorship credit:\n * **Total Credit:** 100 USD\n * **Used:** 26 USD\n * **Remaining:** 74 USD\n* **Subscriptions:** It indicates that there is 1 active subscription.\n* **Dates:** The data is based on usage from Nov 18, 2023.\n* **Side Panel:** The right side has a panel called ‚ÄúSubscription Usage‚Äù with a long alphanumeric subscription ID ‚Äú3de72644-61a8-4056-81ff‚Äù.\n* **Browser Tabs:** The image shows several open browser tabs related to Microsoft Azure and student sponsorships.\n* **Email Address:** The browser window title bar displays the email address "2312004837@ds.study.itm.ac.in‚Äù.\n\nIn essence, the image represents a dashboard showcasing the current balance and usage of an Azure sponsorship program, likely for a student or educational purpose.Screenshot 2025-04-04 at 2.13.30 PM2458√ó1180 207 KB
Please evalute the project early.
we can help in writing evaluation script, that also would be a learning for us.
@carlton @Jivraj @Saransh_Saini
Dear Sir @carlton,
Sir, please note that after the deadline I haven‚Äôt resubmitted the form but I have edited it (as the form was allowing editing till then). Now what exactly have I edited is just added a ‚Äú/‚Äù at the end and that‚Äôs it and nothing more. Highlighting it again, I haven‚Äôt resubmitted the form but edited it on the very next morning after the deadline.
So now my question is: My edited response will be accepted right in this case?
Sir, please throw some light on my doubt.
Warm Regards,
Tensed TDS Student
@carlton . Hi sir, I also edited the form after deadline. I just added /ask in the end‚Ä¶
any update on this would be appreciated @carlton @Jivraj
I would like to clarify something, I had gotten a couple of get requests on my ngrok api endpoint .(but I had set it up for post req as per the P2 details) .Wanted to know if this is requests from ur side. Thank you
@carlton @Jivraj @Saransh_Saini
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a terminal or command-line interface output. It\'s filled with lines of text indicating log entries, likely from a web server or application running on a system.\n\n**Detailed Breakdown:**\n\n* **Timestamp:** Each line begins with a timestamp in the format "Apr 05 14:xx:xx", indicating the date and time of the log entry.\n* **Log Source:** Following the timestamp is "TDS python[79249]: INFO", which seems to indicate that the log messages originate from a Python process (specifically, the TDS component) with process ID 79249.\n* **Log Messages:** The remaining portion of each line represents the log message itself. These messages primarily consist of HTTP request details, including:\n * **IP Address:** Numbers like "162.243.238.100" indicate the client IP address making the request.\n * **HTTP Method:** Keywords like "GET" and "PROPFIND" denote the HTTP request method used.\n * **Requested Resource:** The path following the HTTP method (e.g., "/," "/favicon.ico," "/.well-known/security.txt") indicates the requested file or resource.\n * **HTTP Status Code:** Numbers like "200 OK," "404 Not Found," and "405 Method Not Allowed" represent the HTTP status code returned by the server, indicating the success or failure of the request.\n* **Repetition:** Many of the log messages are repeated, suggesting a pattern of requests being made to the server. Notably, there are many "404 Not Found" errors, indicating that the client is requesting resources that do not exist on the server.\n* **Color:** The terminal background is a dark green. The text is white.\n\n**Overall, the image depicts a log stream from a web server or web application that is handling HTTP requests, with a number of requests resulting in "404 Not Found" errors.**Screenshot 2025-04-05 2323531758√ó564 57.8 KB
something‚Äôs cooking‚Ä¶  And it doesn‚Äôt seem like good news for us ‚Äî at least from the initial visuals.
@carlton I‚Äôm noticing frequent requests from globally scattered IPs‚Äîmostly from cloud or bulletproof hosts like DigitalOcean, Contabo, and Azure‚Äîtargeting sensitive paths like /t4, /logincheck, /.env, and /.git/config. These include IPs from places like New York (162.243.238.100), London (34.89.64.89), Amsterdam (45.148.10.172), Moscow (84.201.151.18), Jaipur (103.175.163.104), and Vilnius (85.255.108.243). It really seems like automated vulnerability scanning or botnet activity. Carlton, what can I do??
Several students have made the exact same problem. We are looking into it.
The evaluation script is ready and the evaluations are going on. So have no worries, your $75 are enough to carry out several evaluations.
My server shut down can you ask me to run the server again? @carlton @Jivraj @s.anand
I‚Äôm running the servers now, i got a bunch hits from random ip s what is the ip address i add a verification if need be
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [15355]
INFO:     Stopping reloader process [11917]
@carlton @Jivraj @Saransh_Saini .
23f1002382@ds.study.iitm.ac.in@tdsproj2:~/tds-solver_NEW$ ps -a
PID TTY          TIME CMD
24617 pts/0    00:00:01 python3
24619 pts/0    00:00:00 python3
24620 pts/0    00:00:01 python3
24645 pts/0    00:00:00 ps
ran it again. You can see from the process id that was actually a process that was started long back
Also a better evaluation strat would be to submit the GitHub repo in the form(Else they can make changes to the repo, who checks the commit history?) and maybe conduct a 2 min demo where the student clones the repo and then you run the script?
I know many students are there but other subjects do it for project courses?
Maybe a helpful tip for next time
If i do fail and repeat this course. Hopefully not XD
@carlton @Jivraj @Saransh_Saini I too faced the same issue, I received a bunch of hits from random ip addresses and it got shut down.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image shows a terminal or command-line interface displaying a series of log entries. The background is black, and the text is predominantly green, creating a classic "hacker" or system administration aesthetic. \n\n**Content Breakdown:**\n\n* **Warning:** The first line reads "WARNING: Invalid HTTP request received." This indicates that the system has detected a potentially problematic web request.\n* **Log Entries:** The majority of the image consists of lines starting with "INFO:" followed by an IP address (104.234.115.27 or 154.81.156.35), a timestamp, a "GET" request, a file or directory path being requested, the "HTTP/1.1" protocol version, and a "404 Not Found" error. \n* **Request Paths:** The requested file paths include:\n * `/` (root directory)\n * `/manage/account/login`\n * `/admin/index.html`\n * `/index.html`\n * `/webpages/login.html`\n * `/cgi-bin/login.cgi`\n * and others, suggesting someone is attempting to access various login or administrative pages on a web server.\n* **Error Type:** The consistent "404 Not Found" message indicates that the requested files or directories do not exist on the server.\n* **IP Addresses:** The log entries originate from two IP addresses: 104.234.115.27 and 154.81.156.35.\n* **Final Line:** The last line is "INFO: 154.81.156.35:54234 - "GET / HTTP/1.1" 404 Not Found"\n\n**Interpretation:** The image strongly suggests a potential attempt to probe or attack a web server. The repeated requests for login pages and administrative interfaces combined with the "404 Not Found" errors are common signs of a bot or attacker scanning for vulnerabilities. The "Invalid HTTP request received" warning further supports this.Screenshot 2025-04-06 at 12.37.36 PM1340√ó1132 196 KB
I started it once again. Can you please reevaluate it now if it hasn‚Äôt been done yet. I actually tested it till 3rd of April and it was working fine. I don‚Äôt know what actually happened. Please do consider.
Actually in the free tier there are many issues. These issues are beyond our control and I request the TDS team to please consider this issue and please consider re-evaluating it if it has not been done yet as we had put in a lot of efforts.
i havent recieved any pings yet . Has it pinged everyone or is it still coming batch by batch
Now my token is expired?
They revoked token access?
My env only shut down its running again lol
You have used 11 requests this month (2025-04), costing 0.01 USD.
so maybe you guys have not hit my server yet im guessing
154.81.156.35:57962 this ip keeps pinging , is this the teams? @carlton @Jivraj
Just do a geographic search on the ip
Even am getting random requests from US,Netherlands, Singapore etc‚Ä¶ what might be the reason 
Hi @23f1002382
I re-ran evaluation on your endpoint, and it completed successfully.
They are malicious probes. A global cyber war is going on. So anything that can be compromised is being probed.
@carlton sir
A lot of us have hosted on Azure and other platforms and were wondering by when we could expect project 2 marks so that we can take this down ? Could we have rough idea as to when the results will be available ?
@Carlton, I believe you all have evaluated it. For me, there are some requests from a known IP with the following location details:
{'status': 'success', 'country': 'India', 'countryCode': 'IN', 'region': 'TN', 'regionName': 'Tamil Nadu', 'city': 'Chennai', 'zip': '600042', 'lat': 13.0895, 'lon': 80.2739, 'timezone': 'Asia/Kolkata', 'isp': 'IIT Madras', 'org': 'IITM', 'as': 'AS141340 IIT Madras', 'query': '103.158.43.17'}

This request was made at 4:38:19 IST.
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a terminal or console output. It consists of multiple lines of text indicating log entries.\n* **Log Format:** Each line appears to follow a similar format:\n * **Timestamp:** Begins with a date and time (e.g., "Apr 06 11:08:19").\n * **Process Identifier:** Followed by "TDS python[79249]".\n * **Info Level:** The word "INFO:" appears next.\n * **IP Address/Port:** A set of numbers that looks like an IP address and port (e.g., "103.158.43.17:0").\n * **Request Type/Status:** A string detailing a request, such as ‚Äú- "GET /favicon.ico HTTP/1.0" 200 OK‚Äù or "- "POST /api HTTP/1.0" 200 OK‚Äù. \n* **Repeating Pattern:** The lines primarily detail "POST" requests to "/api" and a "GET" request for "/favicon.ico" with a "200 OK" status, suggesting successful HTTP requests.\n* **Command Prompt:** The bottom line displays "azureuser@TDS:~$", indicating a user named "azureuser" is logged into a system named "TDS" and is at the root directory.\n* **Color Scheme:** The text is predominantly white displayed on a black background, which is a typical console/terminal color scheme.\n\n\n\nIn summary, the image shows a log of successful HTTP requests (POST and GET) made to an API, logged on a system named "TDS" by a user named "azureuser".Screenshot 2025-04-06 1703051231√ó173 5.14 KB
Are the evaluations done by any chance? I havent received any requests from an Indian IP address yet‚Ä¶
Evals are going on. I just checked my logs, it seems like we ran evaluation on your endpoint, but it looks like your server wasn‚Äôt running.
But i tried and its working can you let me know what I can do?
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a software interface, likely a tool for making API requests or testing web services. It has a dark theme with a lot of text and parameters visible.\n\n**Key Elements & Details:**\n\n1. **Top Bar:** Displays the request method as "POST" and the URL as "4.213.61.248:8080/api". A "Send" button is present.\n2. **Tabs:** Below the URL are tabs for "Params", "Authorization", "Headers", and "Body." The "Body" tab is currently selected.\n3. **Body Parameters:** Within the "Body" section, there‚Äôs a parameter named "question" with the text ‚Äúwhat is output of -s?‚Äù as its value.\n4. **Response Area:** A large text area shows a JSON response. The response begins with ‚Äú{‚Äù and contains key-value pairs detailing system information.\n5. **JSON Response Details:** The JSON response includes parameters such as:\n * ‚Äúanswer‚Äù with a string containing version details.\n * "Darwin arm64 24.2.0"\n * ‚Äú6.0.6‚Äù\n6. **Status Information:** At the bottom, there\'s a status indicator: "200 OK 5.00 s - 2.08 KB", suggesting a successful request.\n7. **Tabs beneath body:** There are tabs for Body, Cookies, Headers, and Test Results.\n8. **Line Numbers:** The response area has numbered lines (1, 2, etc) indicating the JSON response is a multi-line string.\n\n**In essence, the image illustrates a software interface where a request was made to an API endpoint, and the returned JSON response (system information) is displayed.**image1337√ó754 55.1 KB
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a dark screen filled with a large block of white text. It resembles a log or output from a computer program, likely related to an AI or machine learning model. \n\n**Key Observations:**\n\n* **Text-Heavy:** The screen is dominated by lines of text, indicating a verbose output.\n* **JSON-like Structure:** The text is structured similarly to JSON (JavaScript Object Notation), with key-value pairs and nested objects. This suggests the output represents data in a structured format.\n* **"command" Key:** The word "command" appears frequently within the text, suggesting this output is related to commands executed by a system.\n* **"tokens"**: Mentions of "tokens" indicate the text likely relates to a large language model.\n* **Timestamps and Status:** At the bottom, there are timestamps ("14:18:48.336170") and status messages ("200 OK"), suggesting this is a live output of a process.\n* **URL:** A URL ("http://api.HTTP/1.1 200 OK") is present, indicating a network request or interaction.\n* **Filepath**: A filepath ("\\/home\\/study\\/tmp\\/hdrs-00000001\\/hdrs_solver\\/") is present at the bottom of the screen.\n\n**Possible Interpretation:**\n\nThe image likely captures the output from a request sent to an API (possibly a large language model or AI service). The output details the request, its parameters, and the response received, including the number of tokens processed. The filepath suggests this is running on a Linux system.\n\n\n\nimage1914√ó292 40.3 KB
I have been doing this the entire day even yest and getting the output. Can you please check again 
It seems like your server went offline for some reason when we ran evaluations on it. Keep your server running for the next 2 hours, we‚Äôll run a re-evaluation.
Yes sure thank you so much. It is running right now
@Saransh_Saini
The same thing happened to me.
I have not received request from Indian ip as far as I can see on the logs.
Can you please check if my server responded or not ?
I am using Google cloud and the VM was running continuously‚Ä¶
I just now checked it ran! all 5 qs thank you so much!
Your submission was complete successfully. Even your score card has been generated.
Thank you so much sir‚Ä¶
@Saransh_Saini - This is 24f1001631
The same thing has happened to me as the mentioned above. I also have not received request from Indian IP as far as I can see on the logs. I am using the azure VM itself.
I rechecked and maybe the server went offline, so I re-ran the script anyway and checked a few questions now and it works.
I think after a certain while it timed out for me(not entirely sure tho)‚Ä¶ but i fixed it.
ga1 q1
Here\'s a detailed description of the image, point-by-point:\n\n**Overall Impression:** The image is a screenshot of a web-based API request interface, likely from a tool like Postman or Insomnia. It shows the details of a POST request, including parameters, headers, and a JSON response body.\n\n**Key Elements & Details:**\n\n1. **Interface:** The interface has tabs for \'Params\', \'Authorization\', \'Headers\', \'Body\', \'Scripts\', and \'Settings\'.\n2. **Request Type:** The request type is \'POST\' and the URL is `https://tds-project-testing.again.com/api/qi-working-now`. The IP address is `104.211.116.85:8080`.\n3. **Parameters:** There are two parameters: \'question\' with a text value "Install and run Visual Studio Code in your terminal (or...)" and \'file\' with a file selection option.\n4. **Headers:** The \'Headers\' tab indicates there are 9 headers configured.\n5. **Body:** The \'Body\' section displays a JSON response, likely from an API endpoint. It begins with a line noting the response is JSON format.\n6. **JSON Response:** The JSON response contains a nested structure with a key called "answer". Within that, there are several key-value pairs describing system details, including:\n * Version information\n * Darwin version (e.g., 21.2.0)\n * CPU and memory details\n * Various flags with \'enabled\' or \'disabled\' values related to graphics and rendering (e.g., canvas, webgl, etc.).\n7. **Response Status:** A status code "200 OK" and timing information (3.86s, 2.00 KB) are displayed.\n8. **Controls:** There are \'Send\' and \'Share\' buttons present.\n\n**In summary,** the image depicts an API request and its JSON response, showing information about a system\'s capabilities and configurations. It appears to be a debugging or diagnostic tool output.image1378√ó866 65 KB
ga5 q5
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image shows a screenshot of a Postman interface, likely used for testing an API endpoint. It appears to be a request being made with data attached, and a response has been received.\n\n**Key Elements:**\n\n1. **Request Details:**\n * **Method:** POST\n * **URL:** `TDS-Project2-Testing/Again/q5-working` with an IP address `104.211.116.95:8080/api`\n * **Body Type:** Form-data\n * **Key-Value Pairs in Body:**\n * `question`: "Sales Analytics at GlobalRetail Insights"\n * `file`: Attached file named "q-clean-up-sales-data(7).json"\n\n2. **Response Section:**\n * **Status Code:** 200 OK\n * **Response Time:** 3.68 s\n * **Response Size:** 143 B\n * **Response Format:** JSON\n * **JSON Response:**\n * Line 1: `{`\n * Line 2: `"answer": "16087"`\n * Line 3: `}`\n\n3. **Interface Elements:**\n * Buttons for "Send", "Save", and "Share".\n * Tabs for "Body," "Cookies," "Headers", and "Test Results".\n * Settings and Authorization sections are also visible.\n\n**In summary:** This image shows a successful API request made with a text question and a JSON file as input, and the API has returned a JSON response with an "answer" field containing the value "16087."image1384√ó644 48 KB
@Saransh_Saini
Hi sir, can you check and say if my server has been evaluated?
roll no.23f3000975
thank you in advance
Yes you have been evaluated.
You have been evaluated @ItsMeAlex
Thanks Saransh.
PS: Just wanted to know how did u automate the testing of something like this?(Postman?)
Create a shell script that loops through the list of API endpoints and uses curl to send requests to each. You can pass headers, authentication tokens, or data as needed.
@Saransh_Saini
Hi sir, just wanted to know when will the results be released. And also in the image I attached it I think shows five different scores for each questions you asked through curl. Is that the mark for each questions and total mark should be considered?
also want to know if we need to do any extra projects for the bonus marks.
thank you
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a computer terminal window displaying a log output from a program likely related to data science and question answering. The screen is filled with text-based information, indicating the program is processing queries and interacting with various resources.\n\n**Key Elements & Details:**\n\n1. **Terminal Window:** The entire image is framed as a terminal window, evidenced by the title bar at the top indicating tabs for "DEBUG CONSOLE", "TERMINAL", "PORTS", "QUERY RESULTS (PREVIEW)", and "COMMENTS." \n2. **Log Output:** The main content consists of lines of text, structured as log entries. These entries detail the program\'s activity, including:\n * **File Paths:** Repeated references to file paths like "E://data science tool//GA2//third.py", "E://data science tool//GA3//second.py" suggest the program is executing Python scripts.\n * **HTTP Requests:** Lines like "48.43.17:0 - "POST /ask HTTP/1.1" 200 OK" show the program is making POST requests to a server, and the server is responding with "200 OK" status indicating success.\n * **Processing Questions:** Log messages such as "Processing question: LexiSolve Inc. is a startup that delivers a conv" indicate that the program is being asked questions and attempting to process them. The questions relate to concepts like startups, databases, API access, and data analysis.\n * **Scores:** Each log line includes a score (e.g., 12.96, 5.90, 7.78, 14.50). This could represent a confidence level, relevance score, or similar metric related to the question processing.\n3. **Timestamp and User Information:** The bottom of the image displays a timestamp ("06/04/2025 22:40") and user information ("REDMI NOTE 11").\n4. **Background:** The background is a dark, grey-ish blue, typical of many terminal windows.\n\n**In summary:** The image showcases a data science tool processing natural language questions, potentially interacting with an API, and logging its progress to a terminal window. It appears to be in a development or testing phase due to the verbose log output and file paths visible.10000831091920√ó1446 286 KB
i am running via ngrok , and have recieved no pings yet please check
This Makes sense. Thanks.
please send complete screenshot ..
@Saransh_Saini and @carlton  sir ..
Please check my link sir and please use http instead of https , I have submitted the link correctly ‚Ä¶Kindly co-operate..
Postman can‚Äôt be used for automation. Had to write a script for the entire process.
@Saransh_Saini I see a lot of 308‚Äôs as status codes in the logs I can see on render. Could you let me know if testing of my project was successful? Or if I did something wrong? My roll number is 21f2001573.
(A hint on my score would be welcome. ^_^)
can u please check 23f3001787 as i havent recieved any hits on my ngrok logs
Thanks lol maybe i wont fail XD. But really thanks
Lol that question was only right for you XD
@Saransh_Saini
Sir can you please check 24f2000940?
@Saransh_Saini could you please give indication of how long we should keep the server running? Is it ok to shut those down now or will more evaluations be conducted?
You have been evaluated.
Your app crashed during the initial evaluation. But the re-run was successful.
@Jivraj sir could you please check for 24f2003130‚Ä¶ Today‚Äôs morning there was a glitch in my vercel‚Ä¶but I think since it was after evaluation it shouldn‚Äôt have impacted that‚Ä¶could you please verify it once
@Saransh_Saini a gentle reminder.
You have been successfully evaluated
thank you , so I can shut my ngrok session now right
Keep it running for the next hour, have to generate your report/
@Saransh_Saini
Hello sir, can you please say when can we expect results to be published? .
Also we would like to know still how much time or days should our server be running?
Thankyou in advance
can you share your email id
will I know if its done generating ?
@saransh_saini @carlton Can we kindly expect the result for Project 2 today?
No, but we‚Äôll release the first batch soon.
Hello  @carlton @Saransh_Saini @Jivraj Could you please share an update on the expected results for P2? Also, could you confirm whether my evaluation has been completed?
Additionally, when would it be safe to stop the VM, as it is consuming a significant amount of credits?
Looking forward to your response.
Thanks and Regards.
@Saransh_Saini
is my evaluated yet? lemme know due to credit on azure need to check them also.
Hello,
I wanted to provide an update regarding the issue I faced while I was in Jammu. During my stay, my laptop was on, but I encountered an error that caused my endpoint to crash. It seemed that Cloudflared mentioned needing an update, which I believe contributed to the problem.
Now that I‚Äôm back in Delhi, I‚Äôm connected to the internet, and I‚Äôm happy to report that my endpoint is working again.
see this image I have designed my endpoint to monitor with discord webhook
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a dark-themed screen capture of what appears to be a system monitoring or debugging interface. It contains text-based logs, along with the IMDB logo and an alert message indicating API issues.\n\n**Key Elements:**\n\n1. **Text Logs:** The left side features a bulleted list of text logs detailing:\n * Total Requests: 39\n * IP Address: 43.290.106.157 with 39 requests.\n * Recent Queries related to a technology consulting firm (InfoCore Solutions), a FastAPI application development, and cricket batting stats for "bat batman".\n * Reference to IMDB\'s advanced web search.\n\n2. **IMDB Logo:** Centered within the screen is the distinctive IMDB logo, featuring the letters "IMDB" in a bold, yellow typeface against a black background.\n\n3. **Alert Message:** Located at the bottom of the screen is a prominent red alert message. It states:\n * **ALERT: API Status** - 2023-04-07 13:01:32\n * "The API at app.algooch.tech is currently DOWN or experiencing issues."\n * Status: DOWN\n * Last checked: 2023-04-01 13:01:32\n\n**Overall Context:**\n\nThe image likely originates from a system that is monitoring API access to IMDB data. The alert indicates that the API service at a specific URL is currently unavailable, causing issues with the application. The logs suggest ongoing requests before the API went down.image1543√ó875 50.7 KB
Its done @parthivn28
thank you for the swift response
Hey @Saransh_Saini ,  can you please confirm if my report was created or not so that I can turn off the vm on azure if it has been done already.
Thank you again!
Hi @Saransh_Saini
Hope you‚Äôre doing well.
If the evaluation process has been completed, kindly let us know so that we can stop the Azure Web App service.
My roll number is: 21f3001076.
Thank you!
Best regards,
Lakshay
@Saransh_Saini
Hello sir, my mail id is 23f3000975@ds.study.iitm.ac.in
If possible I would like to know my mark.
Thank you
@Saransh_Saini
Could you let me know if my evaluation is complete? Would like to shut down my vm.
Yes, @21f2000709 Your entire evaluation has been completed, along with your report generation. You may shutdown your VM.



 HARISH.S:

23f3000975


@Saransh_Saini
Sir, is my evaluation and project report generation completed.? can i also close the server?
my roll no.23f3000975
@Saransh_Saini
Sir, I saw from the logs on Cloud Run that my project was probably evaluated on 5th April at around 11:51 PM and all the requests made during that time resulted in 3 response status codes: 302, 307 and 405 by no fault of my app, but rather errors in the request itself. I mentioned the exactly correct URL of my app in the form but the evaluation logs show three different types of URL to which request was made. As I mentioned in the form, my url is of the format ‚Äúhttps://‚Ä¶/api/‚Äù and allows only POST requests.

The app was supposed to allow POST requests and I allowed only POST requests, so GET requests even to correct url resulted in 405 response
When POST requests were actually made, two wrong urls were used for all the POST requests
a. http://‚Ä¶/api/ ‚Üí resulted in 302 response
b. https://‚Ä¶/api  ‚Üí resulted in a 307
whereas the url I gave was of the format ‚Äúhttps://‚Ä¶/api/‚Äù

The logs from Cloud Run
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image shows a screenshot of a terminal or console output. It appears to be a log of HTTP requests and responses, likely from a web server or application. The log entries contain timestamps, request methods, URLs, response codes, and request duration information.\n\n**Specific Elements & Details:**\n\n* **Log Entries:** The screenshot is filled with lines of text, each representing a single log entry.\n* **Timestamp:** Each entry begins with a date and time stamp in the format "YYYY-MM-DD HH:MM:SS.milliseconds". (e.g., "2025-04-05 23:51:12.872").\n* **Info/Request Method:** The entries are labeled with "INFO:" or a HTTP request method like "POST", "GET".\n* **IP Address:** Includes an IP address like ‚Äú169.254.126.49512‚Äù.\n* **URL:** The entries include URLs, such as "https://tdsproject2shiva-962709328549.asia-south1.run.app/api/".\n* **HTTP Status Codes:** The output shows different HTTP status codes, like "307 Temporary Redirect", "405 Method Not Allowed", and "200 OK".\n* **Request Duration:** The requests show duration such as "0 ms", "2 ms", "1 ms", etc.\n* **Color Coding:** The entries have a slight color variation, with yellow indicating the current line being processed.\n* **Scrollbar:** A gray vertical scrollbar is visible on the right edge of the image, indicating that the log output is longer than what is currently displayed.\n\n**In Summary:**\n\nThe image presents a log of HTTP requests and responses being processed by a server, which includes timestamps, request methods, URLs, response codes, and durations. It\'s commonly seen during the development or debugging of web applications or APIs.image982√ó552 133 KB
As you can see from the above logs, all POST requests made to my app have the wrong url, some have only http and some end with ‚Äú/api‚Äù instead of ‚Äú/api/‚Äù, both of which do not match with the correct url I gave in the Google Form (screenshot attached below).
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a screenshot of a web form titled "TDS Project 2 - Jan 2025".\n* **Form Instructions:** The form requests the user to log in with their iitm.ac.in or work email ID and states they can submit only one response, but can correct it after submission.\n* **User Email:** The user\'s email address (22f3000819@ds.study.iitm.ac.in) is displayed, noting it was recorded upon submission.\n* **GitHub Repository Link Request:** The form asks for the link to the GitHub repository containing the code for Project 2, with an example format provided (https://github.com/user-name/repository-name). The provided link is: https://github.com/RichPerspective007/tds_p2.\n* **API Endpoint Request:** The form requests the link to the API endpoint and asks that it receives a POST request. The provided link is: https://tdsproject2shiva-962709320549.asia-south1.run.app/api/.\n* **Form Design:** The form has a light gray background, with the questions and instructions in dark gray text. The submitted links are displayed as blue, clickable hyperlinks.\n* **Overall Impression:** It appears to be a submission form for a student project (TDS Project 2) related to data science or technology, requiring the submission of code repository and API endpoint links.image831√ó645 41.7 KB
I request you to re-evaluate my project 2 with the correct url exactly as I had submitted in the Google Form.
Thank you.
Regards,
Shivaditya
@Saransh_Saini
One more thing‚Äîcould you please clarify whether the evaluation process includes both types of responses mentioned in post number 202?
You have been evaluated.
You have been evaluated, successfully.
@Saransh_Saini Have I been evaluated? My roll number is 21f2001573.
@Saransh_Saini  Is my project evaluation done yet? my Roll no.: 24f1002555
@Saransh_Saini
Hi sir, when will be project 2 results released for all?
Thanks,
Sujay D
My IITM student dashboard on the portal shows absent for course project (COURSE PROJET - Absent). Is this referring to project 1 or 2? Coz i missed Project 1 but submitted Project 2 successfully. Also the logs show that the evaluation was performed on the submitted enpoint. So should I be concerned about the dashboard showing ‚ÄòAbsent‚Äô or will it be updated in a few days?
Hello @Saransh_Saini can you please confirm if my report was created or not so that I can turn off the vm on azure if it has been done already.
@Saransh_Saini when can expect result today or tomorrow or later?
Probably in 2 days time assuming no problems or other unforseen errors occur.
@Carlton @Saransh_Saini, it would be helpful if you could specify a date ‚Äî a clear deadline
We cant specify a clear deadline. If we could we would. At the present time there are roughly 100+ evals left in the pipeline. And we retry them to give students the best chance of getting a score. Sometimes we accomodate some unusual situations that we have been made aware of but all of those interrupt our workflows and so it takes time. Which makes this process a little unpredictable.
This is the first term where we have had students deploy solutions that require significant compute resources on our end to evaluate. So there was always going to be hickups. But i think that we have delivered an equally enriching learning experience as a result which is enough to land you an actual job. (Might not be so enriching on your CGPA admittedly, but thats a small price to pay for invaluable skills you hopefully have gained)
@carlton Could you clarify if some kind of a normalisation will be done this time as well? Or if some bonus marks will be given? Last time, it didn‚Äôt help as much because the highest marks were 16.
Normalisation is only helpful when no one scores the top marks.
It will be similar in case the top cumulative score after the ET is, say, 90‚Ä¶ @carlton
@Saransh_Saini @carlton Please can you tell me whether my evaluation is done or not. For roll no: 22f2000946
If yes, I will stop my VM. I am running low on credits.
We will complete evaluation in two days. We will also send out a mail today for those whose evaluation has been completed
sir i am unable to work with other things on my laptop
Here\'s a detailed description of the image:\n\n* **Overall Impression:** The image displays an error message, indicating a problem loading a webpage.\n* **Visual Elements:**\n * **Icon:** A minimalist, black-lined icon resembling a broken computer monitor with an "X" on each screen.\n * **Text:** The message "Aw, Snap!" is prominently displayed in a large, simple font. \n * **Error Explanation:** Below that, it reads "Something went wrong while displaying this webpage."\n * **Error Code:** The specific error code is noted as "Out of Memory."\n * **Link:** A blue, underlined link states "Learn more".\n* **Background:** The background is a pale gray with a subtle, fine grid pattern.\n* **Color Palette:** The dominant colors are white, gray, and black, creating a clean, minimalist aesthetic typical of error pages.\n\n\n\nimage712√ó574 6.41 KB
because laptop giving error because my system ran out of memory and because api working continuously more than 1 week
@carlton @Saransh_Saini
This is a gentle reminder to kindly send the confirmation email indicating for whom the evaluation of Project 2 has been completed.
Additionally, I would like to confirm whether we can shut down our Azure VM after this, or if we should keep it running in case there is an additional evaluation. In one of the sessions, you had mentioned the possibility of offering alternate questions as a second chance for students, evaluated at half the original marking scheme (i.e., 2 marks per question).
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image shows a screenshot of a Vercel Function invocation log, likely from a web application or serverless function deployment. It details function executions, responses, and potential errors.\n\n**Key Elements & Details:**\n\n1. **Timeline:** A timeline at the top displays execution times:\n * `APR 09 00:11:08.94`: POST 504 to `/api`\n * `APR 09 00:11:08.79`: POST 307 to `/api`\n\n2. **Logs:**\n * There are 3 total logs listed.\n * `00:11:07.064`: Email ID `231000598@ds.study.itm.ac.in`\n * `00:11:07.112`: Email updated in `index.html`\n * `00:11:07.140`: **Failed to trigger workflow**: 401 - `{"message":"Bad credentials", "documentation_url":"https://docs.github.com/rest", "status": "401"}` - This is a critical error indicating authentication failure, likely with a GitHub workflow.\n\n3. **Function Invocation Details:**\n * **Route:** `/main.py`\n * **Location:** Washington, D.C., USA (iad1)\n * **Runtime:** Python 3.12\n * **Execution Duration:** 10s / 10s\n * **Memory Used:** 214 MB / 1624 MB\n\n4. **Deployment Information:**\n * **Deployment ID:** `dp1_EFXAUNYSadokslSmpbQc65j6-`\n * **Environment:** production\n\n5. **Status Indicators:**\n * There\'s a red "X" indicating a firewall error.\n * "Response finished" is displayed.\n * There are warning messages related to timeout.\n\n**Summary:**\n\nThe image displays a Vercel function failing due to ‚Äúbad credentials‚Äù during a workflow trigger. The function is running Python 3.12, and the application is deployed in a production environment. The logs and metrics provide useful information for debugging and performance analysis.image2342√ó990 233 KB
Hello @Saransh_Saini , @Jivraj
Sir When i test it locally , my LLM is working fine , even running the app , it gave result in 2 sec ,
I dont know what happened in the logs , it was showing some runtime error ,
As i am using free plan of vercel , so it allow for 10 sec only ,
I think any heavy file being run , so it just take some more time , more than 10 sec , but inbuild feature of free plan allow to run only 10 sec ‚Ä¶ and thats why this happened , i guess
does it means , my LLM failed ??
Can you please try some other question , it will work , or even for heavy question it work ,
You can check its working from interface too
Please check once !!
We will be sending out emails to both sets. Ones who have to keep it on and ones who can shut it down. If you have not received a shutdown notice, assume that you have to keep it on. I apologise for the late reply, we ran into some unforeseen problems, hence the delay.
Thank you for your patience,
Kind regards
@carlton, @Jivraj, @Saransh_Saini
Respected Sir,
I received an email stating we have to turn on URL endpoint again. I am using free version of NGROK if I want to re-start my application then my NGROK URL  will change and the forms are closed. What Should I do ? this is urgent.
@Saransh_Saini @carlton sir today I received this email
Here\'s a point-by-point description of the image:\n\n* **Type:** The image is a screenshot of a text-based message or email.\n* **Content:** The message is an announcement regarding ongoing server checks for "TDS Project 2." It instructs users who previously turned off their services due to a false completion notification to turn them back on.\n* **Tone:** The message is apologetic for the inconvenience and assures users that evaluations will be completed promptly, keeping in mind that some may be utilizing cloud credits. \n* **Format:** The text is formatted as a formal communication with a greeting ("Dear Learner") and a closing ("Kind regards").\n* **Emphasis:** Certain phrases are emphasized using **bold** text.\n* **Background:** The background is white, creating high contrast with the black text.image1408√ó305 10.9 KB
I have did not turned it off it is just that the first request take time of 50 to 60 sec as you can see in the image.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image depicts a software interface, specifically a request/response window likely from a tool like Postman or Insomnia, used for API testing. The interface is dark-themed.\n\n**Key Elements:**\n\n* **Top Bar:** Shows the name of the request ("Untitled-1") and the URL ("https://tds.pro..."). There\'s also a "Save" button and an environment selection dropdown.\n* **Method Selection:** The request is set to "POST."\n* **Tabs:** Various tabs are present including "Params," "Authorization," "Headers," "Body," "Pre-request Script," "Tests," and "Settings."\n* **Query Params Section:** Contains a table with "Key" and "Value" columns, but currently appears empty.\n* **Body Section:** Displays a JSON response with the following content:\n * `{"answer": 1, "tag": "1"}`\n* **Status Indicator:** In the upper-right corner, a status indicator displays: "Status: 200 OK, Time: 53.13 s, Size: 34 B." \n\n**Overall, the image depicts a successful API request (POST) with a JSON response. The status indicates the request was completed successfully (200 OK).**image1842√ó974 33.9 KB
and it also take same time in linux
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image captures a terminal or command-line interface displaying a `curl` command and its response. The background is black, and the text is primarily white/light green.\n\n**Detailed Breakdown:**\n\n1. **Command:** The top portion displays a `curl` command line. The command includes the URL, and parameters related to a POST request (indicated by `-X POST`) and content type (`-H "Content-Type: multipart/form-data"`). The command also includes a question as data, which asks to calculate a formula in Google Sheets. The formula is: `SUM(ARRAY_CONSTRAIN(SEQUENCE(100, 100, 5, 2), 1, 10))`\n\n2. **Response:** Below the command is a JSON-formatted response. \n * The response indicates an "answer" field with the value "140".\n\n3. **Prompt/Username:** At the beginning and end of the lines there is a prompt like ‚Äúsahil@DESKTOP-N2T75T0:~$" indicating the user and computer.\n\n**In summary:** The image showcases a request to calculate a Google Sheets formula using a `curl` command and the corresponding result (140) being displayed in the terminal.image965√ó175 6.84 KB
Please allow some time for my server hosted on Render to initialize, as it may take a moment to become fully active.
Thank you for your patience and understanding.
Just reply to the email that I have sent to you regarding your query. We will make exceptions for students facing this issue of having a changed end point due to the way ngrok works.
Kind regards
Humble Request to Update API Request Link
Dear Team,
I hope this message finds you well. I‚Äôm reaching out to kindly ask if it would be possible to update my API request link for project 2 in TDS. I realized that I mistakenly used the wrong endpoint in my earlier request.
Previous API Request Link:


project2llm-production.up.railway.app


IITM Assignment API - Swagger UI





Correct API Request Link:
https://project2llm-production.up.railway.app/api/
https://project2llm-production.up.railway.app/api/
Would it be possible for you to allow me to make this change, or kindly update the link on my behalf? I sincerely apologize for the confusion, and I‚Äôd be truly grateful for your support and understanding.
Thank you so much for your time and consideration.
Warm regards,
Pratyush Pulak Nishhank
Thank you for considering it also one question sir, how long do I have to keep it running ?
But Sir please give some bonus , As in earlier terms , everyone got S grade in TDS , without doing anything , and from this term the difficulty level increased rapidly , just like e^x
Although I know that our LLM doesnt worked fully(100%) , but atleast they worked 50-60%
We have learned so many things  and try to implement in it too,‚Ä¶
Atleast give some bonus for our hardwork , and participating in both LLM project , so even we dont get S grade , but will get B , A , grade ‚Ä¶ and our CGPA doesn‚Äôt decrease much
because projects hold the major chunk in grading
@carlton
Agree with this sentiment.
Hope there are bonus points for participation in discourse as well.
@carlton
i submitted incorrect api request link
my correct api link:
http://127.0.0.1:8000/api/post_ask_question
is it possible to change some how‚Ä¶
suppose i have resolved the hosting issue that the link i provided had now , will u still evaluate as i fixed the issue in response to the email i received on 8th april?
Sir, @Jivraj can I know how long do I need to keep the server running ?
Roll No. 22f200559
It seems you have provided a local address endpoint, which means it will only work on your computer. If I run it on my computer, it will redirect to my port 8000 if it is running.
till your endpoint has  evaluated
@carlton,@Saransh_Saini
sir my roll number is 23f2004462
Due to an unexpected power outage, my PC shut down abruptly, causing my local server and ngrok tunnel to terminate. When the system rebooted, I restarted the server and ngrok, which generated a new API endpoint as ngrok URLs are temporary and change with every session. The previous endpoint is no longer accessible, and the new one now serves as the API endpoint. I understand the need for a consistent URL and will explore solutions like reserving a domain through ngrok‚Äôs paid plan to prevent such issues in the future. Apologies for any inconvenience caused, and thank you for understanding.
New project 2 url:- https://96c8-2401-4900-6290-6a14-b433-2faa-a056-a6e5.ngrok-free.app/api/
@carlton ,@Saransh_Saini
same goes for me sir my pc also shut down
sir my  roll number is 23f2005141
project 2 url https://b2a4-2401-4900-6290-6a14-b433-2faa-a056-a6e5.ngrok-free.app/api/
my project is running and working in vscode but when checked in git its not like
post‚Äî401 unauthorized
i tried making changes today but same issue‚Ä¶
i think its the token but i tried pasting my token in postman‚Ä¶none worked
i used api token, proxy token and even github barrier token‚Ä¶that didnt work either
can anyon explain why
when i ran it local yep its giving me answers
@carlton @Saransh_Saini  Respected sir, by mistake I have submitted the endpoint as : https://tds-project-2-peach.vercel.app/ while the corrected api which is deployed on vercel for direct requests is : https://tds-project-2-peach.vercel.app/api/
The link provided is also working one but this link has the frontend part not the url endpoint.
kindly evaluate me on the basis of the updated link :  https://tds-project-2-peach.vercel.app/api/
Reg. No -  23f1001995
I think my endpoint has been evaluated, given how POST requests stopped after 3pm. Do I still have to keep it on perhaps through overnight, my laptop now has started to heat up. @Jivraj sir any updates whether my evaluation is completed or not ?.
I kindly request,  if you could please consider reevaluating my assignment. This small error was not reflective of the overall functionality, and I‚Äôm worried that the resulting grade might significantly impact my performance and cause me failing  in the course.
Here\'s a detailed description of the image:\n\n* **Content:** The image displays an email inbox message.\n* **Subject:** The email subject is "[TDS Jan 25] Project 2 Announcement".\n* **Sender:** The sender\'s email address is "s221se2002" and is addressed "to bcc:me".\n* **Timestamp:** The email was received at 2:28 AM (18 hours ago).\n* **Message:** The email body states that evaluations on Project 2 endpoints have been completed and instructs recipients to switch off their server. It mentions a score will be provided once all evaluations are finished. The message ends with "Thanks" and a closing from the "TDS Team."\n* **Visuals:** The email is displayed with a gray background as if it\'s a screenshot of an email client interface. There is a letter "s" next to the sender‚Äôs address.Screenshot 2025-04-09 2115351416√ó385 20.7 KB
I have received this message do this message suggest that my evaluation is successfully completed coz I forgot to add /api at the end of my vercel url . Or is it like the submission had ran but ultimately produced my score 0. If this is the case I request you to reevaluate my submission.
@Jivraj @carlton
Respected Course Team,
Harsh this side from NIT Allahabad, I am writing to inform you that I received a notification
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of an email regarding a project evaluation. \n\n**Key Elements and Details:**\n\n* **Subject Line:** "[TDS Jan 25] Important announcement regarding Project 2".\n* **Sender:** 22ti sa2002 .\n* **Recipient:** "to me".\n* **Timestamp:** 2:26 AM (20 hours ago).\n* **Email Content:**\n * The email starts with a greeting ("Dear Learner").\n * It requests recipients to not ignore the announcement, as server endpoint checks for TDS Project 2 are still in progress.\n * It asks those who turned off their systems (presumably cloud instances) believing the evaluation was complete to turn them back on.\n * An apology is given for any inconvenience, and the email clarifies that the evaluation process is being expedited to prevent unnecessary usage of cloud credits.\n * A promise is made to notify recipients when the evaluation is complete to avoid them running their systems longer than necessary.\n * The email is signed "TDS Team."\n* **Note at the Bottom:** A disclaimer states that the email is for official announcements only and to contact the course team via Discourse for further assistance.\n* **Footer:** "We Resource" is visible at the very bottom.\n* **Buttons:** "Reply" and "Forward" buttons are present.\n\n**General Style:** The email has a formal tone and is likely a mass communication sent to students or participants of a "TDS" (likely a course or program) project.image2096√ó1154 160 KB
regarding an issue with my submission.
I believe the issue may have occurred because I had mistakenly provided an incorrect API endpoint in my earlier submission. However, my server is still actively running on Vercel
https://tds-project-2-peach.vercel.app
and the correct API endpoint is:
correct api : https://tds-project-2-peach.vercel.app/api/
Everything else in the project is functioning as expected. I kindly request you to re-evaluate my submission using the correct endpoint as i am currently in my 3rd year of BTech Chemical engineering at NIT Allahabad and my placement session is coming so i don‚Äôt want to get failed in this course due to such a small mistake.
Thank you for your understanding and support.
Hello sir
can you check and say if my server has been evaluated or not ?
My roll no : 23f3003871
My endpoint is working smoothly, I am showing it to you in this photo.
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a close-up screenshot of a computer screen displaying a code editor window. It appears to be a Python code snippet within a Google Colaboratory environment. The code relates to downloading, processing, and analyzing data from files with different encodings.\n\n**Detailed Breakdown:**\n\n1. **Environment:** The top of the screen shows a Google Colaboratory address in the browser, indicating it\'s running within the Colab cloud-based Jupyter Notebook environment. A reCAPTCHA request is visible, asking the user to confirm they are not a robot.\n2. **Code Editor Window:** The main portion of the image features the code editor window. The file is named "Untitled79.ipynb," indicating it\'s a Python notebook. Tabs for "Code" and "Text" are visible.\n3. **Code Content:**\n * The code begins by defining a URL to an API endpoint.\n * It then opens a zip file named \'q-unicode-data.zip\' in read binary mode (\'rb\').\n * The code defines a question related to processing the files within the zip, which contains three CSV files with different encodings (CP-1252, UTF-8, UTF-16).\n * The task is to sum the values associated with symbols that match specific characters across all three files.\n * The code prepares to send a POST request to the defined URL, attaching the files and data.\n * It includes lines to print the status code and text response from the API.\n4. **Output:** Below the code, there‚Äôs a section showing the output of the script. It displays a status code (200) and a JSON response with a key-value pair: `"answer": 39961`.\n5. **Interface Elements:** At the very bottom of the screen are tabs indicating open webpages. Also visible are the system tray icons.\n\n**Overall, the image depicts a data analysis task being performed in a Python environment, involving file processing, API interaction, and data summation.**10000027021920√ó1440 391 KB
@carlton @Saransh_Saini
urgent !!
hello sir my roll no.23f3000975
My laptop has been on for nearly twelve days. Due to some reasons my laptop restarted automatically and terminated the ngrok server. So i restarted my ngrok server and here i attach its url along with its endpoint ‚Äúask‚Äù.
https://e95b-2405-201-e04b-d085-9cf5-4f92-fe5a-309e.ngrok-free.app/ask
kindly reply soon SIr‚Ä¶
@carlton @Saransh_Saini sir, please reply
@Saransh_Saini
Hello sir, could you please confirm whether I have been evaluated or not?
Roll_No.: 23F3004186
Here\'s a detailed description of the image:\n\n**Overall:**\n\nThe image displays a screenshot of an email titled "TDS P2 Endpoint." It appears to be a communication regarding an API endpoint.\n\n**Key Elements:**\n\n* **Sender:** The sender‚Äôs name is ‚Äú23F3004186 VISHNU KUMAR JHA‚Äù with the email address ‚Äú23f3004186@ds.study.iitm.ac.in‚Äù.\n* **Recipient:** The email is addressed ‚Äúto 22f1001123‚Äù.\n* **Content:** The email content is a brief message to "Saransh" stating the sender is providing the public endpoint for their P2 API. The endpoint URL is: `https://vishnu-dns.centralindia.azure.com/api`.\n* **Roll Number:** The sender provides their roll number: 23F3004186.\n* **Closing:** The email ends with "Thank you," and the sender\'s name, "Vishnu Kumar Jha."\n\n**Additional Notes:**\nThe email has a very simple text-based format. The context indicates it‚Äôs likely related to a technical project or assignment.Screenshot 2025-04-10 100458718√ó524 36.7 KB
@carlton , @Jivraj , @Saransh_Saini
sir,
I kept my laptop on overnight, but in the morning I see my vs-code application and ngrok server along with google chrome was closed on it‚Äôs own. I am confused, do I have to run again ? or my enpoint has been evaluated.
i also got this same problem.
Do all of us have to give the latest project link or only those whose links have actually changed. @Saransh_Saini @carlton @Jivraj.
Basically should we resubmit the link using the form sent today if our link has not changed?
PS: Maybe send a mail to everyone to update the access of their GA7 links to viewer for everyone at IIT Madras.
Just submit whatever is the latest working link. You do not have to submit a new form if you have received an email that said your evaluation was completed.
We already sent an email asking people to update their ga7 permissions
@Saransh_Saini
Could you let me know if my evaluation is complete?
@carlton , @Jivraj @s.anand @jkmadathil
Dear Sirs,
Most of us have hosted our projects in Azure and this is costing us real money .. We have just gotten to a stage where if you could just please let us know if our endpoints have been evaluated and there is some score we will happily take it down.
Kindly bear in mind the there is a financial component ( some of us have free accounts ) involved here and I urge and request you to kindly expedite the evaluation process so that we decrease the financial burden placed upon us by this exercise‚Ä¶
@carlton @Jivraj @Saransh_Saini
Sir, please confirm me whether I have been evaluated or not. Because my azure balance is reducing day by day.
@carlton @Jivraj @Saransh_Saini
I just got the mail stating that my evaluation is complete and I can turn off my server.
However the Cloud Run logs show that all POST requests were made to the wrong end point.
The exact url I gave ends with ‚Äú/api/‚Äù but every POST request was either made to ‚Äú/api‚Äù which resulted in a 307 response or with ‚Äúhttp‚Äù instead of ‚Äúhttps‚Äù which resulted in a 302 response. Only the get requests were made to the correct endpoint but since the app was supposed to allow POST requests only, making GET requests just resulted in 405.
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image shows a screenshot of the Google Cloud Run service details page, likely accessed through a web browser on a mobile device. It‚Äôs displaying log data related to a deployed service.\n\n**Key Elements & Details:**\n\n* **Top Bar:** Displays the website address: `cloud.google.com` along with time (12:16) and signal strength indicators.\n* **Navigation:** The top bar includes navigational icons, a search bar, and likely user account access.\n* **Service Details:** The main section displays details for a service named "tdprojectshiva". It shows status (healthy), region, and a URL for the service.\n* **Tabs:** Across the top are navigation tabs including "Logs", "Revisions", "Triggers", "Networking", "Security", and "Tasks". The "Logs" tab is selected.\n* **Log Data:** The bulk of the image displays log entries. These entries are organized into columns showing:\n * **Timestamp:** Date and time of the log entry.\n * **Severity:** Indicates the importance of the log (e.g. Default, Error, Warning).\n * **Log:** The actual log message. The logs appear to be system messages related to the service\'s operation, deployment, and container startup.\n* **Scroll Bars:** Both vertical and horizontal scroll bars indicate that there is more data available than is currently visible.\n* **Navigation Buttons**: At the bottom of the screen are the usual Android navigation buttons.\n\n**Overall, the screenshot is of a technical interface showing log information for a running service on Google Cloud Run. It suggests someone is monitoring or debugging a deployed application.**10001508681080√ó2340 242 KB
I request you to use the exact url I gave in the gform and make POST requests to it to re-evaluate me. I gave the exact url as asked in the form.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image shows a screenshot of an email message displayed on a mobile phone. The email asks for an API endpoint link. \n\n**Key Elements:**\n\n* **Email Content:** The email body contains the question "What is the link to your API endpoint?" with a field for response. It also states, "Make sure we can send a POST request to this exact URL".\n* **URL:** A specific URL is presented: "https://tdsproject2shiva-962709320549.asia-south1.run.app/api/".\n* **Footer:** The email includes a link to create a Google Form and a question if the form looks suspicious. \n* **Reply Options:** At the bottom are buttons for "Reply," "Reply all," and "Forward."\n* **Device UI:** The screenshot reveals the status bar of a mobile device (time, signal strength, battery). Also, navigation buttons are visible at the bottom of the screen.\n\n**Overall context:** This email appears to be a request for an API endpoint, potentially for testing or integration purposes. The prompt to report the form if suspicious suggests some caution is warranted.10001508721080√ó2340 197 KB
Thanks
Regards,
Shivaditya
@Saransh_Saini @carlton
Hello sir,
I apologize for bothering you again.
About 30 minutes ago, I received an email stating that project 2 has been evaluated. However, when I checked my IP stats, I found there is no special API access. You can verify this. I want to understand whether this is just a wrong email I received or if there is an issue with your system‚Äôs evaluation. Please clarify this doubt, as I am unable to focus on my final term exam.
i closed my local machine too I spent one month on this project please consider my problem
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a terminal or command-line output, likely from a system monitoring or logging process. It details information about API access from various IP addresses.\n\n**Key Elements & Details:**\n\n* **Header:** The first line indicates the script being run: `PS E:\\data science tool\\main\\grok> python uniu.py`. This suggests a Python script named `uniu.py` is executing within a directory structure related to "data science tool" and "grok".\n* **IP Address Listing:** The subsequent lines list five unique IP addresses:\n * 43.230.106.157 (accessed `/api/` 93 times)\n * 52.234.41.123 (accessed `/api/` 48 times)\n * 20.42.17.59 (accessed `/api/` 39 times)\n * 20.57.44.194 (accessed `/api/` 43 times)\n * 172.183.175.198 (accessed `/api/` 39 times)\n* **Endpoint Access:** For each IP address, it indicates that the `/api/` endpoint was accessed a specific number of times, as mentioned above.\n* **Summary Statistics:** At the bottom, it shows that there were a total of 262 calls to the `/api/` endpoint and that 5 unique IPs accessed it.\n\n**In essence, the image represents a log or report of API access events, showing which IP addresses are calling the `/api/` endpoint and how frequently.**image706√ó592 10.1 KB
I checked my Vercel logs and saw that the requests were sent to the /api endpoint instead of the /api/ endpoint that I specifically gave in the google forms.
To confirm this I also sent a request to /api and /api/ enpoints and the /api gave a 404 error while /api/ gave a 200 message.
Please look into this
@carlton @Saransh_Saini
I have mistakenly filled tds-project2-final-omega.vercel.app instead of https://tds-project2-final-omega.vercel.app/api/ in gform, i humbly request you to pls accept this .
@carlton @Jivraj @Saransh_Saini
i have filled gform with 23f1002838@ds.study.iitm.ac.in
i have filled gform for end point edit i hope this will work



 23f2000237:

I checked my Vercel logs and saw that the requests were sent to the /api endpoint i


where did you check it?
Also, on https://www.vercel-status.com/ this is showing
Update - npm have released a status page incident, and users can monitor further updates here: https://status.npmjs.org
Apr 11, 2025 - 03:02 UTC
Monitoring - We have observed authentication issues to private registries using npm access tokens. Affected users may see 4xx errors when installing private packages. Manually regenerating tokens appears to resolve this issue. At this time, there is no official statement from npm or GitHub regarding the root cause.
Apr 11, 2025 - 02:37 UTC
Yes I also got the same email, but when I checked my vercel dashboard I found no such api access. Kindly verify this @Saransh_Saini @carlton
Will we receive scores by today?
Today I got my TDS Project-2 Score and it is showing as absent although I submitted my TDS project 2 , also deployed the app successfully and also filled the g-form
Here‚Äôs my deployed application on-render link with the attached screenshot of my TDS Dashboard:
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a course progress report for a "Tools in Data Science" course. It\'s a screenshot of what appears to be a learning management system interface. \n\n**Key Elements & Details:**\n\n* **Title:** "Tools in Data Science" is prominently displayed at the top, labeled as a "NEW COURSE".\n* **Assignment Scores:** A list of weekly assignment scores is provided:\n * Week 1: 92.50\n * Week 2: 90.00\n * Week 3: 0.00\n * Week 4: 100.00\n * Week 5: 100.00\n * Week 6: Absent\n* **Quiz Score:** A programming quiz score is listed: 90.00.\n* **Course Project Scores:** Two course project scores are displayed: 5.00 and "Absent".\n* **Exam Eligibility:** The question "Allowed to take End Term Exam?" is shown, with the answer "Yes".\n* **Call to Action:** At the bottom, a button with the text "Go to Course page >" invites the user to navigate to the course page.\n* **Background:** The background is a gradient of maroon to dark brown, decorated with small white dots.\n\n**Color Palette:** Predominantly maroon, dark brown, and white.\n\n**Overall:** The image presents a student\'s progress in a data science course, highlighting assignment and quiz scores, and confirming eligibility to take the final exam.image402√ó599 23.3 KB
aap link : https://tds-project2-21f3000591.onrender.com
@carlton @Jivraj
Dear Sir,
In my course dashboard, it shows project 2 status as absent, but i have already submitted the repo and api points well before deadline in the given forum. Still my vercel server is running and api is resolving as expected. Please look into this matter, because I already had issue in my project 1 and lost marks in that. Expecting a positive response from your end.
ID: 21f2000304
@carlton @jivraj @saransh_Saini
hello sir, in my portal the project 2 score is showing absent even after submitting tds project 2 successfully in google form and keeping the server running all the time, please can you recheck it again, deployment link:https://tds-p2-gun1.onrender.com
@carlton @Saransh_Saini @Jivraj
Hello Sir, my project 2 score is showing as 0. I had got email saying please update endpoint because earlier endpoint was having problems. I had sent https://c7f6-150-107-43-5.ngrok-free.app/api/ as updated endpoint in google form on April 10th. Same day I had got around 9 requests on that endpoint around 4:56 PM. They were 200 OK requests on /api/ and 4 requests  were 307 redirect on /api. I presume they were from TDS team. Next day got email to shut off endpoint. I had tested endpoint locally and on ngrok. Both were fine. Was the updated endpoint in the google form evaluated? Was there some problem with the updated endpoint?
@carlton @Saransh_Saini @Jivraj
Please look into this, my portal is showing zero marks
@carlton @Jivraj @Saransh_Saini
My portal is showing 0 even no github repo is made so are evalaution even done???
Pls tell
@carlton @Jivraj @Saransh_Saini
On my portal it‚Äôs showing that Course Project Score 2 - Absent
but I submitted and fill the form also deployed the app successfully.
Namaste Sir. The projects have been quite challenging, and I have applied my knowledge to the best of my ability. I‚Äôve submitted the project but it‚Äôs showing 0 in the portal. Bonus marks for creating APIs and so in the projects would be greatly appreciated. I am planning to start my degree in the upcoming term, and this is the last subject I am completing at this level. So, I kindly request your assistance, sir.
Hello Sir,
For me as well Project 2 scores are showing 0.I have spent alot of time and effort in this project. Please look into it.
@carlton @Saransh_Saini sir ,
I am writing to kindly request a re-evaluation of my Project 2 submission. As I had previously mentioned, the Render deployment link I submitted may take approximately 50 to 60 seconds to activate upon the first load. This behavior is typical of free-tier deployments on Render, and I assure you that the application functions correctly in both Podman and Linux environments.
Upon reviewing my Render logs, I could not find any indication that the project was accessed or evaluated during the expected activation time. To ensure smooth accessibility, I have also deployed the same GitHub repository on Railway and submitted that link as well.
If possible, I kindly request either of the following:

Re-evaluation using the Railway link I provided, or
Re-evaluation using the Render link, with allowance for the 50‚Äì60 second activation time.

Your consideration and understanding in this matter would be greatly appreciated. Please let me know if any further clarification or information is needed.
Thank you for your support and guidance.
@carlton @Jivraj @Saransh_Saini I knew that this affected my project 2 score and that‚Äôs why I made that post(the one to which I‚Äôm replying in this message). Please look into this. My api is working and still on and will be on till 18th April when my credits will run out. Please re-evaluate my project 2 with the exact url I gave in the form. My project 2 was evaluated on the wrong url and this led to a zero in the project 2 score.
Hi sir  @carlton @Saransh_Saini @Jivraj @s.anand
I need your immediate attention regarding my project-2, as I received zero marks, but my server is running completely fine. Below are the key points that I need you to look into:
 Server is running and reachable. and Giving Correct Answers
 GET and POST requests tested via Postman and VS Code, both return 200 OK.
 Tested on my laptop and by 10+ other people ‚Äì all received correct results.
 No issues seen in logs or deployment ‚Äì everything was set up properly.
 Others in my group got full marks ‚Äì we worked on the same project.
 I have no idea what went wrong during the evaluation.
 I‚Äôve spent weeks working on this project, including sleepless nights.
 This is my last term ‚Äì if I fail, I will have to repeat the entire diploma.
Please recheck my project thoroughly. Here are the important links for you to verify:

API Documentation: FastAPI - Swagger UI
API Endpoint: http://shashitdsproject2.centralindia.cloudapp.azure.com/api

I truly believe that my server is functioning as expected, and I just need a re-evaluation to confirm that.
I‚Äôve put in a lot of effort into this, and I sincerely request that you review it again.
as you can see my vm is working fine here
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a Microsoft Azure portal displaying a serial console for a virtual machine named "shashitdsproject2." It shows a command-line interface with text-based output, indicating a system administration or debugging session.\n\n**Key Elements:**\n\n1. **Azure Portal:** The top portion of the image shows the browser interface of the Microsoft Azure portal, including the address bar and search bar.\n2. **Virtual Machine Navigation:** On the left side is a navigation pane with options like "Connect," "Boot diagnostics," and "Serial console," which is currently selected.\n3. **Serial Console Window:** The primary focus of the screenshot is the black serial console window, displaying a scrolling text log. This is a text-only interface to the virtual machine.\n4. **Command-Line Output:** The console displays a series of commands and their output. There are indications of system startup, processes running, and potential issues or error messages (e.g., "sudo command not found").\n5. **Log Information:** The text includes timestamps and log messages related to services like "nginx" and "unicorn," suggesting a web application or server setup.\n6. **Process Details:** Lines show information about running processes, including their process ID (PID), user, CPU usage, and command.\n7. **File Path:** The console shows a file path like "/home/v/.local/share/Trash/files/example."\n8. **Status output:** The image shows output from various processes including "nginx", "unicorn" and "python".\n9. **Error/warning messages:** The image also shows some error or warning messages like "sudo command not found".\n\n**Overall, the image illustrates a system administrator or developer working with a virtual machine in the Microsoft Azure cloud environment, likely troubleshooting an issue or monitoring the system\'s status.**vm start1917√ó1077 110 KB
its running  as you can see here
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a web page displaying the results of an API request. It seems to be a debugging or testing interface, possibly related to a chatbot or natural language processing service.\n\n**Key Elements:**\n\n1. **Web Browser Window:** The screenshot is of a web browser window, likely Google Chrome based on the tab arrangement. Multiple tabs are visible, including "My Drafts," "Graded Assignment," "TDS 2023," and others.\n2. **API Request Interface:** The main content of the focused tab is an interface for making and viewing API requests.\n3. **"Execute" and "Clear" Buttons:** These buttons suggest the user can send an API request (execute) and clear the previous results (clear).\n4. **"Curl" Command:** A text block displays a `curl` command, which represents the API request itself. It includes the URL, headers, and request body.\n5. **"Request URL" Section:** A section labeled "Request URL" shows the URL being requested: `https://shaktidproject2.centralindia.cloudapp.azure.com/api/`.\n6. **"Server Response" Section:** This section displays the server\'s response to the request.\n * **Code:** Shows a status code of "200" indicating a successful request.\n * **Details:** A text field is partially obscured, but it appears to contain information related to the server response.\n * **Response Body:** The `answer` is shown to be `"1902"`.\n7. **"Response Headers" Section:** This section lists various HTTP headers returned by the server, such as `access-control-allow-credentials`, `connection`, `content-length`, `content-type`, `date`, and `server`.\n8. **"Responses" Section:** Displays code and description.\n\n**Overall, the image demonstrates a user testing or debugging an API request, likely related to a natural language processing application or chatbot. The response indicates the API successfully processed the request and returned a value of "1902".**checking ans1913√ó1075 65.5 KB
POST request through  postman vscode
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a screenshot of the Postman application, an API development and testing platform. It appears to be focused on a request being made to a local API endpoint.\n\n**Key Elements & Details:**\n\n* **Postman Interface:** The main visual is the Postman application window. It features the typical sidebar navigation (Workspace, Collections, etc.) and a central request building/testing area.\n* **Request Details:**\n * **Method:** The request type is set to "POST".\n * **URL:** The API endpoint is `http://localhost:8000/api` with a query parameter `shaohidsproject`.\n * **Parameters:** There is a section for "Params" which lists an empty "Key" and "Value" field, indicating no parameters are currently set.\n* **Body Section:** The bottom section displays the "Body" of the request. It appears to contain HTML code, likely returned from the API endpoint, and displays elements related to a Swagger UI interface.\n* **HTML Code Snippet:** Within the body section, lines of HTML code are visible. This code sets up the basic structure for a Swagger UI, with attributes for the `src`, `url`, and `id`.\n* **Status:** The request is indicated to have a "Status: 200 OK", meaning it was successful, with a time of 286ms, and a size of 1.11KB.\n* **Tabs:** The tabs at the top of the body window include, "Pretty," "Preview," and "HTML". The HTML tab is selected, indicating that the HTML source code of the response is being displayed.\n* **Color Scheme:** The Postman interface uses a dark color scheme, typical for developer tools.\n\n**In summary:** The image demonstrates a successful POST request to a local API endpoint that returns HTML code for a Swagger UI, likely used for API documentation and testing.post1535√ó1018 36.8 KB
GET request through  postman vscode
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image shows a screenshot of the Postman application, a popular tool for API testing and development. It displays a request being made to a Swagger/OpenAPI endpoint.\n\n**Key Elements and Details:**\n\n1. **Postman Interface:** The screenshot depicts the Postman application window with its typical sidebar (showing "My Workspace," "New Collection," etc.) and main request area.\n\n2. **Request Details:**\n * **HTTP Method:** A "GET" request is selected.\n * **URL:** The request URL is `http://localhost:8000/api/shashidproject2.centralindia.cloudapp.azure.com/docs` which likely points to a Swagger/OpenAPI documentation endpoint.\n * **Query Params:** A section for adding query parameters is visible, but is currently empty, with columns for "Key" and "Value."\n\n3. **Response Area:**\n * **Status Code:** The response displays a "200 OK" status, indicating a successful request.\n * **Response Body:** The lower section shows the HTML response body, which contains code related to Swagger UI initialization and rendering. It includes JavaScript code referencing a CDN for Swagger UI assets.\n * **HTML Tags:** Visible HTML elements include ``, ``, and `` tags.\n\n4. **Additional Elements:**\n * **Button:** A "Send" button to initiate the request is visible.\n * **Tabs:** Tabs for "Body," "Cookies," "Headers," and "Test Results" are present.\n * **Button:** There is a button for `Pretty`, `Preview`, and `HTML` for displaying the data returned.\n\n**In summary,** the image captures a successful API request made using Postman to a Swagger/OpenAPI documentation endpoint, with the response rendering the Swagger UI in the application.get1525√ó1030 38.6 KB
my server running on my friends on my friends laptop
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a web page displaying an API request/response in a developer tool or API testing environment. It details a successful request to an API endpoint, along with the request details and the server\'s response. \n\n**Key Elements:**\n\n1. **Browser Tab:** The tab reads "shashitsproject2.centralindia.azure.com/docs#/default/process_api_post", indicating the API documentation being viewed.\n2. **Request URL:** The URL being requested is "https://shashitsproject2.centralindia.azure.com/api". It appears to be a POST request with the content type being "multipart/form-data".\n3. **Server Response:**\n * **Code:** The HTTP status code is 200 (OK), signifying a successful request.\n * **Response Body:** The response is a JSON object containing a single key-value pair: `"answer": "https://shashkumarkohir.github.io/my-portfolio/"`. This likely provides a link to a portfolio website.\n4. **Response Headers:** The image shows various response headers like:\n * `access-control-allow-credentials: true`\n * `access-control-allow-origin: https://shashitsproject2.centralindia.azure.com`\n * `connection: keep-alive`\n * `content-length: 61`\n * `content-type: application/json`\n * `date: Mon, 14 Apr 2025 09:39:00 GMT`\n * `server: nginx/1.24.0 (Ubuntu)`\n * `vary: Origin`\n5. **Download Button:** There\'s a "Download" button presumably to download the API response.\n6. **Interface:** The interface resembles that of a developer tool like Postman or a similar API testing platform.\n7. **System Information:** The bottom-right corner of the screen displays the date (14-04-2025) and time (15:10).\n\n**In Summary:** The image captures the successful interaction with an API endpoint, with the server responding with a URL to a portfolio website. It‚Äôs a technical image aimed at developers or individuals involved in API testing and integration.friend laptop1600√ó999 198 KB
Thanks,
Shashi
Sir Please don‚Äôt ignore this ‚Äîthis is my last term and if I fail, I will have to restart the entire diploma. I kindly request you to reconsider my project evaluation.
@Jivraj @carlton @s.anand @Saransh_Saini
MY Project 2  status is currently marked as Absent in the course dashboard. However, I would like to clarify that I submitted the repository and API endpoints well before the deadline through the designated forum.
Additionally, my Vercel server is still active, and the API is functioning correctly, as can be verified here:
 API Form Submission
I kindly request you to review my submission
Here\'s a detailed description of the image:\n\n**Overall:**\n\n* The image shows a screenshot of a web application interface. It appears to be a form for submitting a question.\n\n**Elements within the interface:**\n\n* **Title:** The prominent heading reads "Submit Your Question" in a clear, sans-serif font.\n* **Question Field:** Below the title is a large text area labeled "Question:" for the user to input their query. \n* **File Upload:** There\'s an optional file upload section labeled "Upload ZIP File (optional):".\n * There\'s a "Choose File" button, and below it, the current status is shown as "No file chosen."\n* **Submit Button:** A large, blue button labeled "Submit" is located at the bottom of the form, indicating the action to finalize the question submission.\n* **Background:** The form is centered on a light-gray background, and the entire view is within a web browser window.\n\n**Technical Details:**\n\n* The browser\'s address bar shows "tdproject2.vercel.app/qfp/". This likely indicates the application is hosted on the Vercel platform.\n* Browser tabs and navigation controls are visible at the top of the window.\n\n**Overall Impression:** The interface is minimalistic and designed for a simple question submission process. The optional file upload suggests the ability to include supporting files along with the question.image1905√ó953 32.7 KB
Project 2 marks are showing 0 for me, when I checked logs no requests were made to my endpoint. Could you please check into this, and update as soon as possible?
Getting marks in this project would help me to pass this sub. Also, please check if evaluation has been done for my endpoint or not.
Thank you
2 to 3 days can be given to fix issues please, help us students complete this subject successfully  Please consider this sir
Sir, I too had provided render API and my logs do not show that it was accessed during the evaluation period. I had submitted the link in the form which was provided to update the link as i had not received any mail that my project had been evaluated before that.
Due to this, my score stands 0 as of now.
Sir, can you please look into this. Thank you
21f3002753@ds.study.iitm.ac.in
Anyone know this email id
i have sent request to access but he or she did not response today is deadline for GA7
Sir what if they don‚Äôt provide access i have sent manual email and through request but no response get received although i have completed  1 from 3 and 3 from 5
Bruh why are u posting ga7 in project 2 post?
is anything wrong and GA7 tagline not created and in this group people quickly response so i use this
Hi Sir, @carlton @Jivraj @Saransh_Saini Please check my project, It‚Äôs all working, why is it showing me 0 on dashboard? project2,‚Ä¶ rollnumber 23f2001390 and mail is 23f2001390@ds.study.iitm.ac.in
same for me its showing 0 for me
Same here, marked absent despite having submitted the Google form.
my score also showing zero..kindly look this  sir
MY Project 2 status is currently marked as Absent in the course dashboard. However, I would like to clarify that I submitted the repository and API endpoints well before the deadline through the designated forum.
Additionally, my Vercel server is still active, and the API is functioning correctly, as can be verified here:
https://project2-three-plum.vercel.app/api/
I kindly request you to review my submission
Request for Re-evaluation
I have completed the entire project and ensured that my model is working correctly. Despite this, I have received zero marks, which seems to be an error.
API LINK:https://project2llm-production.up.railway.app/api/
https://project2llm-production.up.railway.app/api/
I kindly request a re-evaluation of my submission. Please verify the working model and the completion of all project requirements.
Thank you.
@carlton @s.anand @Jivraj
project url: https://tdsproject2-eight.vercel.app/
Dear Sir,
In my course dashboard, Project 2 score is shown as zero. However, I had submitted the repository and API endpoints (http://35.192.157.22.80) through the Google Form. I had received a mail to make edit in API end point if changed. I had edited my api end point by adding  /api/ and it was http://35.192.157.22/api/. My server was running fine. I have worked hard to do this project and now receiving a score of zero. Kindly look into it.
Sir I have also recieved 0 marks, but I checked now also using python requests library and my server is working fine .  But I see a lot of GET requets instead of POST in my logs file which was for the past couple of days requests, which is very unlikely . Please check my link again , its still active . App link  -  http://16.16.189.187:8000/tdsp2
My test file-
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a code editor (likely VS Code) displaying a Python script and the output of running that script in a PowerShell terminal. It demonstrates a process of sending a POST request to a FastAPI server with a CSV file and a natural language query. \n\n**Code Section (Top):**\n\n* **Language:** Python\n* **Imports:** The code starts by importing the `requests` library, used for making HTTP requests.\n* **URL:** A URL is defined pointing to a FastAPI server ( `http://16.16.189.187:8000/tdsp2`).\n* **Data Definition:** A dictionary `data` is created containing a "question" key with a natural language query: "What is the total sales of all the items in the \'Gold\' ticket type? Write SQL to".\n* **File Handling:** The code specifies a CSV file (`q-fastapi.csv`) located at `C:/Users/suneh/Downloads/q-fastapi.csv` and opens it in read-binary mode (`"rb"`) with the text/plain content type.\n* **POST Request:** A POST request is sent to the FastAPI server using the `requests.post()` method, including both the `data` dictionary and the file.\n* **Response:** The code expects a response and doesn\'t show how it is handled.\n\n**Terminal Output (Bottom):**\n\n* **Command:** The terminal shows the execution of the Python script `burima.py`.\n* **Status Code:** The server responded with an HTTP status code of 200 (OK).\n* **JSON Response:** The server returned a JSON response with the following structure:\n * `{"answer": "SELECT SUM(units * price) AS total_sales FROM tickets WHERE LOWER(TRIM(type)) = \'gold\';"}`\n * The "answer" key contains a SQL query generated in response to the natural language question. The query calculates the total sales of items with the "gold" ticket type.\n\n**In Summary:**\n\nThe image depicts a program that receives a CSV file and a natural language question, and leverages a FastAPI server to generate an SQL query for answering the question. This demonstrates a workflow for converting natural language to SQL with the aid of a backend server.image1331√ó627 52.2 KB
My server log file -
Here\'s a detailed description of the image:\n\n**Overall:**\n\nThe image presents a text-based log or data stream, likely from a web server or network monitoring system. It consists of lines of text with various codes and messages.\n\n**Detailed Breakdown:**\n\n* **Log Entries:** The majority of lines begin with "INFO:" or "WARNING:", indicating the level of message severity.\n* **IP Addresses:** Each line (typically starting with "INFO:") includes an IP address (e.g., 103.158.43.17, 3.138.153.199), suggesting these are requests originating from different clients.\n* **HTTP Requests:** Following the IP address are HTTP request details including:\n * **Method:** "GET", "POST", or "PRI" \n * **Path:** The specific resource being requested (e.g., "/tdsp2", "/favicon.ico")\n * **Protocol:** "HTTP/1.1" or "HTTP/1.0"\n* **Status Codes:** Many of the requests are followed by HTTP status codes:\n * **200 OK:** Indicates a successful request.\n * **404 Not Found:** Indicates that the requested resource could not be found on the server.\n* **Warnings:** Several lines contain the message ‚ÄúInvalid HTTP request received.‚Äù, suggesting that some incoming requests were malformed or couldn‚Äôt be processed.\n\n**In summary:** The image shows a log of HTTP requests made to a server, with a mix of successful requests (200 OK), not found errors (404 Not Found), and invalid request warnings. It\'s a typical output from a web server\'s access log.Screenshot 2025-04-14 144745934√ó490 31.1 KB
My app request handeling -
Here\'s a detailed description of the image:\n\n1. **Content:** The image shows a snippet of Python code.\n2. **Code Structure:** It appears to be a definition of an asynchronous function named `tdsp2` within a web framework (likely FastAPI, based on the `@app.post` decorator).\n3. **Decorator:** `@app.post("/tdsp2")` indicates this function handles POST requests to the `/tdsp2` endpoint.\n4. **Function Definition:** `async def tdsp2(question: str = Form(...), file: Optional[UploadFile] = File(None)):` defines the function signature.\n5. **Parameters:**\n * `question`: A string parameter received from a form, marked as required (`...`).\n * `file`: An optional file upload using `UploadFile`. It defaults to `None` if no file is provided.\n6. **Framework Specifics**: `Form` and `File` indicate that this code is built on top of a web framework such as FastAPI or Starlette, which provides these classes to handle form data and file uploads respectively.\n7. **Background**: The code is displayed on a dark background, typical for code editors or terminals.\n
please  kindly look into the matter sir
@s.anand @carlton @Jivraj
I noticed that my  Project 2  status is currently marked as  ‚ÄúAbsent‚Äù in the course dashboard. However, I would like to clarify that I **submitted the GitHub repository and Vercel API link well before the deadline
via the designated forum.
Additionally, my Vercel server is still active, and the API is functioning correctly, which can be verified here:
 API Form Submission
I also have a response copy from the forum confirming my submission, including both the GitHub and Vercel links, as proof. I kindly request you to review this and take the necessary steps to update my project status.
Here is a detailed description of the image:\n\n**Overall Impression:**\n\nThe image shows a screenshot of a Google Form. The form appears to be requesting a GitHub repository link and an API endpoint URL.\n\n**Specific Elements:**\n\n1. **Form Title:** The form is requesting a GitHub repository link for "Project 27".\n2. **First Question:** Asks for "What is the link to your GitHub repository which has the code for Project 27?". It provides an example format: "https://github.com/username/repository-name". An input field is present below for the user to enter the link: "https://github.com/itskaiffazal/tdsproject2".\n3. **Second Question:** Asks for "What is the link to your API endpoint?". It states that a POST request will be sent to this URL. An input field is present below for the user to enter the link: "https://tdsproject2.vercel.app/api/".\n4. **Footer:** The bottom of the form contains text: "Create your own Google Form" and "Does this form look suspicious? Report".\n5. **Background:** The form has a light purple/lavender background.\n\n**Overall:** The form appears to be a way to collect information about a user\'s code repository and API endpoint. It could be used for a project submission, code review, or as part of an application process.image1503√ó644 37.4 KB
Here\'s a detailed description of the image:\n\n**Overall:**\n\n* The image shows a screenshot of a web application interface. It appears to be a form for submitting a question.\n\n**Elements within the interface:**\n\n* **Title:** The prominent heading reads "Submit Your Question" in a clear, sans-serif font.\n* **Question Field:** Below the title is a large text area labeled "Question:" for the user to input their query. \n* **File Upload:** There\'s an optional file upload section labeled "Upload ZIP File (optional):".\n * There\'s a "Choose File" button, and below it, the current status is shown as "No file chosen."\n* **Submit Button:** A large, blue button labeled "Submit" is located at the bottom of the form, indicating the action to finalize the question submission.\n* **Background:** The form is centered on a light-gray background, and the entire view is within a web browser window.\n\n**Technical Details:**\n\n* The browser\'s address bar shows "tdproject2.vercel.app/qfp/". This likely indicates the application is hosted on the Vercel platform.\n* Browser tabs and navigation controls are visible at the top of the window.\n\n**Overall Impression:** The interface is minimalistic and designed for a simple question submission process. The optional file upload suggests the ability to include supporting files along with the question.image1905√ó953 32.7 KB