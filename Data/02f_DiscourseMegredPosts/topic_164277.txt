# Topic: Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025]

Please post any questions related to Project 1 - LLM-based Automation Agent.
Deadline: Sunday, February 16, 2025 6:29 PM
Update on 27 Jan 2025:
A sample evaluation script for Project 1 tasks A1-A10 is available at tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip · sanand0/tools-in-data-science-public · GitHub
You can use this to validate your code for Project 1.
Please note:

This is a sample. It WILL change.
Don’t rely on the dataset being the same. It WILL change.
LLMs give different results each time they are called. Make sure:

Your code gives correct results reliably (i.e. try a few times)
Change the task in the evaluation script slightly to test variations


Your AI Proxy usage resets on 1 Feb. You have a limited budget. Utilize what you can this month.
For those who submit their code by Friday 31 Jan, I will run a sample evaluation and share the results.

sir show us all the way to do project
Hi Shouvik,
We will have live sessions to guide on how to do project.
Kind regards
Jivraj
Will those session be on youtube too?
Hi Sakthivel,
Yes all sessions are being recorded and are available on youtube within a day.
Jan 25 TDS Playlist
Kind regards
Here\'s a detailed description of the image:\n\n* **Type:** The image is a screenshot of a command-line interface (CLI) or a code editor with dark background.\n* **Content:** The image displays a text-based instruction or a command to be executed. \n* **Text:** The text reads:\n * "A1. Install uv (if required) and run"\n * "https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datacgen.py"\n * "with --{user_email} as the only argument. (NOTE: This will generate data files required for the next tasks)."\n* **Purpose:** The instruction appears to guide the user to install a package (\'uv\') and then run a Python script (\'datacgen.py\') from a GitHub repository, providing their email address as an argument. The script is intended to generate data files for subsequent tasks.\n* **Color scheme:** The text is displayed in a light color, likely white or light green, against a dark background.Screenshot 2025-01-23 1516141281×125 18.1 KB
sir @Jivraj after editing line 127 in datagen.py i got those  required data files. is it allowed ? also i had to run datagen.py MANUALLY(is this process also should be automatic)?
Hi Guddu ,
I didn’t make any changes to file and it worked for me. Can you mention what is need of making changes ?
command that I used :
uv run datagen.py 22f3002542@ds.study.iitm.ac.in --root ./data
here --root option defines the folder where you want to store generated data. by default it would try to create a folder in root directory of operating system.
Kind regards
Jivraj
getting this issue :
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_issuer'}}

Hi Aishik,
Pls add context to your query, without that we won’t be able to understand, where exactly you are facing problem.



 23f2005325:

openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_issuer'}}



Possible reasons for this issue:

Not using anand sir’s proxy url for sending requests.
Token not being correct.

yes I was not setting the base url to the proxy. I have fixed it thank you .
While implementing task A5, I am confused about what recent actually means in the phrase “recent log file”, mentioned under task A5, in the problem statement. This confusion arises because there are no dates corresponding to the log files. Should I consider log-0 as the most recent one? or the log-&lt;largest_number&gt; file? Please clarify.
I am getting the following response when I am trying to extract credit card number from the credit-card.png :
{'id': 'chatcmpl-&lt;redacted&gt;', 'object': 'chat.completion', 'created': 1737872397, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': "I'm sorry, but I can't assist with that.", 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 946, 'completion_tokens': 11, 'total_tokens': 957, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'service_tier': 'default', 'system_fingerprint': '&lt;redacted&gt;', 'monthlyCost': 0.07715699999999998, 'cost': 0.0029040000000000003, 'monthlyRequests': 31, 'costError': 'crypto.createHash is not a function'}

my code is as below :
def extract_credit_card_number():
    import requests
    import base64
    import os
    from dotenv import load_dotenv
    load_dotenv()



    BASE_URL = "http://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {os.environ["AIPROXY_TOKEN"]}"
    }

    image_path = "../data/credit_card.png"

    with open(image_path, "rb") as image_file:
        base64_image = base64.b64encode(image_file.read()).decode("utf-8")

    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {
                "role": "system",  
                "content": "You are a helpful assistant that provides detailed and accurate descriptions of images. Focus on describing the objects, colors, textures, the overall scene, and most importantly, the text and numbers in the image. Be concise but thorough."
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "You are given an image containing a credit card number. Extract the credit card number from the image"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
    }

    
    response = requests.post(BASE_URL, headers=headers, json=payload)

    
    if response.status_code == 200:
        result = response.json()
        print("RESULT:", result)
        cno = result["choices"][0]["message"]["content"]
        print("CREDIT CARD NUMBER:", cno)
    else:
        print(f"Error: {response.status_code}")
        print(response.text)

please guide @Jivraj @Saransh_Saini
do we have to do these tasks in the linux? As in some of the GA1, the linux answers only accepted. Please tell me that, do we can do it in the desktop or we have to use linux?
@Jivraj @carlton
The bash commands are usually run in a linux machine, but you can easily run those commands in VSCode without installing any virtual machines. Download the WSL extension in VSCode and you will get a WSL terminal to work with.
For more information watch this video https://youtu.be/q74CP4fB7cY?si=M_zw8WzpmMCyVQat or watch TDS Live Sessions.
Regards,
TDS TA
what frameworks can we use? hopefully anything?
or what frameworks can’t we use?
@carlton @Jivraj
Project 1 deliverables are all that matter. How you accomplish them is not very relevant. The keys to a successful Project 1 are:
Deliverables,
and an example of the Evaluation has been provided.
If your project runs in accordance with the Evaluation methodology then it is considered.
model='gemma3:27b' created_at='2025-06-13T11:27:31.467624736Z' done=True done_reason='stop' total_duration=63291114844 load_duration=18041203 prompt_eval_count=323 prompt_eval_duration=18565545886 eval_count=461 eval_duration=44706514761 message=Message(role='assistant', content="Here's a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a text-based document, likely instructions or a guide, detailing deliverables and evaluation criteria. The text is presented as a bulleted list with some code snippets and URLs.\n\n**Key Elements & Details:**\n\n* **Heading 1: Deliverables** – This section outlines tasks to be completed.\n * Create a new Github repository.\n * Add an MIT License file.\n * Write and test your code. It includes instructions to use `POST /run?task=...` and `GET /read?path=...`.\n * Commit and push the code.\n * Create a Dockerfile that builds your application.\n * Publish your Docker image publicly to Docker Hub.\n * Ensure that running your image via `podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000` serves the API at `http://localhost:8000/run?task=...` and `http://localhost:8000/read?path=...`.\n * Submit a Google Form with the Github repository URL (`https://github.com/user-name/repo-name`) and Docker image URL (`user-name/repo-name`).\n* **Note:** This section contains important reminders.\n * Use the `AIPROXY_TOKEN` environment variable for security.\n * Use your AI Proxy token, which has a $1 limit.\n * Stick to GPT-4o-Mini as the generation model.\n * Keep prompts short for the `/run` and `/read` calls to complete within 20 seconds.\n* **Heading 2: Evaluation** – This suggests there's a section below (not fully visible) detailing how the deliverables will be assessed.\n\n**Text Style & Formatting:** The text is in a clear, instructional style, with code snippets, URLs, and bullet points to enhance readability. It appears to be documentation for a development or software engineering task.", thinking=None, images=None, tool_calls=None)Screenshot 2025-01-27 at 8.35.23 am1764×1764 374 KB
Please read the documentation carefully from top to bottom.
So the main question is how do you test if the script will run according to the evaluation? The whole point is for it to run not just on your system. It should be deployable anywhere on any machine. Your solution should work anywhere we test it. Thats why you package it in a docker container. How you achieve that is up to you. But if we cannot run your docker container according to the specification we have provided then it has failed this crucial test.
Kind regards
@23f1002382
You can use any library as long as your Project 1 meets the deliverable requirements and does all the (20+) API tasks.
Kind regards
A sample evaluation script for Project 1 tasks A1-A10 is available at tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip · sanand0/tools-in-data-science-public · GitHub
You can use this to validate your code for Project 1.
Please note:

This is a sample. It WILL change.
Don’t rely on the dataset being the same. It WILL change.
LLMs give different results each time they are called. Make sure:

Your code gives correct results reliably (i.e. try a few times)
Change the task in the evaluation script slightly to test variations


Your AI Proxy usage resets on 1 Feb. You have a limited budget. Utilize what you can this month.
For those who submit their code by Friday, I will run a sample evaluation and share the results.

@carlton @Jivraj @Saransh_Saini - please socialize this during the live sessions.
By clicking the project link ,I am getting the notes…but no project is available in my project 1
by clicking the link
Here is a point-by-point description of the image:\n\n* **Content:** The image displays a screen capture of a survey or questionnaire item.\n* **Question:** The question asks if the user has seen "Project 1" available at a provided link and attempted it.\n* **Response Options:** The response options are a radio button labeled "Yes".\n* **Visual Elements:** There are two sections titled "Project 1" with an arrow and an orange dot.\n* **Background:** The background of the screen is light yellow/beige.image1198×136 9.49 KB
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a webpage detailing a data science project, specifically concerning the development of an LLM-based Automation Agent.\n\n**Key Elements:**\n\n1. **Sidebar Navigation:** On the left side, a sidebar menu is visible with the heading “Tools in Data Science.” It includes categories like:\n * Development Tools\n * Deployment Tools\n * Large Language Models\n * Project 1 (expanded, showing subcategories)\n * Background\n * Create an API\n * Phase A: Handle Operatio...\n * Phase B: Handle Business...\n * Deliverables\n\n2. **Main Content Area:** The primary area of the screen contains text detailing the project.\n * **Title:** "Project 1 - LLM-based Automation Agent"\n * **Timeline:** The project is due on February 15, 2025, and results will be announced on February 25, 2025. A link to a Discourse thread is provided for questions.\n * **Background Information:** The text describes the project\'s context: the user has joined the operations team at DataWorks Solutions. The company aims to automate routine tasks in its Continuous Integration (CI) pipeline to improve efficiency and consistency. The project will utilize a Large Language Model (LLM) to achieve this.\n\n3. **Visual Style:** The webpage has a clean, minimalist design with a light background. It appears to be documentation or a project brief within a data science learning platform.image1750×581 70.9 KB
I am getting this opened.
Hi @Divya1 ,
There won’t be any project1 page such as GA1s, there is a google form(which can be found in same page) which needs to be filled after you do project1.
Hi @23f2005325 ,
Extracting details from credit cards is sensitive, try using strong prompts or take code from LLM and execute it in script.
kind regards
Regarding Wednenday 9-10 pm live session, maybe the instructors could also discuss how to use docker as a virtual environment using maybe ollama(local llm as now there is deepseek opensource, i doubt we would need to use openai for testing, just for production(test submission)  would be enough) and also some agent(langchain, autogen, crewai) just a quick how-to on setting up and problems while setting up if possible
More resources on docker. Using docker as a virtual environment. Editing and executing code in Dockerfiles (like when you change code in src a web framework automatically reloads page(hot reload)), something along the lines of this .
@carlton @Jivraj



 23f1002382:

Regarding Wednenday 9-10 pm live session, maybe the instructors could also discuss how to use docker as a virtual environmen


In Tuesday’s(21 January) session we had discussed docker towards ending of session.
What was discussed in that live session regarding docker:

Search for existing containers on repositories such as dockerhub.
Pull an existing docker image.
Run that image inside a container.
Enter to that container and modify something(such as installing python inside a ubuntu container, for customization or create some file)
Once done you can commit it.
And push customized container’s image to docker hub.

Regarding local models running for project1, it’s a good idea, we will see if it’s possible to discuss in session.
In the google forms , I have 2 questions in one form now to submit should it is compulsory that to answer the both the questions?
Hi @Divya1
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a list of deliverables or tasks, likely for a software development or coding project. It appears to be instructions for a student or developer to complete.\n\n**Key Elements & Details:**\n\n* **Title:** The text at the top reads "Deliverables" with a star icon.\n* **List of Instructions:** The main content is a bulleted list of tasks to complete:\n * Create a new public GitHub repository.\n * Add an MIT LICENSE file.\n * Write and test code using POST /run?task=... and GET /read?path=...\n * Commit and push code to the repository.\n * Create a Dockerfile.\n * Publish Docker image publicly to Docker Hub.\n * Ensure `podman run` command serves the API at `http://localhost:8000/run?task=...` and `http://localhost:8000/read?path=...`.\n * Submit the URL of the GitHub repository and the Docker image name in a Google Form.\n* **Highlighted Text:** A red box highlights the required submission details: the GitHub repository URL (format: `https://github.com/user-name/repo-name`) and the Docker image name (format: `user-name/repo-name`).\n* **Technical terms:** The list includes terms like "MIT LICENSE", "Dockerfile", "Docker Hub", "podman run" which indicates this is for an experienced or intermediate developer.\n* **Command Line Syntax:** Includes an example command line utilizing "podman run" to execute the docker image and map port 8000.\n\n**In essence:** The image provides a clear checklist of requirements for a coding project, culminating in the submission of the project\'s source code and containerized application.Screenshot 2025-01-29 at 8.19.05 am1738×982 122 KB
Please do very carefully all things mentioned in the Deliverables as well as look at the Evaluation Section.
Here\'s a detailed description of the image:\n\n* **Content Type:** The image displays a list of prerequisites for evaluation, likely related to a software project or code submission.\n* **Heading:** The main heading states "Pre-requisites: Your repository **MUST** meet the following criteria to be eligible for evaluation." The word "MUST" is emphasized in bold.\n* **List of Criteria:** Below the heading is a bulleted list outlining the required conditions:\n * A publicly accessible GitHub repository.\n * The presence of a `LICENSE` file with the MIT license.\n * A valid `Dockerfile` within the repository.\n * A publicly accessible Docker image that can be run using the command: `podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000`\n * The Docker image should use the same Dockerfile as the GitHub repository.\n* **Formatting:** The criteria are presented as a hierarchical list with bullets and indented sub-points.\n* **Emphasis:** Key terms like "LICENSE" and "Dockerfile" are highlighted, likely indicating their importance.\n\n\n\nIn essence, the image presents the requirements for a software project to be evaluated, emphasizing the need for a public GitHub repository, a Dockerfile, and a runnable Docker image.Screenshot 2025-01-29 at 8.26.08 am1460×496 45.5 KB
We had a session on 28th Jan introducing all the important aspects of Project.
If you do not do everything exactly as mentioned especially the pre - requisites mentioned in the Evaluation section you will get 0 in the project and there will be no appeal for failing to meet the pre - requisites of the evaluation criteria.
In order for us to evaluate the project you have to provide the deliverables mentioned above.
Kind regards

Subject: Request to Add Instructors to Private GitHub Repo
Message:
"Dear [Instructors’ Names],
I’ve set up the environment and dependencies for the project and was wondering if it would be appropriate to add you to my private GitHub repository. I’d appreciate any guidance on improving performance, scalability, and design principles. Please let me know if this is feasible or if there’s a more suitable way to seek feedback. Apologies if this request is out of scope.
Thank you for your time!
Best,
[Your Name]"*
ChatGPT can make mistakes. Check important info.
@23f1002382 - You’re welcome to use the evaluation script in this post for private repos.




Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025] Tools in Data Science


    A sample evaluation script for Project 1 tasks A1-A10 is available at tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip · sanand0/tools-in-data-science-public · GitHub 
You can use this to validate your code for Project 1. 
Please note: 

This is a sample. It WILL change.
Don’t rely on the dataset being the same. It WILL change.
LLMs give different results each time they are called. Make sure:

Your code gives correct results reliably (i.e. try a few times)
Change the task in t…
  

For public repos submitted in the form, I’ll run this script over the weekend and share preliminary results.
T  h  a  n  k      y  o  u         sir.
For A6, /data/docs/ has subfolders with .md files from which we have to extract the heading level 1’s (#) right? Apparently there are few files with different content but the same name. Can someone confirm the same? If yes how to address these files @Jivraj @carlton
I had set up the environment and dependencies and everything was working fine. When i tried to recreate it from scratch in a new codespace it broke. I fixed almost everything except this error
@ANdIeCOOl ➜ /workspaces/TDS-Project-1 (main) $ crewai create crew b2b
Traceback (most recent call last):
  File "/home/codespace/.python/current/bin/crewai", line 5, in &lt;module&gt;
    from crewai.cli.cli import crewai
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/__init__.py", line 3, in &lt;module&gt;
    from crewai.agent import Agent
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agent.py", line 7, in &lt;module&gt;
    from crewai.agents import CacheHandler
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agents/__init__.py", line 2, in &lt;module&gt;
    from .parser import CrewAgentParser
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agents/parser.py", line 6, in &lt;module&gt;
    from crewai.utilities import I18N
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/utilities/__init__.py", line 13, in &lt;module&gt;
    from .embedding_configurator import EmbeddingConfigurator
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/utilities/embedding_configurator.py", line 4, in &lt;module&gt;
    from chromadb import Documents, EmbeddingFunction, Embeddings
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/__init__.py", line 6, in &lt;module&gt;
    from chromadb.auth.token_authn import TokenTransportHeader
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/auth/token_authn/__init__.py", line 24, in &lt;module&gt;
    from chromadb.telemetry.opentelemetry import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py", line 13, in &lt;module&gt;
    from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/trace_exporter/__init__.py", line 25, in &lt;module&gt;
    from opentelemetry.exporter.otlp.proto.grpc.exporter import (  # noqa: F401
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py", line 72, in &lt;module&gt;
    from opentelemetry.sdk.metrics.export import MetricsData
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/__init__.py", line 16, in &lt;module&gt;
    from opentelemetry.sdk.metrics._internal import Meter, MeterProvider
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/__init__.py", line 56, in &lt;module&gt;
    from opentelemetry.sdk.metrics._internal.measurement_consumer import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/measurement_consumer.py", line 29, in &lt;module&gt;
    from opentelemetry.sdk.metrics._internal.metric_reader_storage import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/metric_reader_storage.py", line 26, in &lt;module&gt;
    from opentelemetry.sdk.metrics._internal._view_instrument_match import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/_view_instrument_match.py", line 22, in &lt;module&gt;
    from opentelemetry.sdk.metrics._internal.aggregation import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/aggregation.py", line 48, in &lt;module&gt;
    from opentelemetry.sdk.metrics._internal.exponential_histogram.mapping.exponent_mapping import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/exponent_mapping.py", line 25, in &lt;module&gt;
    from opentelemetry.sdk.metrics._internal.exponential_histogram.mapping.ieee_754 import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/ieee_754.py", line 15, in &lt;module&gt;
    from ctypes import c_double, c_uint64
  File "/usr/local/python/3.12.1/lib/python3.12/ctypes/__init__.py", line 8, in &lt;module&gt;
    from _ctypes import Union, Structure, Array
ImportError: /usr/local/python/3.12.1/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so: undefined symbol: ffi_type_uint32, version LIBFFI_BASE_7.0

i updated the libffi package using sudo but while breaking something else can someone pls help me? @carlton @Jivraj @s.anand



history of commands in new codespace
    1  crewai --version
    2  pip install crewai crewai-tools
    3  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    4  export PATH=/opt/conda/bin:$PATH
    5  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    6  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    7  crewai create crew &lt;project_name&gt;
    8  crewai create crew b2b
    9  history



UPDATE: IT’s WORKING if you do this in order
    1  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    2  export PATH=/opt/conda/bin:$PATH
    3  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    4  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    5  pip install --no-cache-dir --force-reinstall typing_extensions pydantic crewai crewai-tools
    6  conda install -c conda-forge typing_extensions
    7  exec bash
    8  crewai create crew "Project 1 - LLM-based Automation Agent"

Something about different environment conda and python can the instructors please help me understand it(resources ), so i can trouble shoot this later with better accuracy come precision
evaluate.py
TDS course repo


github.com


tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip ·...
Contribute to sanand0/tools-in-data-science-public development by creating an account on GitHub.





line 20
from datagen import (
    get_markdown,
    get_dates,
    get_contacts,
    get_logs,
    get_docs,
    get_email,
    get_credit_card,
    get_comments,
    get_tickets,
)

but we get datagen.py only in a1 task
line 69
async def a1(email: str, **kwargs):
    await run(
        f"""
Install `uv` (if required) and run the script `https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py`
with `{email}` as the only argument
"""
    )
    return email in await read("/data/format.md")

The issue is importing datagen before ensuring it exists
just checking
@carlton @Jivraj
Hi @23f1002382,
Yes datagen.py must be present in same directory from where you  are executing evaluate.py.
Oh, You trying to use crewai locally for Project1
kind regards
Hi @JoelJeffrey ,
Filepath is unique for every file, which needs to be inserted to json file.
Ok. So just to confirm, since there are files with the same name, the json file should map the filepath and not the filename to the title right?
Here\'s a point-by-point description of the image:\n\n* **Content:** The image displays text instructions likely pertaining to a data processing or software development task.\n* **Task Description:** The instructions detail how to find Markdown (`.md`) files within the `/data/docs/` directory.\n* **Extraction:** The task involves extracting the first header line (lines beginning with `#`) from each file.\n* **Index File:** The extracted data is to be used to create an index file named `/data/docs/index.json`.\n* **Data Mapping:** This JSON file should map each filename (without the path) to its corresponding title (the extracted header line).\n* **Example Output:** A JSON structure example is provided demonstrating the expected mapping: `{"README.md": "Home", "large-language-models.md": "Large Language Models", ...}`.Screenshot from 2025-01-31 12-25-29790×117 19.9 KB
no crewai, it takes really long i put time out for 300 secs(in run(task:str) in evaluate.py) still sometimes its not enough. I’ll try with autogen next and then langchain
INFO:     127.0.0.1:65085 - "GET /read?path=/data/format.md HTTP/1.1" 200 OK
data/format.md 81ms
INFO:     127.0.0.1:65149 - "POST /run?task=%0AFormat+the+contents+of+%60%2Fdata%2Fformat.md%60+using+%60prettier%403.4.2%60%2C+updating+the+file+in-place%0A HTTP/1.1" 200 OK
INFO:     127.0.0.1:65251 - "GET /read?path=/data/format.md HTTP/1.1" 200 OK
INFO:     127.0.0.1:65263 - "POST /run?task=The+file+%60%2Fdata%2Fdates.txt%60+contains+a+list+of+dates%2C+one+per+line.+Count+the+number+of+Wednesdays+in+the+list%2C+and+write+just+the+number+to+%60%2Fdata%2Fdates-wednesdays.txt%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65298 - "GET /read?path=/data/dates-wednesdays.txt HTTP/1.1" 200 OK
INFO:     127.0.0.1:65312 - "POST /run?task=Sort+the+array+of+contacts+in+%60%2Fdata%2Fcontacts.json%60+by+%60last_name%60%2C+then+%60first_name%60%2C+and+write+the+result+to+%60%2Fdata%2Fcontacts-sorted.json%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65350 - "GET /read?path=/data/contacts-sorted.json HTTP/1.1" 200 OK
INFO:     127.0.0.1:65361 - "POST /run?task=Write+the+first+line+of+the+10+most+recent+%60.log%60+file+in+%60%2Fdata%2Flogs%2F%60+to+%60%2Fdata%2Flogs-recent.txt%60%2C+most+recent+first HTTP/1.1" 200 OK
INFO:     127.0.0.1:65390 - "GET /read?path=/data/logs-recent.txt HTTP/1.1" 200 OK
INFO:     127.0.0.1:65402 - "POST /run?task=Find+all+Markdown+%28%60.md%60%29+files+in+%60%2Fdata%2Fdocs%2F%60.%0AFor+each+file%2C+extract+the+first+occurrance+of+each+H1+%28i.e.+a+line+starting+with+%60%23+%60%29.%0ACreate+an+index+file+%60%2Fdata%2Fdocs%2Findex.json%60+that+maps+each+filename+%28without+the+%60%2Fdata%2Fdocs%2F%60+prefix%29+to+its+title%0A%28e.g.+%60%7B%22README.md%22%3A+%22Home%22%2C+%22path%2Fto%2Flarge-language-models.md%22%3A+%22Large+Language+Models%22%2C+...%7D%60%29 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65436 - "GET /read?path=/data/docs/index.json HTTP/1.1" 200 OK
INFO:     127.0.0.1:65452 - "POST /run?task=%60%2Fdata%2Fcredit_card.png%60+contains+a+credit+card+number.+Pass+the+image+to+an+LLM%2C+have+it+extract+the+card+number%2C+and+write+it+without+spaces+to+%60%2Fdata%2Fcredit-card.txt%60 HTTP/1.1" 500 Internal Server Error
INFO:     127.0.0.1:65482 - "GET /read?path=/data/credit-card.txt HTTP/1.1" 500 Internal Server Error
INFO:     127.0.0.1:65503 - "POST /run?task=The+SQLite+database+file+%60%2Fdata%2Fticket-sales.db%60+has+a+%60tickets%60+with+columns+%60type%60%2C+%60units%60%2C+and+%60price%60.+Each+row+is+a+customer+bid+for+a+concert+ticket.+What+is+the+total+sales+of+all+the+items+in+the+%22Gold%22+ticket+type%3F+Write+the+number+in+%60%2Fdata%2Fticket-sales-gold.txt%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:49154 - "GET /read?path=/data/ticket-sales-gold.txt HTTP/1.1" 200 OK

result after running evaluate.py:
 Score: 0 / 10
why sir @Jivraj @Saransh_Saini  what is the problem here??
please do a live session of complete project process with one or two tasks if possible
Hi Guddu,
We are planning several project sessions in order to show the workflow of creating a successful project.
Although you are returning a 200 ok, the get request file must match the expectation. In other words after running the first task for example, has the new format.md been formatted correctly and matches the expected output.
In this case you would write out the the expected variable in the evaluate.py and see if result variable matches the expected. Then you can figure out what went wrong.
Kind regards
Ok sir
But please try to take those sessions sooner
Because it’s taking too much time for me to do any problem(plus two more courses and one oppe you know) .so I just want to build the project before deadline.
Please give the date, time and agenda also please.
Yes sir ,
As soon as we know we will send an announcement.
Kind regards.
the model keeps wrong answer, it says uvicorn for uv and has no info on how to run uv even after explicitly giving instructions(basically an older model) , basic “ls” command is also wrong, among other things. You can check your logs with respect to my api key.
Do you think we could access a better model?
Maybe Download Deepseek 70b or even 671b and create an api while y’all run the model locally, in the long it would be cheaper for the course?
because the model doesn’t know basic commands after telling how to do it.
So if the model gives us wrong commands 2/3 times then how would we even solve the question.
I spent a week on this just saying
@s.anand @carlton @Jivraj
sent pull request maybe accept it then please 


Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a colorful, flat-design illustration representing "Tools in Data Science." It\'s a collage of icons and graphic elements associated with data analysis, machine learning, and technology.\n\n**Key Elements & Details:**\n\n* **Text:** Bold, white text reads "TOOLS IN DATA SCIENCE" centered within the composition.\n* **Icons/Graphics:** The image is packed with various icons, including:\n * **Charts & Graphs:** Bar charts, line graphs, pie charts and scatter plots.\n * **Data Representation:** Hexagonal grids, globe with network connections, and various blocks representing datasets.\n * **Technology & Programming:** Icons resembling circuit boards, coding symbols, and a camera with an overlay.\n * **Tools & Instruments:** A pen, a pair of pliers, and a level.\n * **Network & Connections:** Interconnected lines forming networks and a connection symbol\n* **Color Palette:** A vibrant palette featuring blues, reds, oranges, and teals dominates, suggesting energy and innovation.\n* **Style:** Flat design with simple shapes and minimal gradients. This style is common for modern tech illustrations.\n* **Layout:** A dense, almost mosaic-like arrangement of icons, creating a visually engaging and informative image.\n\n**Overall Message:** The image visually communicates the diverse range of tools and concepts used in the field of data science. It is likely intended for use in marketing materials, educational content, or blog posts related to data science.


can we have the code for this session please?
@Jivraj @carlton
i need some help can you send me your repo?
Hello, I recently started working on the project. I understood how to do all the phase A tasks on a high level but I’m struggling to start the implementation of the first task in phase A. I’m confused mainly about how the /data directory is supposed to be created, I don’t know how to generate the data and a little confused about the output formats. I would appreciate if I could get in contact with anyone who could guide me in the right direction.
Hello everyone, @s.anand @carlton
I had a few queries regarding the project;

I am preloading my docker image with uv and generating the /data files when the container is ran. For task A1, I am automating my server to remove the /data directory that’s already present and run datagen.py again. Is this fine?
For /read endpoint, is there a standard for parameters like “path=/data/format.md” or the parameter could be a plain english sentence like “path=show the data in format.md”?
Are we concerned about what’s shown on the console if I run a /run command as long as it gets the job done?
For tasks A1-10, are the file paths provided in the project doc standard or even they’re flexible? Ex. “Count the number of Wednesdays in file /data/format.md, and write just the number to /data/out.txt”

+1




Dear Sir,
Can we have a mentorship program for TDS for those who have no experience in programming like me ?
thanks &amp; regards.
ULAGAOOZHIAN
For Project-1 to complete, it requires:
"You MUST complete ALL these 3 steps to get a score. Failure to do so will result in getting 0 in the project. If you do not do ALL these 3 steps before the deadline, there will be no appeal available.
• Fill the form that is on the Project Page
But I did not get the form; where is it? While I checked inside the project pages also.
Hi Dewang,
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a webpage outlining deliverables and evaluation criteria for a "Tools in Data Science" project, specifically focusing on creating an API. It appears to be from an online learning platform. \n\n**Key Elements & Details:**\n\n* **Sidebar Navigation:** A left-side menu provides navigation options, including "Tools in Data Science," "Development Tools," "Deployment Tools," "Large Language Models," "Project 1" with sub-sections like "Background" and "Create an API," "Phase A: Handle Operation…," "Phase B: Handle Business…," "Deliverables," "Evaluation," "Data Sourcing," "Data Preparation," "Data Analysis," "Data Visualization," and "Live Sessions."\n* **Deliverables Section:**\n * A list of tasks is outlined, including creating a GitHub repository, adding a LICENSE file, writing and testing code (using `POST /run?task=…` and `GET /read?path=…`), committing and pushing code, creating a Dockerfile, publishing to Docker Hub, and ensuring the image is running.\n * A command-line instruction is displayed: `podman run --env Aiproxytoken=$AIPROXY_TOKEN -p 8000:8000 automatically serves the API at http://localhost:8000/run?task=… and http://localhost:8000/read?path=…`.\n * A request to submit a GitHub repository link and Docker image name is highlighted.\n* **Note Section:** \n * Instructions regarding the `AIPROXY_TOKEN` environment variable and avoiding committing the token to the repository are included.\n * Guidance on using the AI proxy token and its limitations is given.\n * A prompt to keep requests concise and short is present.\n* **Evaluation Section:** A header labeled “Evaluation” is visible below the deliverables.\n\n**Overall, the image details a set of tasks for a data science project, focusing on API creation, deployment using Docker, and the use of an AI proxy token. It also includes important notes regarding security and efficient prompting.**Screenshot 2025-02-03 at 6.27.39 pm 12268×1766 491 KB
Please read the Project page Deliverables carefully as well as the Evaluation Pre - Requisites.
Kind regards


github.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-


README.md

main

# TDS-Project1-Ollama_FastAPI-
## Info
- Create codespaces on main or evalution script branch
Use history.txt to get sqlite to version 3.45.3 into bash session 
   - 64  export PATH=/opt/conda/bin:$PATH
   - 65  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
   - 66  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"

- cd to latest_ai_development and run cmd [ crewai run] which set up server 
- Then in a separate bash terminal run "python evaluate.py" 
- also make sure to enter openai or sanand api key in crew.py

# Simple history of commands
1. Terminal 1 
    - 1  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    - 2  export PATH=/opt/conda/bin:$PATH
    - 3  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    - 4  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    - 5  cd latest_ai_development/
    - 7  pip install crewai crewai-tools




  This file has been truncated. show original





My take on autonomous agents. Limited by model capabilities to some extent. Will use function calling hence forth but here is a quick look at using crewai for agent tasks.
Sir   @carlton @Jivraj just saying,
If possible Please do 40-50% of project in upcoming live sessions so that we all have atleast something to submit.
I am using ubuntu. How do I use python 3.13. It says my python version is 3.12 even after installing python 3.13
Someone please help
@s.anand sir, I see that the project 1 timeline was changed from February 7 - 17, 2025 to January 17 - February 15 which undoubtedly is a good increase in duration. However, I have my GATE DA exam on Feb 15 and the exam center is unexpectedly far. So, I request you to consider pushing the deadline to at least Feb 16. If not, I’ll still do my best.
Hello! @carlton @s.anand
Is the proxy server down right now?
I am getting this error when I am accessing the endpoint:
{‘id’: ‘chatcmpl-Axq55TzulOVjHYuXYIhkRQzCC3PNl’, ‘object’: ‘chat.completion’, ‘created’: 1738824915, ‘model’: ‘gpt-4o-mini-2024-07-18’, ‘choices’: [{‘index’: 0, ‘message’: {‘role’: ‘assistant’, ‘content’: …, ‘costError’: ‘crypto.createHash is not a function’}
Or, do I have to install crypto module?
@21f3002390 - AI Proxy is working and you did get the result. You can ignore any costError. It won’t happen in the future anyway.
What’s happening? I was trying to generate a unique hash for each request, as a precursor to caching requests. But I made a mistake in the code. Specifically, crypto.createHash is not supported in CloudFlare. I fixed that by removing this. I’ll introduce caching later if required.
For the question #A8 on recognizing the credit card number in the image, Open AI doesn’t seem to be recognizing the number correctly and as a result the evaluation is failing. What should be the solution?
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a console or terminal output, likely from a program or script executing a task involving image processing and text extraction. It displays a series of HTTP requests and responses, indicating a workflow where an image is processed by a Large Language Model (LLM) to extract a credit card number and save it to a text file. \n\n**Key Elements & Details:**\n\n1. **Running Task:** The initial line indicates the task being executed: processing the image `/data/credit_card.png` to extract a credit card number and writing it to `/data/credit-card.txt` without spaces.\n2. **HTTP POST Request:** The image shows an HTTP POST request sent to `http://localhost:8000/run/task`, which includes the task definition and file paths.\n3. **HTTP 200 Response (POST):** Following the POST request, there\'s an HTTP 200 OK response, confirming the successful reception of the task by the server. The response body is a JSON object that defines the function being called (`"extract_numbers_from_image"`) and the input/output file paths.\n4. **HTTP GET Request:** Another HTTP request is displayed, this time a GET request to `http://localhost:8000/read/path`, likely to retrieve the content of the `/data/credit-card.txt` file.\n5. **File Content:** The core of the screenshot is the content of the `/data/credit-card.txt` file. It displays the following:\n * **EXPECTED:** 402639933653956\n * **RESULT:** 402639933653956\n\nThe `EXPECTED` and `RESULT` lines confirm that the number extracted from the image matches the expected value, signifying successful OCR and data extraction. The image suggests an automated process of extracting a credit card number from an image and verifying its correctness.image913×498 13.6 KB
When will live sessions for demo project start? If started please provide link for that as I am unable to get what the project is about and what are the initial steps to start project.
Getting the following error :
127.0.0.1 - - [07/Feb/2025 01:44:54] "GET /run?task=generate%20data%20for%20ujanaishik109@gmail.com HTTP/1.1" 200 -
  File "/tmp/datagenyhqKlO.py", line 1
    404: Not Found
    ^^^
SyntaxError: illegal target for annotation


when executing the following code :
Main.py
@routes.route("/run", methods=["GET", "POST"])
def run():
    task = request.args.get("task")
    try:
        res = get_func_name(task)
        func_name = res["func_name"]
        args = res.get("arguments", [])
        print("ARGUMENTS : ", args)
        if args:
            generated_func = globals()[func_name](*args)
            print("GENERATED FUNC :",generated_func)
            res = f"{func_name} executed successfully"
        else:
            generated_func = globals()[func_name]()
            print(generated_func)
            res = f"{func_name} executed successfully"
    except Exception as e:
        res = None
        print("error : ", e)
    return jsonify(res)


Tasks.py
def generate_data_files(user_email: str):
    subprocess.Popen(
        [
            "uv",
            "run",
            "https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py",
            f"{user_email}",
            "--root",
            "../data",
        ]
    )
    print("data generated successfully")

Please Guide @s.anand @carlton @Jivraj
A query regarding the task description in the query given to LLM for phase A.
For task A3, we have been asked to count wednesdays and the python file corresponding to A3 does count for wednesday alone. However the example says the LLM might be asked to count Sundays or other days. Should we be modifying task A3 code? Or was that just an example and only Wednesdays would need to be counted?
@carlton @Jivraj  Please respond .
When will the project session be held? If I have missed it, can I get the recording?
@carlton
Tuesday is when we are currently planning a project session.
Kind regards
Tasks in Phase A are defined but that does not mean it has to do one precise thing. If that was the case then there is no use for an LLM.
Your application should be able to take parse the input and be able to run commands that do similar things in parameterised fashion. It could be Wednesdays or Sundays or it might be in Arabic days or anything. So coding to precisely do something very specific is not the goal.
The program has to be intelligent to do a certain type or class of tasks.
We had a session introducing project. Week 3 session 1. But we will have a more hands on session on Tuesday.
Kind regards
the last date of project submission is gonne get extended?
Project 1 was released over a month ago. So there will be no extension for Project 1
how to handle this error
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a terminal or command-line interface output.\n* **Error Message:** The prominent part of the output is a "ModuleNotFoundError". This indicates a Python script is trying to import a module named \'datagen\', but the module cannot be found.\n* **Traceback:** A traceback is visible, detailing the path and line number where the error occurred in a file named "evaluateEp39.py".\n* **File Path:** The file path mentioned in the error is `/tmp/evaluateEp39.py`.\n* **Prompt:** The terminal prompt reads `root@vikash:/mnt/e/IITN/New/TDS/LLM Project#`. This indicates the user \'root\' is operating on a system with a mount point at `/mnt/e/IITN/New/TDS/LLM Project`.\n* **Environment Variables:** It appears `OPENAI_API_KEY=$AIProxy` has been set and used during the run, and the initial command used was `run https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2023-01/project-1/evaluate.py`.\n* **Color Scheme:** The terminal is using a dark color scheme with white or light-colored text.\n* **Cursor:** The cursor is at the end of the terminal prompt, indicating the user can type another command.\n\nIn essence, the image captures a Python script execution that failed due to a missing module, \'datagen\'.image1425×490 11.1 KB
@carlton @s.anand
    expected = sum(1 for date in dates if parse(date).weekday() == 2)
    if result.strip() != str(expected):
        return mismatch("/data/dates-wednesdays.txt", expected, result)
    return True```



 /data/dates-wednesdays.txt
 EXPECTED:
129
 RESULT:
“129”
If it is expecting str then why throw error sir  ? @carlton @Jivraj
or just tell me how to pass count as an int here
with open(output_file, "w") as f:
        f.write(str(count)) 

@s.anand @carlton @Jivraj
I am getting below error message from LLM end points https://api.openai.com/v1/chat/completions or https://aiproxy.sanand.workers.dev/openai/v1/embeddings , while running my project .
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a line of text with various data points and parameters in a computer code-like format.\n* **Parameters:** It includes parameters such as "frm", "lt", "Image", "Q", "used", and "rendering". \n* **Values:** Associated with these parameters are values including "24.0", "17", "205.0", "10", "0.0025628000000000003", and "2.176".\n* **Formatting:** The data points and parameters are displayed using a specific format, likely representing data from a software or analysis process.\n* **Background:** The background is black, ensuring the white text is clearly visible. \n\nIn summary, the image shows a snippet of data in a formatted, computer-readable style, likely representing parameters and values from a computational process.
Kindly help me to resolve this issue. 
@carlton Will there be evaluation script for tasks in group B also?
Some questions about ‘B’ group tasks:
Q1: For the following tasks (B5, B7, B9, and B10) tasks, how will input files be provided? Will it be URL or will datagen.py also generate files for these?
Q2: For the above tasks as well as for B6 ( Extract data from (i.e. scrape) a website), how should output be returned?
Q3: In task B8, for transcribing audio file, which Python package is recommended or do we need to use OpenAI API?
B5. Run a SQL query on a SQLite or DuckDB database
B7. Compress or resize an image
B8. Transcribe audio from an MP3 file
B9. Convert Markdown to HTML
B10. Write an API endpoint that filters a CSV file and returns JSON data
its expecting to  match every single detail in that even " and ’ .
in that case changing evaluate.py will result in zero or less marks.
llm will only handle  -calling function based on query and parameter   . What is it going to do about the logic of functions.
If i still focus on passing evaluate.py will it be any good sir @carlton @s.anand
🔴 /data/contacts-sorted.json
⚠️ EXPECTED:
[{'first_name': 'Kevin', 'last_name': 'Aguirre', 'email': 'ricardocarlson@example.net'}, {'first_name': 'Andrew', 'last_name': 'Anderson', 'email': 'kimberly08@example.com'}, {'first_name': 'Robert', 'last_name': 'Arnold', 'email': 'hunterpamela@example.com'}, {'first_name': 'Isaac', 'last_name': 'Barker', 'email': 'jessicabriggs@example.net'}, {'first_name': 

My output was in good looking structured form but I had to make it look like this just to pass the evaluation.
⚠️ RESULT:
[{"first_name": "Kevin", "last_name": "Aguirre", "email": "ricardocarlson@example.net"}, {"first_name": "Andrew", "last_name": "Anderson", "email": "kimberly08@example.com"}, {"first_name": "Robert", "last_name": "Arnold", "email": "hunterpamela@example.com"}, {"first_name": "Isaac", "last_name": "Barker", "email": "jessicabriggs@example.net"}, {"first_name": "Anthony", "last_name": "Barrett", "email": "kevinknox@example.org"}, {"first_name": "Monique", "last_name": "Bass", "email": "lindsaymcgrath@example.net"}, {"first_name": "Michael", "last_name": "Berry", "email": "an

Sorry, sir, not trying to be rude, but there isn’t a single full-fledged project session. It’s a bit difficult to dive into the project without guidance on how to do it. It would be nice to have a full project session where we can start a project from the beginning and follow it to completion.
@carlton @Jivraj @s.anand
Yes. I am very worried about this project. I have been trying to do this. But have gotten nowhere until now.
@carlton sir I request you demonstrate atleast few tasks, I spent last 2 days trying to implement but din’t reach anywhere, its really demotivating sir.
Can you please demonstrate it by just doing One task or provide sample example code of 1 similar task in the way you explained here. It will be very helpful right now it is very confusing.
We will be doing project session on Tuesday 9 Feb [correction] Tuesday 11th of Feb (thanks @23f1002382 @23f2000237) . Project 1 uses the things you learnt in week 1-3. But mostly week 2 &amp; 3.
We dont do it in the beginning, (but introduced it 2 weeks ago in a live session), to give students chance to practise the new learnings from week 2 &amp; 3.
The plan has always been to demonstrate a few tasks and have you try doing the rest.
Kind regards
@s.anand @carlton @Jivraj
I am getting below error message from LLM end points https://api.openai.com/v1/chat/completions or https://aiproxy.sanand.workers.dev/openai/v1/embeddings , while running my project .
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a line of text with various data points and parameters in a computer code-like format.\n* **Parameters:** It includes parameters such as "frm", "lt", "Image", "Q", "used", and "rendering". \n* **Values:** Associated with these parameters are values including "24.0", "17", "205.0", "10", "0.0025628000000000003", and "2.176".\n* **Formatting:** The data points and parameters are displayed using a specific format, likely representing data from a software or analysis process.\n* **Background:** The background is black, ensuring the white text is clearly visible. \n\nIn summary, the image shows a snippet of data in a formatted, computer-readable style, likely representing parameters and values from a computational process.
Kindly help me to resolve this issue. I am unable to proceed with my project.
Today’s 9th Feb and it’s a Sunday.



 s.anand:

Update: 27 Feb 2025:


Sir, does this mean 27th is submission deadline?
Hi Aindree,
No its a typo (and will be corrected soon). In the context of what was written it clearly means it was updated on 27th January. The update being that the evaluation.py file was provided so that you could test your code against it.
Thanks for bringing it to our attention.
Kind regards
Hi
This would be only for a selected few questions right because say for the credit card question, where the LLM is involved, to get the card number itself, we have to give a fine-tuned and strong query.
Try using the eval() function, that seemed to work for me
@carlton @s.anand @Jivraj  Sir, could you please share some guidance on the above?
@jivraj,@carlton
I have done the a1 to a10 task and tried querying through localhost and its working fine basically all these ten steps but dont know whether its enough or not. also steps in phase B i am confused that should we create separate endpoints for these tasks or should it be with same /run endpoint and query. then will the input be random by any user. what about the output . where should it be given. phase b needs more explanation.
At what time will the session be happening tomorrow sir can you please give the details?
Hi @carlton @Jivraj
Facing some issues in running my project. Taking an example of the Phase A - A3 task.
I am able to read my files through the GET/read/data/dates.txt query.
I am also able to use the count_wednesdays function through the POST/run task/count_wednesdays.
But when I am entering a query such as “count_wednesdays in data/dates.txt” I am unable to get a response.
Here\'s a detailed description of the image:\n\n* **Layout:** The image presents a two-column table-like structure with "Code" and "Details" as headers.\n* **Code Column:** Displays the HTTP status code "200".\n* **Details Column:** Displays the text "Response body" followed by a JSON object.\n* **JSON Object:** The JSON object contains a single key-value pair:\n * **Key:** `"error"`\n * **Value:** `"Could not understand the task"`\n* **Color Scheme:** The background is a pale green, and the text is black. The JSON object is highlighted with a dark green background. \n\nIn summary, the image shows a response indicating a successful HTTP request (status code 200), but the server reported an error in understanding the given task.image618×246 6.28 KB
Please advice. Thank you.
Here\'s a detailed description of the image:\n\n* **Content:** The image displays two lines of text, resembling instructions or commands.\n* **First Line:** "the sender\'s email address, and write just the email address to /data/email-sender.txt". This line instructs to extract an email address and save it to a specified file path.\n* **Second Line:** "/data/credit-card.png contains a credit card number. Pass the image to an LLM, have it extract the card number, and write it without spaces to /data/credit-card.txt". This line indicates an image file contains a credit card number and directs to use a Large Language Model (LLM) to extract it and save it to another file path without spaces.\n* **Formatting:** The lines are in a bulleted list format.\n* **Context:** The image likely originates from a document outlining a data processing or information extraction task.\n\n\n\nimage1215×112 19 KB
On task A8, credit-card.png is given, but it is in credit_card.
it makes the errors. I checked that 2 to 3 tasks depend on these, and we create the ouput file with ‘-’ this only. please clarify that output and input files name ‘-’ or ‘_’   @carlton @Jivraj
On tomorrow live sessions, kindly explain how to use docker, evaluations, github, what generally we have to do submit, please get some tuturials for us to submit those answers. Thankyou Sir  @Jivraj @carlton
(post deleted by author)
(post deleted by author)
(post deleted by author)
 Score: 9 / 10
Almost done with A tasks. Please use this for local llm to verify output
Also Ollama doesn’t require Schemas
CHECK OUT THE REPO AND ANY INPUTS ARE WELCOME
Link to ReadMe and also repo
Hi Andrew,
You have done a great job with the Phase A tasks. Very methodical, well structured, logical and even incorporates (unnecessarily) two different ways of evaluating its performance via local llm or the project proxy.
I just want to forewarn you (and others who are tempted to just blindly copy and paste) that evaluate.py is not meant to give you an exact expectation of what prompts will be sent to your application.
In other words getting 10/10 in evaluate.py does NOT guarantee 10/10 or even 5/10  or 1/10 in the real evaluation.
So do not write your code so rigidly that it will only work in the very strict interpretation of evaluate.py. It has always been meant to give you a feel for what to aim for. Your code should be flexible enough to deal with the general idea of the task.
That said, evaluate.py is a good way to know what to expect. Some of Phase A tasks although given a detailed specification in the project description, will still be given challenging prompts (i.e. hard difficulty, and requires some clever self correcting mechanism). Some of the tasks will be given straight forward prompt (i.e. easy for your application).  Some of the tasks will be given with some level of parameterisation that deviates from the strict interpretation (i.e. medium difficulty).
Hope that helps with how you deal with Phase B tasks (and making your Phase A more robust to a stronger evaluation.)
A word of caution: (i.e. this is just some advice, not a set in stone recommendation) Your requirements.txt is massive. If your code does not execute a task (possibly your first task) within 20 seconds (on our server) then it will fail that task. You might want to consider a dynamic, flexible way of installing only required libraries when necessary and keeping the image footprint small and efficient, as we will necessarily have limits on how big we allow images to grow since we have to run and evaluate hundreds of images automatically.
Kind regards
Respected @s.anand @carlton and @Jivraj ,
Is anyone actively monitoring the Discourse page? I have been raising this issue for the past few days, but there has been no response. Does this mean the TAs are not addressing students’ concerns?
I am encountering the following error while running my project with these LLM endpoints:

https://api.openai.com/v1/chat/completions
https://aiproxy.sanand.workers.dev/openai/v1/embeddings
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a line of text with various data points and parameters in a computer code-like format.\n* **Parameters:** It includes parameters such as "frm", "lt", "Image", "Q", "used", and "rendering". \n* **Values:** Associated with these parameters are values including "24.0", "17", "205.0", "10", "0.0025628000000000003", and "2.176".\n* **Formatting:** The data points and parameters are displayed using a specific format, likely representing data from a software or analysis process.\n* **Background:** The background is black, ensuring the white text is clearly visible. \n\nIn summary, the image shows a snippet of data in a formatted, computer-readable style, likely representing parameters and values from a computational process.
This issue is blocking my progress, and I urgently need assistance to resolve it. Kindly provide guidance or suggest a solution at the earliest.

Looking forward to your response.
Thanks,
Telvin Varghese
Hi,
I am not able to understand how to do the Project 1. The date is also very near.
The problem I am facing is, When I did the Modules the page was different, but now in the Project 1 I am not getting any section to submit the project.
Please let me know where are the questions and how tot submit that.
The deadline is near.



 carlton:

o do not write your code so rigidly that it will only work in the very strict interpretation of evaluate.py. It has always been meant to give you a feel for what to aim for. Your code should be flexible enough to deal with the general idea of the task.


This where I need help, i tried doing with agentic framework but i failed with the model in llm proxy, which was highly suspect because, that model should have known what the uv framework but it seemed to me to be outdated. Hence executing code Interpreter tools failed as the model gave outdated code. I have raised this issue before
Hence i moved to function calling, using local llms as cost-effective solution and it was quite robust.
I just need to understand how the function should be general, maybe 2-3 tasks you could provide the general description along with all the ways one would query the agent llm(ie our project). This general function is what i need help with. Please kindly do the needful.



 carlton:

keeping the image footprint small and efficient, as we will necessarily have limits on how big we allow images to grow since we have to run and evaluate hundreds of images automatically.


Any tentative size cutoff for the docker image?
Hi Telvin
You have run out of tokens. Thats what the message is saying. You ran out 3 days ago. It was clearly mentioned that the limit is $1. You have exceeded $2.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image shows a screenshot of a webpage titled "Large Language Models" within a learning platform (likely a course or tutorial). It appears to be instructions on how to use LLMs for a specific course.\n\n**Key Elements:**\n\n1. **Page Title:** The main heading clearly states "Large Language Models".\n2. **Navigation Menu:** On the left side, there\'s a navigation menu with categories such as "Tools in Data Science," "Development Tools," "Deployment Tools," and an expanded section "Large Language Models" displaying sub-topics like "Prompt engineering," "TDS TA Instructions," and others.\n3. **Content Area:** The main content area contains text detailing the practical usage of LLMs, mentioning associated costs, and providing instructions on how to configure API access.\n4. **Cost Information:** There\'s highlighted text indicating that LLM usage is limited to $1 per calendar month for the course.\n5. **API Instructions:** The text instructs users to replace specific API URLs (from openai.com) with those from a proxy server (aiproxy.sanand.workers.dev/openai/). It also requires replacing the OpenAI API key with the AIPROXY\\_TOKEN.\n6. **Navigation Buttons**: At the bottom of the page are buttons for navigation to the previous and next pages. The current page is \'Prompt engineering\'.\n\n**In summary:** The image displays course material relating to Large Language Models, providing practical guidance on using them within the course’s infrastructure and cost limitations.Screenshot 2025-02-11 at 3.36.50 pm2078×1276 305 KB
In our current internal build of project 1, we have yet to exceed $0.50
As to whether it can be renewed is something we have still not yet decided, because the question you have raised equally would apply to everyone. Raising it for you means raising it for everyone. $1 for everyone equals raising it by $1600+ (i.e Rs 1.39 Lakhs) for us!
The budget question then involves more than one person. It also involves the BS Team Operations and not just the TDS team and therefore instead of responding with a response that is not useful, we typically try to solve the problem first and then respond.
In short we are working on it. But as we have mentioned repeatedly in our sessions, use APIs efficiently, thats part of the skill. As soon as we have a resolution we will inform everyone via an announcement and an email.
Kind regards
Thanks for your response, @Carlton. It seems I won’t be able to proceed with the project until this issue is resolved. Also, I haven’t used LLM so much until February 7th to cost $2.
Every request you send, gives you a response back with exactly how much that request cost. So you can track your usage.
I’m aware of that. I’ve mostly noticed a cost of $0.0003 per request, so I haven’t been tracking my total monthly expenses. Moving forward, I’ll keep a record of the cost for each request. Also, do strong prompts impact the overall cost?
@carlton Is the project session happening today? I don’t have the link. Can you please send it if it’s happening?
Hi, where is the link for todays Project 1 demo session? @carlton @Jivraj
https://meet.google.com/odh-ycbm-ahj?authuser=0
request
http://localhost:8000/run?task=Extract the sender's email from /data/email.txt and write to /data/email-sender.txt](http://localhost:8000/run?task=Extract the sender's email from /data/email.txt and write to /data/email-sender.txt)

output
{    "detail": "Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid\_request\_error', 'param': None, 'code': 'invalid\_issuer'}}"}

@carlton sir I am getting this issue while running my script. Please help!
I’m getting an error in task a2, def do_a2():
“”“Format markdown using prettier”“”
format_md_path = DATA_ROOT / “format.md”
subprocess.Popen([“prettier”, str(format_md_path), “–write”, “–parser”, “markdown”])
print(“data formatted successfully”)
any idea how to fix this? Also in A8, a 5 and a 3 is getting interchanged. Can someone help why that is hapening, I changed the prompt to include caution about not switching 3 and 5 as well, that didn’t help either
what is  the session time?
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a command-line interface (CLI), likely a terminal or console window. It displays the output of a script execution that resulted in an error.\n\n**Key Elements & Details:**\n\n* **Command Prompt:** The prompt indicates the user is in a directory structure related to an "IITM online degree/Diploma" project within a mounted drive. The path is `/mnt/d/My_Folder/IITM_online_degree/Diploma/TDS/Project`.\n* **Executed Command:** The command being executed is `uv run https://raw.githubusercontent.com/sanand/tools-in-data-science-public/tds-2025-01/project-1/datagen.py 2310021040@ds.study.iitm.ac.in`. This appears to run a Python script named `datagen.py` from a GitHub repository.\n* **Error Message:** The core of the image is a traceback showing a `PermissionError: [Errno 13] Permission denied: \'/data!\'`. This means the script attempted to create a directory or file at `/data!` but lacked the necessary permissions to do so.\n* **Traceback Details:** The traceback points to:\n * The script `/tmp/datagen2e008.py`, line 284, where the `os.makedirs` function was called.\n * The `os.makedirs` function itself, within the system\'s "frozen os" module.\n* **Text Formatting:** Error messages and file paths are highlighted in red, likely to draw the user\'s attention to the issue.\n\n**In summary:** The image shows an error occurring during the execution of a Python script, specifically a `PermissionError` preventing the script from creating a directory or file at a specified path.Screenshot 2025-02-11 1814531459×207 15.3 KB
Could you kindly help me with this
in checking for the task of json my code is outputting json with double quotes (valid json) and evaluate.py has exact same json but with single quotes , what should I do?
check out my repo and download the datagen and evaluate file for testing
it should work, use fastapi text response when /read api
Has anyone used a local LLM for testing? If so, could you please share the request URL and the request body format? I attempted to use a local LLM, but I was unable to succeed
use ollama it is openai api compatible, supports function calling without json schema for tool usage. Check it out
NEED HELP. CAN SOMEONE CONTACT OLLAMA AND ASK THEM TO CHECK THEIR CODE ITS HAS SOME SILLY MISTAKES IN CODE EXAMPLES. I DONT KNOW HOW TO DO IT.
LINK TO PAGE WITH CODE EXAMPLE
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a snippet of code, likely Python, related to data analysis and specifically to storing and retrieving data using vector embeddings. It is presented as a text-based screenshot of code.\n\n**Key Elements and Details:**\n\n* **Code Snippet 1: Storing Documents:**\n * The code iterates through a list named `documents`.\n * Inside the loop, it uses a function called `ollama.embed` with the model `mxbai-embed-large` to generate embeddings for each document.\n * The generated embeddings and the original document are then added to a collection using the `collection.add` function.\n * `ids` are assigned based on the index `i`.\n\n* **Text "Step 2: Retrieve"**: Indicates a step in a larger process dealing with information retrieval.\n\n* **Code Snippet 2: Retrieving Documents:**\n * Defines an example input query: "What animals are llamas related to?".\n * It generates an embedding for this input query, also using the `ollama.embed` function with the same model.\n * It then performs a query on the collection using `collection.query` to find documents similar to the input query, requesting only 1 result (`n_results=1`).\n * Finally, it assigns the most relevant document to the variable `data`.\n\n**Overall Context**: The image presents code demonstrating a basic implementation of a vector database for semantic search. It showcases how to store documents as embeddings and then retrieve the document most relevant to a given query.Screenshot 2025-02-11 232608919×714 22.4 KB

correct code in step 2 collection query step
response = ollama.embed(
  model="nomic-embed-text:latest",
  input=task
)
results = collection.query(
  query_embeddings=response["embeddings"], #here embeddings and also not list of list as response embeddings already gives correct format
  n_results=1
)
data = results['documents'][0][0]

@s.anand @Jivraj @carlton
@s.anand @carlton @Jivraj
While implementing the Phase B tasks, can I take the data (csv file, git repo, audio, sqlite/duckdb database, website, image and markdown file) of my choice and perform any operation on them as long as they meet the critetia mentioned in the Phase B task list? Please guide.
@s.anand @carlton @Jivraj
In the Task B5, where we have to run an SQL query on a sqlite or duckdb database, should I create a database on my own and then take the query to be ran on it as an argument? Or should I take the query as an argument and run it on the ticker_sales.db in ./data folder? Please guide
same issue on my side as well
on using the AIPROXY_TOKEN from here https://aiproxy.sanand.workers.dev/
getting this error :
Error: Your authentication token is not from a valid issuer.
@carlton @Jivraj  please help!
@carlton @Jivraj Can the link to the live session (for project) be provided?
As in the previous session for task a1 we use llm just to get the url and email , so after retriving the both arguments can i use them in a function and got the work given in work done in function.
Also, am i correct that we use llm only to retrive url or location ??
@carlton @Jivraj
Anyone whom have done have done any one task of phase a and one task of phase b, please help…
Can you do one task from each phase in today’s session. Please @carlton @Jivraj
thanks for the reply I will check
TDS project  Tedious project 
can anyone share the link of yesterdays live session if there in youtube
Its updated in the TDS live sessions playlist


Here\'s a detailed description of the image:\n\n* **Overall Composition:** The image is a graphic featuring text overlaid on a colorful, geometric patterned background. It appears to be a title card or a slide header.\n* **Text:** The text "WEEK 5" is displayed in large, bold, white letters. Below it, "SESSION 1" is written in a similar style. \n* **Background Pattern:** The background is divided into three horizontal bands, each with a unique geometric pattern consisting of colorful shapes (triangles, squares, circles) and various icons like globes, scissors, and abstract designs.\n* **Color Palette:** The color scheme is vibrant and diverse, including shades of blue, orange, red, green, and white.\n* **Style:** The design has a flat, modern, and somewhat playful aesthetic, likely intended for a digital presentation or infographic.\n* **Format:** The image has a widescreen aspect ratio with dark bands on the left and right sides.\n\n\n\n


For task A2:

A2. Format the contents of /data/format.md using prettier@3.4.2, updating the file in-place

I am getting the following error:
🔴 A2 failed: Command '['npx', 'prettier@3.4.2', '--stdin-filepath', '/data/format.md']' returned non-zero exit status 1.
However, running a POST request to https://localhost:8000/run?task=Format+/data/format.md+with+prettier+3.4.2 gives successful output.
{"success":true,"message":"Formatted and verified successfully!"}% 
Here is my code snippet:
def format_file(filepath):
    while True:  # Loop until formatting and verification pass
        try:
            result = subprocess.run(
                ["npx", "prettier@3.4.2", "--write", filepath],
                check=False,  # Don't raise exception automatically
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                return {"success": False, "message": f"Prettier write failed: {result.stderr}"}

            if verify_prettier_formatting(filepath):
                return {"success": True, "message": "Formatted and verified successfully!"}
            else:
                logging.info("Verification failed. Retrying formatting...") #Log the retry
                # If verification fails, the loop continues and prettier --write is executed again.

        except Exception as e:
            return {"success": False, "message": str(e)}

def verify_prettier_formatting(filepath):
    try:
        subprocess.run(["npx", "prettier@3.4.2", "--check", filepath], check=True, capture_output=True, text=True) #Capture output
        return True  # File is formatted correctly
    except subprocess.CalledProcessError as e:
        logging.error(f"Prettier check failed: {e.stderr}") # Log the error from prettier check
        return False  # File is not formatted correctly

What am I missing here?
I am getting the same error. Did you find any solution?
Has anyone succeeded in the extraction of credit cards details task? The LLM seems to consider it as illegal task and if I use pytessaract the docker image size will become really large. What to do in this case?
@carlton @Jivraj
Hi @carlton @Jivraj,
I followed what you taught in Feb 11 session and tried implementing task A1. My understanding is once i run the subprocess, datagen.py file should be run and /data folder should be created in the project folder. But it is not happening to me. I am getting the following error
Traceback (most recent call last):
  File "/var/folders/rj/z_3b8hl51558519w90k5hp600000gn/T/datagen4COEF3.py", line 284, in &lt;module&gt;
    os.makedirs(config["root"], exist_ok=True)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "&lt;frozen os&gt;", line 227, in makedirs
OSError: [Errno 30] Read-only file system: '/data'

If i can’t automate this process, i don’t see the point writing code for other tasks. Can anyone help me solving this error?
shell = true in evaluate.py, remove it meaning comment it out, task a2 thats causing the error
the admin banned me from using laughing emoji  @jkmadathil
For task A6,

HTTP Request: GET http://localhost:8000/read?path=/data/docs/index.json “HTTP/1.1 200 OK”

⚠️ EXPECTED:
{'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/culture.md': 'Prevent north only miss cold.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/family.md': 'Debate at office traditional stop great.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/bar.md': 'Among ago cover good.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/story.md': 'Anything song key first.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'drop/former.md': 'Brother college detail.', 'drop/add.md': 'Fish work to individual.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/else.md': 'Fly candidate may so college.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/ready.md': 'Central about ready information.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/question.md': 'Family evening its degree.', 'civil/argue.md': 'Line culture seven six.', 'civil/gas.md': 'Talk why around necessary.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/central.md': 'Believe region their our whatever.', 'standard/easy.md': 'Myself must detail win.', 'standard/sound.md': 'Night national film next.', 'standard/five.md': 'Lay would green generation season.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/late.md': 'Scientist people may story.', 'standard/level.md': 'Work around ask to.', 'standard/analysis.md': 'While natural from staff option artist can.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/sometimes.md': 'Big order defense field represent.', 'few/weight.md': 'Man mission American.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/my.md': 'Open line address contain whole impact into front.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/southern.md': 'Meet prove admit.', 'few/theory.md': 'Security effort protect future task long close.', 'few/information.md': 'Really morning yeah.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/save.md': 'Thought hear home set employee early purpose.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/book.md': 'Mr oil difficult dog.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/cold.md': 'Election buy member alone school audience.', 'community/else.md': 'Actually service thank state.', 'community/left.md': 'Picture let tell never.', 'community/soldier.md': 'It lawyer cover job.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'Congress/remember.md': 'Purpose good policy line trade.', 'ten/rock.md': 'Method wall when book agency.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/nature.md': 'Eight own hot first success.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/serve.md': 'Want exist bank book.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/white.md': 'Whatever significant capital air about.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/own.md': 'Say small finish sing raise.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/discuss.md': 'Hit result find miss culture heart clear task.'}

⚠️ RESULT:
{'suddenly/mouth.md': 'Outside food subject positive human.', 'suddenly/add.md': 'Window word during born do finally.', 'suddenly/free.md': 'Them ball significant different which traditional.', 'suddenly/management.md': 'Man fire long hour modern.', 'suddenly/leave.md': 'Season people Democrat hand among too.', 'suddenly/low.md': 'Front actually decision security fast song believe leg.', 'suddenly/why.md': 'Account listen such day method sing.', 'suddenly/miss.md': 'Rather although team thank.', 'suddenly/base.md': 'Total low room structure staff.', 'suddenly/strategy.md': 'Never understand less operation onto still trade environment.', 'ground/girl.md': 'Civil speech back sell.', 'ground/game.md': 'Fill whose card or daughter old meet.', 'ground/term.md': 'Pick return put set.', 'ground/every.md': 'Free service trouble effort somebody blood modern.', 'ground/along.md': 'Important plant increase door much.', 'ground/call.md': 'Article agent three scientist.', 'ground/do.md': 'Memory food strategy meeting.', 'ground/end.md': 'Large player discussion similar prove part.', 'ground/full.md': 'Actually start commercial.', 'ground/ever.md': 'Human example gun now my just Republican.', 'way/not.md': 'Decision together land chair.', 'way/morning.md': 'Information later service raise after trial base.', 'way/responsibility.md': 'Our child why environment care goal.', 'way/increase.md': 'Return say response political.', 'way/relationship.md': 'General view thing poor machine market peace.', 'way/soldier.md': 'Produce table should will school produce player wall.', 'way/act.md': 'Smile guess simple read style its international.', 'way/sound.md': 'Conference first finally recognize as.', 'way/reach.md': 'Exactly size discuss management miss article.', 'way/hotel.md': 'From become actually.', 'hit/run.md': 'Stock several region put thought decade evening.', 'hit/free.md': 'Crime usually produce.', 'hit/foot.md': 'Ball specific trip state.', 'hit/ball.md': 'Condition color focus traditional.', 'hit/song.md': 'Section environmental final light word in yes operation.', 'hit/since.md': 'Shoulder wrong matter seek cultural vote themselves.', 'hit/safe.md': 'Hear try spend item can along light.', 'hit/much.md': 'Guess great dream through concern feel.', 'hit/prove.md': 'Her base cup forward.', 'hit/stop.md': 'Nation this avoid herself deal place memory.', 'few/sometimes.md': 'Big order defense field represent.', 'few/southern.md': 'Meet prove admit.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/weight.md': 'Man mission American.', 'few/information.md': 'Really morning yeah.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/theory.md': 'Security effort protect future task long close.', 'few/my.md': 'Open line address contain whole impact into front.', 'resource/rest.md': 'Ok tough talk.', 'resource/move.md': 'Law write democratic drug itself house accept through.', 'resource/particularly.md': 'Affect woman nice.', 'resource/entire.md': 'Focus to once sea friend group.', 'resource/painting.md': 'Customer environment none trade.', 'resource/structure.md': 'Stuff return protect our bit reality.', 'resource/until.md': 'Growth industry region receive.', 'resource/significant.md': 'Long million fall throughout government tend.', 'resource/hospital.md': 'Quality certain fight want much body between.', 'resource/marriage.md': 'Foot specific mission.', 'for/hope.md': 'Whatever report wife fly close lot student.', 'for/poor.md': 'Explain claim police eye paper much when.', 'for/assume.md': 'Control yeah effect local economy worry.', 'for/couple.md': 'Floor both take indeed audience.', 'for/money.md': 'Join live next care material.', 'for/never.md': 'Me natural full.', 'for/situation.md': 'Show book instead hope lawyer.', 'for/north.md': 'Card level kind send loss growth.', 'for/hit.md': 'Minute wish above pass just later watch.', 'for/perhaps.md': 'Every professor sport unit rock bed.', 'project/individual.md': 'Tough safe machine small outside mention could must.', 'project/change.md': 'Century drug value.', 'project/home.md': 'Big decade edge feeling surface matter force student.', 'project/want.md': 'Region catch nation civil one Mr specific.', 'project/something.md': 'Major control three.', 'project/reality.md': 'Mouth including fine.', 'project/my.md': 'Fire point or success marriage write example.', 'project/issue.md': 'Former true career similar use visit machine.', 'project/surface.md': 'Cold reduce task life American act stage.', 'project/drug.md': 'Reason still field animal.', 'effort/morning.md': 'Policy quickly get capital smile.', 'effort/he.md': 'Thought view product interview explain.', 'effort/house.md': 'High hear thought according.', 'effort/church.md': 'Culture ask change focus.', 'effort/effect.md': 'Before suddenly who student could boy serve.', 'effort/price.md': 'Shoulder financial public reason home explain safe.', 'effort/company.md': 'Exactly treatment concern fly factor care drive.', 'effort/international.md': 'Rich take hear open.', 'effort/federal.md': 'Difference rate character by his blood this.', 'effort/computer.md': 'Lay financial article exactly.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/culture.md': 'Prevent north only miss cold.', 'by/family.md': 'Debate at office traditional stop great.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'bill/appear.md': 'Whole senior next stop yard national section.', 'bill/room.md': 'Able improve anything teacher media writer employee.', 'bill/citizen.md': 'Safe anyone major reach mother ground over leave.', 'bill/for.md': 'A several low detail.', 'bill/role.md': 'More light anything study hand power.', 'bill/set.md': 'Necessary century drive attack capital.', 'bill/generation.md': 'Stay could quality shake.', 'bill/drive.md': 'Situation we his.', 'bill/computer.md': 'Culture ahead change perhaps however audience.', 'bill/gas.md': 'Reveal attack and church.', 'color/sell.md': 'Mention although while boy turn.', 'color/throughout.md': 'She actually gun start.', 'color/management.md': 'Short serve beat increase than visit.', 'color/smile.md': 'His season employee husband.', 'color/wear.md': 'Share green measure sometimes.', 'color/official.md': 'Suddenly seat tend thus office action move.', 'color/admit.md': 'Each important clear.', 'color/treat.md': 'Tv outside attorney rich say same environment.', 'color/turn.md': 'Try drop old along.', 'color/sit.md': 'Including turn seem none computer.', 'build/together.md': 'Finally point only police artist.', 'build/rest.md': 'Author run let.', 'build/wall.md': 'Administration a week form side feeling.', 'build/none.md': 'Commercial stop page else.', 'build/explain.md': 'Join tend idea stand not option woman.', 'build/decision.md': 'Poor fund interesting bring.', 'build/beyond.md': 'Artist billion begin record anything none management practice.', 'build/dream.md': 'Decision suddenly prevent speak old power herself.', 'build/each.md': 'Able out key.', 'build/street.md': 'Knowledge specific technology before leave.', 'wrong/market.md': 'Realize key point whatever Democrat or say.', 'wrong/free.md': 'Deal even from mouth source.', 'wrong/sure.md': 'Similar him believe actually.', 'wrong/apply.md': 'Everybody office list service stock significant.', 'wrong/share.md': 'Painting every apply.', 'wrong/standard.md': 'Already place fund really.', 'wrong/might.md': 'Possible during claim view.', 'wrong/nation.md': 'About prove cold question race.', 'wrong/be.md': 'Land debate natural American.', 'wrong/suggest.md': 'Could environmental rather can us night.', 'Congress/remember.md': 'Purpose good policy line trade.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'industry/wrong.md': 'Floor race land those hard actually avoid property.', 'industry/book.md': 'Together state billion race beautiful how.', 'industry/car.md': 'Heart central eye thought painting government appear.', 'industry/cause.md': 'Time religious describe oil heart.', 'industry/feeling.md': 'Include memory strategy other statement imagine teach.', 'industry/small.md': 'Little third your season kind.', 'industry/heavy.md': 'Quality international window probably adult attention.', 'industry/election.md': 'Democrat often turn.', 'industry/possible.md': 'Structure high discover half dog half forward.', 'industry/fish.md': 'Much without in fight miss.', 'live/white.md': 'Whatever significant capital air about.', 'live/discuss.md': 'Hit result find miss culture heart clear task.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/own.md': 'Say small finish sing raise.', 'lot/seat.md': 'Method institution third political.', 'lot/wall.md': 'Each feel program size different kid.', 'lot/worry.md': 'Support moment maintain majority American rule rock.', 'lot/improve.md': 'Reason better difficult take.', 'lot/heart.md': 'Make let way.', 'lot/modern.md': 'Example first recently let.', 'lot/make.md': 'First eat data executive.', 'lot/check.md': 'Wall artist recent side approach.', 'lot/hotel.md': 'Technology town film nothing writer head from.', 'lot/perhaps.md': 'Main manage authority serious short.', 'drop/add.md': 'Fish work to individual.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/else.md': 'Fly candidate may so college.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/former.md': 'Brother college detail.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'central/several.md': 'Appear talk administration sort.', 'central/them.md': 'Unit huge call.', 'central/often.md': 'For nice after analysis series.', 'central/before.md': 'Account vote off police since.', 'central/commercial.md': 'Address country last teacher game compare.', 'central/these.md': 'Feeling rate first national.', 'central/tough.md': 'Party single media process statement forget.', 'central/crime.md': 'Hotel we five blue lawyer argue.', 'central/less.md': 'Guess environmental cover three late.', 'central/nice.md': 'Those religious audience case those.', 'civil/argue.md': 'Line culture seven six.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/ready.md': 'Central about ready information.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/question.md': 'Family evening its degree.', 'civil/gas.md': 'Talk why around necessary.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/central.md': 'Believe region their our whatever.', 'friend/oil.md': 'Little someone story put hundred able.', 'friend/discover.md': 'Someone city idea.', 'friend/month.md': 'Race walk people its Democrat sound.', 'friend/alone.md': 'Suffer concern choose participant work.', 'friend/myself.md': 'Truth simply memory alone plant large.', 'friend/note.md': 'Word end size enough.', 'friend/large.md': 'Tough glass per.', 'friend/wife.md': 'Sea investment many difference keep like improve.', 'friend/allow.md': 'Become personal own behavior sport.', 'friend/hand.md': 'Nation yourself final ground thus follow.', 'standard/late.md': 'Scientist people may story.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/level.md': 'Work around ask to.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/sound.md': 'Night national film next.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/easy.md': 'Myself must detail win.', 'standard/five.md': 'Lay would green generation season.', 'standard/analysis.md': 'While natural from staff option artist can.', 'community/book.md': 'Mr oil difficult dog.', 'community/else.md': 'Actually service thank state.', 'community/soldier.md': 'It lawyer cover job.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/cold.md': 'Election buy member alone school audience.', 'community/left.md': 'Picture let tell never.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/save.md': 'Thought hear home set employee early purpose.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/story.md': 'Anything song key first.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/bar.md': 'Among ago cover good.', 'education/evening.md': 'Give tonight sell over whole word care.', 'education/body.md': 'Note start bad part positive during.', 'education/total.md': 'Contain hit individual college month.', 'education/nature.md': 'Skin look fine policy special part.', 'education/really.md': 'Difference beyond cost but.', 'education/reason.md': 'Wrong increase investment deep near simply spring.', 'education/blood.md': 'North smile know.', 'education/imagine.md': 'Summer keep conference.', 'education/fish.md': 'Answer impact sense professor gun fast me.', 'education/article.md': 'Usually could bad attack customer couple represent.', 'lead/rest.md': 'Address half hit.', 'lead/speech.md': 'Maintain prepare indicate production surface.', 'lead/become.md': 'Building plant air something direction fall provide.', 'lead/stage.md': 'View main when Republican father plant.', 'lead/under.md': 'Test next education series.', 'lead/adult.md': 'Rule others especially institution total what law.', 'lead/which.md': 'Far task service radio reach morning accept.', 'lead/phone.md': 'Unit good including show stand.', 'lead/would.md': 'President still follow race analysis opportunity.', 'lead/trade.md': 'Success whatever environmental avoid father how although may.', 'why/show.md': 'Decade station development character movement.', 'why/data.md': 'Itself feeling fund mean.', 'why/more.md': 'Address music fish team national tough.', 'why/debate.md': 'Meeting wind medical can city face cost.', 'why/something.md': 'Everybody bed economic own least peace executive.', 'why/most.md': 'Agreement station room name.', 'why/spring.md': 'Fine according mission against.', 'why/phone.md': 'By near next teacher be degree although.', 'why/full.md': 'Yard like phone catch on attention your.', 'why/stuff.md': 'Cup everybody open book he decade.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/serve.md': 'Want exist bank book.', 'ten/nature.md': 'Eight own hot first success.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/rock.md': 'Method wall when book agency.', 'rule/hear.md': 'History event character everybody paper machine little billion.', 'rule/thing.md': 'Trial produce despite water range television.', 'rule/feel.md': 'Soon give never future difference.', 'rule/system.md': 'Bill article station despite.', 'rule/produce.md': 'Yes method sense.', 'rule/eye.md': 'Finally this team yet throughout.', 'rule/nation.md': 'Radio entire ago behavior prevent response ten according.', 'rule/thousand.md': 'Anything help military with run.', 'rule/goal.md': 'Inside firm without.', 'rule/perhaps.md': 'Back election leave.'}

If I am not wrong, both the expected and actual result contain the same entries. It is just that the ordering is different. The expected result also doesnt follow any particular format (so does the actual result).
Kindly advise on this @carlton
EDIT : Resolved on a later evaluation
For the task - * B10. Write an API endpoint that filters a CSV file and returns JSON data
Do we have to handle prompts for converting CSV to JSON or for writing an endpoint for doing so?
@carlton @Jivraj
yeah i am also facing the same doubt
+1…
@Jivraj @s.anand
could someone please share their repo for reference. it would be very much helpful
Dear Instructors (@carlton, @iamprasna):
Confirming, just to be needfully pedantic:
It will solely be the responsibility of the Project Evaluator (human or machine) to parse the correct AIPROXY_TOKEN generated against my IITM email ID (presumably, per some database which holds all such generated AIPROXY_TOKENs of the students who have generated one); and the correct $IMAGE_NAME (to-be-submitted by myself in the Project Submission Google Form) in podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000, correct?
Asking this seemingly obvious question, as (apparently) the actual AIPROXY_TOKEN is not to be included anywhere in the code, or the repository, or the dockerfile.
I am also facing the same issue, just that the ordering is different.
Sorting by keys also didn’t help.
Please help on this @carlton @Jivraj
sir will the tasks of Phase A and Phase B change? like currently do we need to make llm write the code for all tasks dynamically or can we write a pre defined python code to execute tasks after the llm parses the task and runs python code
Check length of result and length of expected, one is 98 and other is 298
expected = {'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/culture.md': 'Prevent north only miss cold.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/family.md': 'Debate at office traditional stop great.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/bar.md': 'Among ago cover good.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/story.md': 'Anything song key first.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'drop/former.md': 'Brother college detail.', 'drop/add.md': 'Fish work to individual.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/else.md': 'Fly candidate may so college.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/ready.md': 'Central about ready information.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/question.md': 'Family evening its degree.', 'civil/argue.md': 'Line culture seven six.', 'civil/gas.md': 'Talk why around necessary.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/central.md': 'Believe region their our whatever.', 'standard/easy.md': 'Myself must detail win.', 'standard/sound.md': 'Night national film next.', 'standard/five.md': 'Lay would green generation season.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/late.md': 'Scientist people may story.', 'standard/level.md': 'Work around ask to.', 'standard/analysis.md': 'While natural from staff option artist can.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/sometimes.md': 'Big order defense field represent.', 'few/weight.md': 'Man mission American.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/my.md': 'Open line address contain whole impact into front.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/southern.md': 'Meet prove admit.', 'few/theory.md': 'Security effort protect future task long close.', 'few/information.md': 'Really morning yeah.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/save.md': 'Thought hear home set employee early purpose.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/book.md': 'Mr oil difficult dog.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/cold.md': 'Election buy member alone school audience.', 'community/else.md': 'Actually service thank state.', 'community/left.md': 'Picture let tell never.', 'community/soldier.md': 'It lawyer cover job.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'Congress/remember.md': 'Purpose good policy line trade.', 'ten/rock.md': 'Method wall when book agency.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/nature.md': 'Eight own hot first success.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/serve.md': 'Want exist bank book.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/white.md': 'Whatever significant capital air about.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/own.md': 'Say small finish sing raise.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/discuss.md': 'Hit result find miss culture heart clear task.'}
result  = {'suddenly/mouth.md': 'Outside food subject positive human.', 'suddenly/add.md': 'Window word during born do finally.', 'suddenly/free.md': 'Them ball significant different which traditional.', 'suddenly/management.md': 'Man fire long hour modern.', 'suddenly/leave.md': 'Season people Democrat hand among too.', 'suddenly/low.md': 'Front actually decision security fast song believe leg.', 'suddenly/why.md': 'Account listen such day method sing.', 'suddenly/miss.md': 'Rather although team thank.', 'suddenly/base.md': 'Total low room structure staff.', 'suddenly/strategy.md': 'Never understand less operation onto still trade environment.', 'ground/girl.md': 'Civil speech back sell.', 'ground/game.md': 'Fill whose card or daughter old meet.', 'ground/term.md': 'Pick return put set.', 'ground/every.md': 'Free service trouble effort somebody blood modern.', 'ground/along.md': 'Important plant increase door much.', 'ground/call.md': 'Article agent three scientist.', 'ground/do.md': 'Memory food strategy meeting.', 'ground/end.md': 'Large player discussion similar prove part.', 'ground/full.md': 'Actually start commercial.', 'ground/ever.md': 'Human example gun now my just Republican.', 'way/not.md': 'Decision together land chair.', 'way/morning.md': 'Information later service raise after trial base.', 'way/responsibility.md': 'Our child why environment care goal.', 'way/increase.md': 'Return say response political.', 'way/relationship.md': 'General view thing poor machine market peace.', 'way/soldier.md': 'Produce table should will school produce player wall.', 'way/act.md': 'Smile guess simple read style its international.', 'way/sound.md': 'Conference first finally recognize as.', 'way/reach.md': 'Exactly size discuss management miss article.', 'way/hotel.md': 'From become actually.', 'hit/run.md': 'Stock several region put thought decade evening.', 'hit/free.md': 'Crime usually produce.', 'hit/foot.md': 'Ball specific trip state.', 'hit/ball.md': 'Condition color focus traditional.', 'hit/song.md': 'Section environmental final light word in yes operation.', 'hit/since.md': 'Shoulder wrong matter seek cultural vote themselves.', 'hit/safe.md': 'Hear try spend item can along light.', 'hit/much.md': 'Guess great dream through concern feel.', 'hit/prove.md': 'Her base cup forward.', 'hit/stop.md': 'Nation this avoid herself deal place memory.', 'few/sometimes.md': 'Big order defense field represent.', 'few/southern.md': 'Meet prove admit.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/weight.md': 'Man mission American.', 'few/information.md': 'Really morning yeah.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/theory.md': 'Security effort protect future task long close.', 'few/my.md': 'Open line address contain whole impact into front.', 'resource/rest.md': 'Ok tough talk.', 'resource/move.md': 'Law write democratic drug itself house accept through.', 'resource/particularly.md': 'Affect woman nice.', 'resource/entire.md': 'Focus to once sea friend group.', 'resource/painting.md': 'Customer environment none trade.', 'resource/structure.md': 'Stuff return protect our bit reality.', 'resource/until.md': 'Growth industry region receive.', 'resource/significant.md': 'Long million fall throughout government tend.', 'resource/hospital.md': 'Quality certain fight want much body between.', 'resource/marriage.md': 'Foot specific mission.', 'for/hope.md': 'Whatever report wife fly close lot student.', 'for/poor.md': 'Explain claim police eye paper much when.', 'for/assume.md': 'Control yeah effect local economy worry.', 'for/couple.md': 'Floor both take indeed audience.', 'for/money.md': 'Join live next care material.', 'for/never.md': 'Me natural full.', 'for/situation.md': 'Show book instead hope lawyer.', 'for/north.md': 'Card level kind send loss growth.', 'for/hit.md': 'Minute wish above pass just later watch.', 'for/perhaps.md': 'Every professor sport unit rock bed.', 'project/individual.md': 'Tough safe machine small outside mention could must.', 'project/change.md': 'Century drug value.', 'project/home.md': 'Big decade edge feeling surface matter force student.', 'project/want.md': 'Region catch nation civil one Mr specific.', 'project/something.md': 'Major control three.', 'project/reality.md': 'Mouth including fine.', 'project/my.md': 'Fire point or success marriage write example.', 'project/issue.md': 'Former true career similar use visit machine.', 'project/surface.md': 'Cold reduce task life American act stage.', 'project/drug.md': 'Reason still field animal.', 'effort/morning.md': 'Policy quickly get capital smile.', 'effort/he.md': 'Thought view product interview explain.', 'effort/house.md': 'High hear thought according.', 'effort/church.md': 'Culture ask change focus.', 'effort/effect.md': 'Before suddenly who student could boy serve.', 'effort/price.md': 'Shoulder financial public reason home explain safe.', 'effort/company.md': 'Exactly treatment concern fly factor care drive.', 'effort/international.md': 'Rich take hear open.', 'effort/federal.md': 'Difference rate character by his blood this.', 'effort/computer.md': 'Lay financial article exactly.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/culture.md': 'Prevent north only miss cold.', 'by/family.md': 'Debate at office traditional stop great.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'bill/appear.md': 'Whole senior next stop yard national section.', 'bill/room.md': 'Able improve anything teacher media writer employee.', 'bill/citizen.md': 'Safe anyone major reach mother ground over leave.', 'bill/for.md': 'A several low detail.', 'bill/role.md': 'More light anything study hand power.', 'bill/set.md': 'Necessary century drive attack capital.', 'bill/generation.md': 'Stay could quality shake.', 'bill/drive.md': 'Situation we his.', 'bill/computer.md': 'Culture ahead change perhaps however audience.', 'bill/gas.md': 'Reveal attack and church.', 'color/sell.md': 'Mention although while boy turn.', 'color/throughout.md': 'She actually gun start.', 'color/management.md': 'Short serve beat increase than visit.', 'color/smile.md': 'His season employee husband.', 'color/wear.md': 'Share green measure sometimes.', 'color/official.md': 'Suddenly seat tend thus office action move.', 'color/admit.md': 'Each important clear.', 'color/treat.md': 'Tv outside attorney rich say same environment.', 'color/turn.md': 'Try drop old along.', 'color/sit.md': 'Including turn seem none computer.', 'build/together.md': 'Finally point only police artist.', 'build/rest.md': 'Author run let.', 'build/wall.md': 'Administration a week form side feeling.', 'build/none.md': 'Commercial stop page else.', 'build/explain.md': 'Join tend idea stand not option woman.', 'build/decision.md': 'Poor fund interesting bring.', 'build/beyond.md': 'Artist billion begin record anything none management practice.', 'build/dream.md': 'Decision suddenly prevent speak old power herself.', 'build/each.md': 'Able out key.', 'build/street.md': 'Knowledge specific technology before leave.', 'wrong/market.md': 'Realize key point whatever Democrat or say.', 'wrong/free.md': 'Deal even from mouth source.', 'wrong/sure.md': 'Similar him believe actually.', 'wrong/apply.md': 'Everybody office list service stock significant.', 'wrong/share.md': 'Painting every apply.', 'wrong/standard.md': 'Already place fund really.', 'wrong/might.md': 'Possible during claim view.', 'wrong/nation.md': 'About prove cold question race.', 'wrong/be.md': 'Land debate natural American.', 'wrong/suggest.md': 'Could environmental rather can us night.', 'Congress/remember.md': 'Purpose good policy line trade.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'industry/wrong.md': 'Floor race land those hard actually avoid property.', 'industry/book.md': 'Together state billion race beautiful how.', 'industry/car.md': 'Heart central eye thought painting government appear.', 'industry/cause.md': 'Time religious describe oil heart.', 'industry/feeling.md': 'Include memory strategy other statement imagine teach.', 'industry/small.md': 'Little third your season kind.', 'industry/heavy.md': 'Quality international window probably adult attention.', 'industry/election.md': 'Democrat often turn.', 'industry/possible.md': 'Structure high discover half dog half forward.', 'industry/fish.md': 'Much without in fight miss.', 'live/white.md': 'Whatever significant capital air about.', 'live/discuss.md': 'Hit result find miss culture heart clear task.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/own.md': 'Say small finish sing raise.', 'lot/seat.md': 'Method institution third political.', 'lot/wall.md': 'Each feel program size different kid.', 'lot/worry.md': 'Support moment maintain majority American rule rock.', 'lot/improve.md': 'Reason better difficult take.', 'lot/heart.md': 'Make let way.', 'lot/modern.md': 'Example first recently let.', 'lot/make.md': 'First eat data executive.', 'lot/check.md': 'Wall artist recent side approach.', 'lot/hotel.md': 'Technology town film nothing writer head from.', 'lot/perhaps.md': 'Main manage authority serious short.', 'drop/add.md': 'Fish work to individual.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/else.md': 'Fly candidate may so college.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/former.md': 'Brother college detail.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'central/several.md': 'Appear talk administration sort.', 'central/them.md': 'Unit huge call.', 'central/often.md': 'For nice after analysis series.', 'central/before.md': 'Account vote off police since.', 'central/commercial.md': 'Address country last teacher game compare.', 'central/these.md': 'Feeling rate first national.', 'central/tough.md': 'Party single media process statement forget.', 'central/crime.md': 'Hotel we five blue lawyer argue.', 'central/less.md': 'Guess environmental cover three late.', 'central/nice.md': 'Those religious audience case those.', 'civil/argue.md': 'Line culture seven six.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/ready.md': 'Central about ready information.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/question.md': 'Family evening its degree.', 'civil/gas.md': 'Talk why around necessary.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/central.md': 'Believe region their our whatever.', 'friend/oil.md': 'Little someone story put hundred able.', 'friend/discover.md': 'Someone city idea.', 'friend/month.md': 'Race walk people its Democrat sound.', 'friend/alone.md': 'Suffer concern choose participant work.', 'friend/myself.md': 'Truth simply memory alone plant large.', 'friend/note.md': 'Word end size enough.', 'friend/large.md': 'Tough glass per.', 'friend/wife.md': 'Sea investment many difference keep like improve.', 'friend/allow.md': 'Become personal own behavior sport.', 'friend/hand.md': 'Nation yourself final ground thus follow.', 'standard/late.md': 'Scientist people may story.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/level.md': 'Work around ask to.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/sound.md': 'Night national film next.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/easy.md': 'Myself must detail win.', 'standard/five.md': 'Lay would green generation season.', 'standard/analysis.md': 'While natural from staff option artist can.', 'community/book.md': 'Mr oil difficult dog.', 'community/else.md': 'Actually service thank state.', 'community/soldier.md': 'It lawyer cover job.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/cold.md': 'Election buy member alone school audience.', 'community/left.md': 'Picture let tell never.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/save.md': 'Thought hear home set employee early purpose.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/story.md': 'Anything song key first.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/bar.md': 'Among ago cover good.', 'education/evening.md': 'Give tonight sell over whole word care.', 'education/body.md': 'Note start bad part positive during.', 'education/total.md': 'Contain hit individual college month.', 'education/nature.md': 'Skin look fine policy special part.', 'education/really.md': 'Difference beyond cost but.', 'education/reason.md': 'Wrong increase investment deep near simply spring.', 'education/blood.md': 'North smile know.', 'education/imagine.md': 'Summer keep conference.', 'education/fish.md': 'Answer impact sense professor gun fast me.', 'education/article.md': 'Usually could bad attack customer couple represent.', 'lead/rest.md': 'Address half hit.', 'lead/speech.md': 'Maintain prepare indicate production surface.', 'lead/become.md': 'Building plant air something direction fall provide.', 'lead/stage.md': 'View main when Republican father plant.', 'lead/under.md': 'Test next education series.', 'lead/adult.md': 'Rule others especially institution total what law.', 'lead/which.md': 'Far task service radio reach morning accept.', 'lead/phone.md': 'Unit good including show stand.', 'lead/would.md': 'President still follow race analysis opportunity.', 'lead/trade.md': 'Success whatever environmental avoid father how although may.', 'why/show.md': 'Decade station development character movement.', 'why/data.md': 'Itself feeling fund mean.', 'why/more.md': 'Address music fish team national tough.', 'why/debate.md': 'Meeting wind medical can city face cost.', 'why/something.md': 'Everybody bed economic own least peace executive.', 'why/most.md': 'Agreement station room name.', 'why/spring.md': 'Fine according mission against.', 'why/phone.md': 'By near next teacher be degree although.', 'why/full.md': 'Yard like phone catch on attention your.', 'why/stuff.md': 'Cup everybody open book he decade.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/serve.md': 'Want exist bank book.', 'ten/nature.md': 'Eight own hot first success.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/rock.md': 'Method wall when book agency.', 'rule/hear.md': 'History event character everybody paper machine little billion.', 'rule/thing.md': 'Trial produce despite water range television.', 'rule/feel.md': 'Soon give never future difference.', 'rule/system.md': 'Bill article station despite.', 'rule/produce.md': 'Yes method sense.', 'rule/eye.md': 'Finally this team yet throughout.', 'rule/nation.md': 'Radio entire ago behavior prevent response ten according.', 'rule/thousand.md': 'Anything help military with run.', 'rule/goal.md': 'Inside firm without.', 'rule/perhaps.md': 'Back election leave.'}
print(len(set(result)), len(set(expected)))
count = 0
print("length of result", len(result))
print("length of expected", len(expected))
for y in result:
    if y not in expected:
        count += 1
        print(f"{y}:{result[y]} IS EXTRA FILE")
        print(count)




 s.anand:

A sample evaluation script for Project 1 tasks A1-A10 is available at tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip · sanand0/tools-in-data-science-public · GitHub


Sir there is an error in the evaluation script for task A1, url - https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py doesn’t exist,
instead this should - https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py
@23f2001978
That error is usually if you are using the wrong endpoint (ie. using open ai libraries instead of sending requests to aiproxy).
Without seeing the request its hard to tell you what the cause of the error is.
Kind regards
@21f2000709 @23f1002382
B10 → Create a service that creates a specified endpoint that receives a CSV and returns a JSON data . Where the JSON is expected, whether in the response body of the endpoint , or in a file will be specified by the task master 
Kind regards
hi @carlton @Jivraj
for A2 i am getting this particular error and i don’t know what i am doing wrong in this
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a terminal window displaying the output of a process that formats a Markdown file using a tool called "prettier." It showcases a request-response interaction and the before-and-after content of the file.\n\n**Key Elements & Details:**\n\n1. **Terminal Window:** The background is a dark terminal window with a green text color.\n2. **Running Task:** A line indicating that a task is running: “Running task: format the contents of ‘/data/format.md’ using ‘prettier@3.4.2’, updating the file in-place”.\n3. **HTTP Request & Response (POST):**\n * A POST request to `http://localhost:8000/run/task` is visible. The request includes details about the task, the file path (`/data/format.md`), and the prettier version (3.4.2).\n * The corresponding HTTP response is `200 OK`, indicating successful execution.\n4. **HTTP Request & Response (GET):**\n * A GET request to `http://localhost:8000/read/path/data/format.md` is displayed.\n * The response is “200 OK”.\n5. **File Content (Data/format.md):**\n * **EXPECTED:** Indicates the content before formatting.\n * **RESULT:** This section displays the formatted Markdown content. It includes:\n * A heading: “Unformatted Markdown”.\n * A paragraph with extra spaces and trailing whitespace.\n * An unformatted list with “First Item”, “Second Item”, and “Third Item”.\n * A sub-list with "Fourth Item".\n * A line of Python code: “print(\'user@example.com\')”.\n\n**In essence, the image demonstrates a process that takes a Markdown file with formatting inconsistencies and uses \'prettier\' to produce a clean, formatted version of the same file.**Screenshot from 2025-02-12 19-31-471501×564 44.7 KB
issue with evaluate.py , post the code snippet in task a2, where it calculates the result and checks with expected.
you mean screenshot of evaluate.py file?
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a screenshot of code within a software development environment, likely a code editor or IDE (Integrated Development Environment). It features lines of Python code with syntax highlighting. \n\n**Specific details:**\n\n* **Code Snippet:** The code appears to be related to file processing, possibly markdown formatting or content comparison. The code uses the `subprocess` module to run external commands.\n* **Syntax Highlighting:** Different code elements like keywords, variables, strings, and comments are colored differently to improve readability.\n* **Function Definition:** A function `a2` is defined, taking parameters `email`, `str`, `file` and `kwargs`.\n* **`subprocess.run()`:** The code utilizes `subprocess.run()` with arguments to execute a command-line tool named `prettier`. It is used for code formatting.\n* **File paths:** The file path `/data/format.md` appears in the code, indicating the file being processed.\n* **File Comparison:** The code compares the `expected` output to the `result` after running `prettier`.\n* **IDE Elements:** At the bottom, there\'s a bar showing tabs labeled "PROBLEMS", "OUTPUT", "DEBUG CONSOLE", "TERMINAL", and "PORTS", confirming it is an IDE environment.\n* **Line Numbers:** The left side of the screenshot displays line numbers, starting from 76 and extending to at least 103.\n\n**In summary,** the image depicts a code snippet involving file processing, markdown formatting using the `prettier` tool, and a comparison of expected and actual results, likely within a software development environment like VSCode or similar.Screenshot from 2025-02-12 20-21-561501×564 61.8 KB
running in docker?
////////////////////////////
Yes, I commented out check=True to see the error
@carlton @Jivraj
could you please help me out on how to start with TDS Project-1, as I am stuck at the moment and don’t know where to start from. This project is very much unfamiliar for me and I need some guidance on how to start with it. It would be really great if you could provide some help through resources/materials/videos and help me complete the project. Thanks in advance!
then im not sure exactly wait lemme check
issue with evaluate py, specifically , how it formats the file, maybe shell=True should be uncommented if commented out. then im not sure. Im not in composing docker files yet
Could anyone please help me with the project… I am trying to do it but I’m always getting errors even while starting.
My final docker image size is coming 1.25 gb, I am using the ubuntu base image as I thought it would be appropriate given the tasks. Is it ok with that size?
PS - Also I would be running out of token if I need to test again with some other base image now.
@carlton
Go through the week 1-3 assignments once, you would be good to go with Phase A tasks.
@23f2003413 @AnvithaV
You do not need the whole of ubuntu!
Just python and uv
More like 128mb image.
Please watch Tues week 5 session 1
Kind regards
Will there be more live sessions on project ?
@carlton
I could pull it down to 610 mb, using python:3.9-slim now, but there are some essential libraries that is needed which is taking up the space…will it be ok? I mean installing on the go with uv might lead to timeout during evaluation…
How did you corrected it ?
I tried cutting it down further but it is affecting the functionality, this is the best I can do, i.e., 610 mb
could you help later, when i need to construct docker image, via gmeet? PLEASE
ANY SUGGESTIONS (just one digit away) ::
import easyocr
from pathlib import Path
import re

def extract_credit_card_number(input_image: str, output_file: str):
    
    input_path = Path(f".{input_image}")
    output_path = Path(f".{output_file}")

    if not input_path.exists():
        raise ValueError(f"Image file {input_path} does not exist.")

    # Step 1: Use OCR to extract text from the image
    reader = easyocr.Reader(['en'])
    try:
        result = reader.readtext(str(input_path))
    except Exception as e:
        raise ValueError(f"OCR processing failed: {str(e)}")

    # Combine all extracted text into a single string
    extracted_text = " ".join([text for (_, text, _) in result])

    # Step 2: Use the LLM to refine the extracted text and extract the credit card number
    prompt = f"""
    The following text was extracted from an image. It may contain a credit card number. 
    Extract the credit card number and return only the number without spaces or dashes. 
    If no credit card number is found, return "None".

    Extracted text: {extracted_text}
    """
    try:
        response = chat_completion(prompt)
        card_number = response.get("choices", [])[0].get("message", {}).get("content", "").strip()

        # Validate the card number (basic check for 16 digits)
        if card_number.lower() == "none" or not card_number.isdigit() or len(card_number) != 16:
            raise ValueError("No valid credit card number found in the image.")

        # Write the card number to the output file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w") as f:
            f.write(card_number)

        return f"A8 Completed: Credit card number extracted and written to {output_file}"
    except Exception as e:
        raise ValueError(f"Failed to process text with LLM: {str(e)}")

 /data/credit-card.txt
⚠️ EXPECTED:
4026399336539356
⚠️ RESULT:
4026399338539356

&lt;Response [200]&gt;
{‘id’: ‘chatcmpl-B0De8V66WZAucAweJe6e32BWSLnpT’, ‘object’: ‘chat.completion’, ‘created’: 1739392156, ‘model’: ‘gpt-4o-mini-2024-07-18’, ‘choices’: [{‘index’: 0, ‘message’: {‘role’: ‘assistant’, ‘content’: “I’m sorry, but I can’t assist with that.”, ‘refusal’: None}, ‘logprobs’: None, ‘finish_reason’: ‘stop’}], ‘usage’: {‘prompt_tokens’: 874, ‘completion_tokens’: 11, ‘total_tokens’: 885, ‘prompt_tokens_details’: {‘cached_tokens’: 0, ‘audio_tokens’: 0}, ‘completion_tokens_details’: {‘reasoning_tokens’: 0, ‘audio_tokens’: 0, ‘accepted_prediction_tokens’: 0, ‘rejected_prediction_tokens’: 0}}, ‘service_tier’: ‘default’, ‘system_fingerprint’: ‘fp_bd83329f63’, ‘monthlyCost’: 0.048128640000000014, ‘cost’: 0.0026880000000000003, ‘monthlyRequests’: 51}
def query_gpt_image(image_path: str, task: str):
    print("🔍 Image Path:", image_path)
    image_format = image_path.split(".")[-1]
    with open(image_path, "rb") as file:
        image_data = base64.b64encode(file.read()).decode("utf-8")
    response = requests.post(
        "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions",
        headers={"Authorization": f"Bearer {"APIKEY"}",
                "Content-Type": "application/json"},
        json={
            "model": "gpt-4o-mini",
            "messages": [
                {
                "role": "user",
                "content": [
                    {"type": "text", "text": task},
                    {
                    "type": "image_url",
                    "image_url": { "url": f"data:image/{image_format};base64,{image_data}" }
                    }
                ]
                }
            ]
            }
                     )
    response.raise_for_status()
    print(response)
    print(response.json())
    result = response.json() 
response = query_gpt_image("data/credit_card.png","Extract the credit card number from image")

Why is this not working?
EDIT: Requires prompt engineering as “credit card” is sensitive information 
&lt;Response [200]&gt;
{‘id’: ‘chatcmpl-B0Dlie1ZIS68PZBCT0XJKhLKbyPAC’, ‘object’: ‘chat.completion’, ‘created’: 1739392626, ‘model’: ‘gpt-4o-mini-2024-07-18’, ‘choices’: [{‘index’: 0, ‘message’: {‘role’: ‘assistant’, ‘content’: ‘The numbers extracted from the image are:\n\n- 3009 1429 5211 59\n- 09/29\n- 113’, ‘refusal’: None}, ‘logprobs’: None, ‘finish_reason’: ‘stop’}], ‘usage’: {‘prompt_tokens’: 871, ‘completion_tokens’: 31, ‘total_tokens’: 902, ‘prompt_tokens_details’: {‘cached_tokens’: 0, ‘audio_tokens’: 0}, ‘completion_tokens_details’: {‘reasoning_tokens’: 0, ‘audio_tokens’: 0, ‘accepted_prediction_tokens’: 0, ‘rejected_prediction_tokens’: 0}}, ‘service_tier’: ‘default’, ‘system_fingerprint’: ‘fp_bd83329f63’, ‘monthlyCost’: 0.05092764000000002, ‘cost’: 0.002799, ‘monthlyRequests’: 52}
response = query_gpt_image("data/credit_card.png","Extract number from image")

Sir in main.py file I’m defining task with different variables . But in evaluate.py tasks are defined by different variables to test and when I’m testing it using python evaluate.py it returns unsuccessful . I’m testing all my tasks of main.py with Postman it returns successful.
My query is that how the tasks get evaluated and do i need to change my variables in main.py ? And what are the other things i have to change.
Also plss update evaluate.py fie with phase B tasks
@s.anand @carlton @Saransh_Saini
@22f3001777
Yes there will be one more session today (13th Feb) at usual time 8pm to 10pm
Kind regards
Hi instructors and TAs,
For the different tasks in Phase B, I don’t have a clear idea of what type of a response you expect.
eg.

Run a SQL query on a SQLite or DuckDB database &amp; Extract data from (i.e. scrape) a website &amp; Transcribe audio from an MP3 file - Do you want the query’s response on an output file like A10? or as a response?

I understand that these are broad problems you except us to solve, but it would be helpful to know what type of response you would require.
Thanks,
Trebhuvan
Hi,
Pls tell us how to use evaluate.py script to check our codes
Output specifications will be detailed in the “task” sent to the endpoint.
Phase B is meant to be vague because if you can solve it, without an elaborate and gratuitous use of gpt function calling, then you can actually solve all tasks using the same function !
Kind regards
Okay sure!! Ping me when you require to generate…
Hello sir,
Is yesterday’s session not uploaded to YouTube yet ?
I couldn’t find it in calendar either… It will be very helpful if you (or anyone else) could provide yesterday session’s recording’s link…



 21f2000709:

I tried cutting it down further but it is affecting the functionality, this is the best I can do, i.e., 610 mb


@carlton @Jivraj
will it be ok? Actually I developed it in a way that require some of the essential dependencies and at this point of time it would be dangerous to alter the way of handling it as I am running short of AIProxy Token credits.
Earlier when I asked this:



 21f2000709:

Any tentative size cutoff for the docker image?


I could have altered my way of handling dependencies but at that point of time there was no clear numbers.
I request you to please allow this time around with this size…
@carlton Could you please consider extending the submission date of Assignment 5 (it is 16th Feb right now). We are very busy with the project.
And assignment 6 submission date is much later: 9th of March.
@carlton +1 Agreed, a relaxation in deadline will be a boon for students who’ve taken up other projects this term.
usage of langchain is allowed?
It will be extended, @carlton mentioned it in a TA session already.
Hi @Rishabh2
What exactly you mean by variables?  only one argument is required for running evaluate.py that’s an email address.
You need to download both evaluate.py and datagen.py in same folder and then execute evaluate.py using uv.
uv run evaluate.py --email $any_email.
For phase B




Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025] Tools in Data Science


    Output specifications will be detailed in the “task” sent to the endpoint. 
Phase B is meant to be vague because if you can solve it, without an elaborate and gratuitous use of gpt function calling, then you can actually solve all tasks using the same function ! 
Kind regards
  

Kind regards
610 Mb’s is good size, no need to worry, it will be evaluated.
Hi @23f1002382
This is the classic case where you use Prompt engineering to solve your problems. I assume you have already achieved your answers, but I want to clarify this for someone who is facing this problem.
The thing is GPT-4o-mini is intelligent enough to understand what kind of task you are asking it do, and extracting Credit Card info from an image is one of the many prohibited tasks.
What you can do is, try to fool it using itself. Just ask ChatGPT to generate a prompt that would be capable of fooling itself into extracting out that credit card info. I was capable of doing it after pretending to be a working on a Cyber Security project, and other fake details which ChatGPT itself provided me with.
@carlton . I cannot send requests to https://aiproxy.sanand.workers.dev/openai/v1 . Getting  $RateLimitError: Error code: 429 - {‘message’: 'On 2025-02 you used $2.0003758999999954, exceeding 2'}  . Looks like I used all of my credit . What can I do now ? Project is also Incomplete.
Try creating a better prompt for this task.
Hint: Ask it to recheck certain similar looking digits.
After submitting docker image through, it will be pulled and our token will be used.
Things to be checked at your end.
1. podman run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p8000:8000 $IMAGE_NAME works fine
2.  Above command will start 8000 server so use evaluate.py to test if things are working as expected.
Kind regards.
Jivraj
Hi @JoelJeffrey
What you did wrong and how did you correct it?
I think there was something wrong with the way the code was getting inputs (keys). I just rewrote that part and it worked
Hi @22f3001307
Provide required write permissions to /data folder. We will also discuss this issue regarding permissions in initial part of today’s session.
Kind regards
Hello sir,
Is yesterday’s session not uploaded to YouTube yet ?
I couldn’t find it in calendar either…
Command to run the image in the docs, seemed to have some error,
Here\'s a detailed description of the image:\n\n* **Content:** The image showcases a snippet of command-line instructions.\n* **Text:** The text instructs the user to run an image via a `podman run` command, specifying environment variables (`-e`) for an API token and port mapping (`-p`).\n* **Command details:**\n * The command begins with `podman run $IMAGE_NAME`.\n * It sets the environment variable `AIPROXY_TOKEN` to the value of `$AIPROXY_TOKEN`.\n * It maps port 8000 on the host to port 8000 inside the container.\n * Finally, it indicates that this automatically serves an API at `http://localhost:8000/run?task=...`.\n* **Background:** The text is displayed in white against a dark teal/green background, likely representing a terminal or command-line interface.\n* **Visual effect:** The part of the text after "...and" is blurred.\n\n\n\nIn essence, the image provides instructions on how to run a container using `podman` and access an API served by that container.
The command:
podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000
gives the error:
crun: executable file `-e` not found in $PATH: No such file or directory: OCI runtime attempted to invoke a command that was not found
However the correct command seems to be:
podman run -e AIPROXY_TOKEN="$AIPROXY_TOKEN" -p 8000:8000 $IMAGE_NAME
This works totally fine.
Here\'s a point-by-point description of the image:\n\n* **Content Type:** The image displays a command-line interface (CLI) or terminal window.\n* **Background:** The background is black, typical of most terminal windows.\n* **Text:** The window displays several lines of white text representing log messages or output from a running application. \n* **Log Messages:** The messages indicate the application is starting up, with lines like:\n * "Started server process [ ]"\n * "Waiting for application startup..."\n * "Application startup complete."\n * "Webcam running at http://0.0.0.0:8080 (Press CTRL+C to quit)"\n* **Application Type:** The log messages suggest a web application with a webcam component is running.\n* **Address:** The application is accessible through the URL http://0.0.0.0:8080, indicating it\'s running locally on the host machine.\n* **Termination:** The message "(Press CTRL+C to quit)" indicates that the user can terminate the application using the keyboard shortcut Ctrl+C.
@Jivraj
nvm i can laugh nw xD
One final question @Jivraj @carlton , will our projects be evaluated with our AIPROXY_TOKEN or a different one.
Because my project is done but for evaluation if my AIPROXY_TOKEN is used, it might be out of credits.
Thanks. Do you know the new date?
That wasn’t said, but it was not this weekend for sure.
my automation is happening and prompt distribution too but it just isnt able to pass any test after 1st in evaluation.py did someone else face same problem if yes then how to solve it please help
actually that easyocr is directly sending the clear text(no confusion) to llm and llm is just extracting the  exact numbers from it .
[quote=“23f2001975, post:211, topic:164277, full:true”]
@s.anand @carlton
While running the evaluation.py i am facing several issues because my output isnt strictly adhering sometimes to it will the checking be on such a basis only
for example in A3
 EXPECTED:
129
 RESULT:
“129”
this is the error i get while it is the function in eval.py checking problem as it gets response as text and doesnt strip (“”)
Please guide what should i do



 21f2000709:

podman run -e AIPROXY_TOKEN=“$AIPROXY_TOKEN” -p 8000:8000 $IMAGE_NAME


Yes this is correct command, we will update in project page.




Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025] Tools in Data Science


    After submitting docker image through, it will be pulled and our token will be used. 
Things to be checked at your end. 
1. podman run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p8000:8000 $IMAGE_NAME works fine 
2.  Above command will start 8000 server so use evaluate.py to test if things are working as expected. 
Kind regards. 
Jivraj
  

@Jivraj sir I get this error
but my app.py is able to get the server running on localhost and not on 0.0.0.
model='gemma3:27b' created_at='2025-06-14T05:10:45.002889261Z' done=True done_reason='stop' total_duration=40387523003 load_duration=18323168 prompt_eval_count=323 prompt_eval_duration=18824964064 eval_count=222 eval_duration=21543491830 message=Message(role='assistant', content="Here's a point-by-point description of the image:\n\n* **Content:** The image shows a terminal output with an error message.\n* **Error Type:** The error is a `ModuleNotFoundError`.\n* **Specific Error:** The error indicates that the module named 'fastapi' could not be found.\n* **File and Line:** The error occurred in the file `/app/app.py` on line 1, during an import statement.\n* **Command Prompt:** The terminal prompt displays the user (`vikramjncash`), host (`ANJANEYA`), and current directory (`/mnt/c/IIT_Madras/TDS_Project`). It also shows a podman run command with an ID.\n* **Text Color:** The text is displayed in shades of blue and green on a black background, typical of terminal windows.\n\n\n\nIn summary, the image depicts an error message in a terminal indicating that the 'fastapi' module is missing or not installed, likely during the execution of a python script.", thinking=None, images=None, tool_calls=None)image1014×190 18.2 KB
could you please help ?
When i am trying evaluate the code, I am getting the following error
Traceback (most recent call last):
  File "/var/folders/rj/z_3b8hl51558519w90k5hp600000gn/T/evaluateyea70I.py", line 20, in &lt;module&gt;
    from datagen import (
    ...&lt;9 lines&gt;...
    )
ModuleNotFoundError: No module named 'datagen'

can someone tell me what i should do?
@carlton @Jivraj @Saransh_Saini
@22f3001307
Install datagen.py in the same folder from where you are executing evaluate.py.
@vikramjncasr Check how you are executing, use uv or else install required modules globally
Kind regards
Sir,
the folder already exists in that folder
besides, I am using OPENAI_API_KEY=$AIPROXY_TOKEN uv run https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/evaluate.py from Anand sir’s page to run the code in my system
Sir would the belowformat be ok when you evaluate ?
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a command-line interface (CLI) or terminal window. It displays a series of informational messages related to a server process, likely a web application. \n\n**Key Elements & Details:**\n\n* **Text-Based Output:** The entire image consists of text-based messages displayed in a green color.\n* **Process Information:** The messages indicate the startup and running status of a server process.\n* **Command Execution:** The line beginning with `PS C:\\IIT_Madras\\TDS_Project>` appears to be the command that initiated the process. It uses the `uvicorn` command to launch a web application (`app.py`). The command includes parameters for specifying the host (`127.0.0.1`) and port (`8000`).\n* **Startup Sequence:** The messages show the server process finishing, starting up, waiting for the application to start, and ultimately completing its startup.\n* **Running Status:** The message "Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)" confirms that the server is running and listening on the specified address and port.\n* **HTTP Request:** The final line "127.0.0.1:54184 - "GET / HTTP/1.1" 200 OK" indicates a successful HTTP GET request to the root path of the application.\n\n**In essence, the image documents the successful launch and operation of a web application served by Uvicorn.**image985×211 24.1 KB
But when I use podman i keep getting errror.
Hello,
Can anyone please reset my AIProxy limit. I am getting this error, {“detail”:“Agent error: 429 Client Error: Too Many Requests for url: https://aiproxy.sanand.workers.dev/openai/v1/chat/completions”}
Thank you.
i am getting unauthorized error in A9 again and again, i have pasted my code if someone can help please look into this.
# /// script
# requires-python = "&gt;=3.11"
# dependencies = [
#   "numpy",
#   "httpx",
#   "fastapi",
# ]
# ///


import httpx
import numpy as np
import datetime
import os

from fastapi import HTTPException


now = datetime.datetime.now()

OPENAI_API_KEY = os.environ["AIPROXY_TOKEN"]
OPENAI_API_URL = "http://aiproxy.sanand.workers.dev/openai/v1/embeddings"


# async def get_similarity_from_embeddings(emb1: list[float], emb2: list[float]) -&gt; float:
def get_similarity_from_embeddings(emb1: list[float], emb2: list[float]) -&gt; float:
    # """Calculate cosine similarity between two texts."""
    # emb1 = await embed(text1)
    # emb2 = await embed(text2)
    return float(np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2)))


# async def embed_list(text_list: list[str]) -&gt; list[float]:
async def embed_list(text_list: list[str]) -&gt; list[float]:
    OPENAI_API_KEY = os.environ["AIPROXY_TOKEN"]
    OPENAI_API_URL = "http://aiproxy.sanand.workers.dev/openai/v1/embeddings"
    """Get embedding vector for text using OpenAI's API."""
    try:
        async with httpx.AsyncClient() as client:
            # with httpx.AsyncClient() as client:
            response = await client.post(
                # response = httpx.post(
                OPENAI_API_URL,
                headers={"Authorization": f"Bearer {OPENAI_API_KEY}"},
                
                json={"model": "text-embedding-3-small", "input": text_list},
            )
        # print(f'{response.json()["data"][0]["embedding"]}')
        emb_list = [emb["embedding"] for emb in response.json()["data"]]
        print(f"Number of embeddings returned = {len(emb_list)}")
        return emb_list

    except KeyError as e:
        print(f"INSIDE EMBED_LIST IN A9. KeyError occurred while querying GPT: {e}")
        raise HTTPException(status_code=400, detail=str(e))

    except Exception as e:
        print(f"INSIDE EMBED_LIST IN A9. General Error while querying gpt: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def most_similar(embeddings):
    # Extract the phrases and their corresponding embeddings
    phrases = list(embeddings.keys())
    emb_values = list(embeddings.values())

    # Initialize variables to track the maximum similarity
    max_similarity = -1  # Start with the smallest possible similarity value
    most_similar_pair = None

    # Compute cosine similarity between each pair of embeddings
    for i in range(len(emb_values)):
        for j in range(i + 1, len(emb_values)):  # Avoid repeating pairs
            similarity = get_similarity_from_embeddings(emb_values[i], emb_values[j])
            if similarity &gt; max_similarity:
                max_similarity = similarity
                most_similar_pair = (phrases[i], phrases[j])

    return most_similar_pair


# async def get_similar_comments(input_file_path: str, output_file_path: str):
async def get_similar_comments(input_file_path: str, output_file_path: str):
    print(f"Reading the input file: {input_file_path}")
    with open(input_file_path, "r") as file:
        comments = file.readlines()

    print(f"Embedding the comments")
    # embeddings = await embed_list(comments)
    embeddings = await embed_list(comments)
    embed_dict = dict(zip(comments, embeddings))
    most_similar_pair = most_similar(embed_dict)
    print(f"Most similar comments: {most_similar_pair}")

    with open(output_file_path, "w") as file:
        for comment in most_similar_pair:
            file.write(f"{comment.strip()}\n")
        # file.write(f"Most similar comments: {most_similar_pair}")


if __name__ == "__main__":
    # import asyncio

    input_file_path = "/data/comments.txt"
    output_file_path = "/data/similar_comments.txt"
    # asyncio.run(get_similar_comments(input_file_path, output_file_path))
    get_similar_comments(input_file_path, output_file_path)

@Jivraj @carlton sir can you take my doubt in today’s session please , i have successfully run docker server but endpoints are not working…
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a computer screen with multiple open windows, typical of a software development environment. It appears to be focused on a Python-based project, likely using the FastAPI framework, as indicated by the code visible in the editor window. \n\n**Detailed Breakdown:**\n\n* **Editor Window (Right):** \n * A code editor (likely VS Code based on the interface) is open, displaying Python code. \n * The code contains comments indicating the project is related to automation.\n * Sections are dedicated to defining environment variables (specifically `AIPROXY_TOKEN`), defining API routes (`@app.get("/")`), and handling requests.\n * There are also imports for `fastapi`, `logging`, and other common Python modules.\n * At the bottom of the editor window, there\'s a status bar indicating file types, line endings, and other settings.\n* **Browser Window (Left):**\n * A web browser window displays an error message: "Not found!". \n * The URL in the address bar is "http://localhost:5000", suggesting a local development server is running. \n * The browser window is likely displaying the response from an API endpoint that doesn’t exist or is not configured correctly.\n* **Terminal/Output Window (Bottom):** \n * A terminal or output window displays build information from a Dockerfile. \n * It details the sizes of files and directories created during the build process.\n * The text shows that multiple layers are being built for a Docker image.\n* **Other Elements:**\n * The top bar shows open tabs for various files (e.g., app.py, README.md).\n * The file explorer on the left-hand side shows the project\'s directory structure.\n * VS Code UI elements are visible (problems, debug, source control icons) indicating a development workflow.\n\n**In Summary:**\n\nThe image shows a developer working on a Python/FastAPI project, encountering an error (Not Found) in the browser, and building a Docker image for the project. The development environment is set up within VS Code, with the terminal showing build details.Screenshot 2025-02-13 1659121917×1024 124 KB
If anyone have knowledge about this , please help
How did u resolve the issue?  @JoelJeffrey
I am also facing the same issue.
Evaluation Output:
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"

🔴 A9 failed: 'data'

❌ A9 FAILED

I sense ‘Authentication Problem’ happens only with the evaluation script, as the curl requests seems to work fine.
INFO:httpx:HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 200 OK"
INFO:     127.0.0.1:60849 - "POST /run?task=%60%2Fdata%2Fcomments.txt%20contains%20a%20list%20of%20comments,%20one%20per%20line.%20Using%20embeddings,%20find%20the%20most%20similar%20pair%20of%20comments%20and%20write%20them%20to%20%2Fdata%2Fcomments-similar.txt,%20one%20per%20line HTTP/1.1" 200 OK

Any views? @carlton @Jivraj
@Jivraj @carlton Sir i keep getting this error
Here\'s a detailed description of the image:\n\n**Overall:**\n\nThe image displays a terminal output, specifically an error message encountered while attempting to run a Python application.\n\n**Key Elements:**\n\n1. **Command Line:** The beginning of the output shows the command that was executed: `uv run app.py`. It indicates the use of the `uv` tool to run a Python file named `app.py`.\n2. **Traceback:** A traceback is displayed, starting with "Traceback (most recent call last):". This indicates an error occurred during program execution and provides information about where the error originated.\n3. **File Path:** The traceback points to a specific file: `/home/vidushilinux/tds-project-1/app.py`, line 9. This indicates that the error occurred in the `app.py` file within the `tds-project-1` directory, on line 9.\n4. **Error Message:** The core of the error message is "ModuleNotFoundError: No module named \'fastapi\'". This indicates that the Python script is trying to import a module named `fastapi`, but the module is not installed or not found in the Python environment\'s search path.\n5. **Import Statement:** The line of code triggering the error is "from fastapi import FastAPI", showing that the script attempts to import the `FastAPI` class from the `fastapi` module.\n\n**Interpretation:**\n\nThe error indicates that the `fastapi` library is not installed in the Python environment where the script is being executed. To resolve the error, one would need to install the `fastapi` package using a package manager like `pip` (e.g., `pip install fastapi`).\n\n\n\nimage671×109 8.64 KB
even though i have downloaded the packages globally and tried installing them by making a venv but nothing seems to work please help
what is the base url?
use your api key guys
we are using that only bro, only for A9 it says unauthorized
network mapping or something, even im working that out
Even i am facing the same problem. I am unable to resolve it ,i tried many ways.
could anyone please help
2 ways, try command line package installing, or inside venv, try which python,etc and make paths reconcile, or inside venv, uv pip install , if that doesn’t work, inside venv pip install 
thanks , already it work out
@Jivraj @carlton sir please help
When I am downloading the data folder after processing datagen.py , it is trying to download in root folder and it is facing permission error . how can we overcome this ?
needs sudo permission all the time…
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a terminal or command-line interface. It is predominantly black with text rendered in shades of blue and green. \n\n**Key Elements:**\n\n* **Prompt:** The top line shows a user prompt indicating the current user ("vkovalchuk") and the current directory ("/mnt/c/IT_Hadara/TDS_Project").\n* **Files/Directories:** The main content consists of a list of files and directories within the current directory. Common Linux/Unix directories are visible, including "bin", "boot", "etc", "home", "lib", "media", "mnt", "opt", "proc", "root", "run", "sbin", "srv", "sys", "usr", and "var". Some directories have the phrase "us-merged" appended to them.\n* **Cursor:** A blinking cursor is visible at the end of the directory list, indicating the input point for the user.\n* **Formatting:** The directories are aligned and appear to be the result of an "ls" (list) command in a Unix-like operating system.\n* **Color Scheme:** Blue is used for typical directory/file names, while some directories ("init", "tmp") appear in green.\n\n**In summary,** the image depicts a standard Linux/Unix command-line session listing the contents of a directory.image1368×124 19.9 KB
Hello Sir @carlton @Jivraj
What are implications on missing the project 1.
Due to some personal reasons I wasn’t able to start any work on my project 1. It seems difficult for me to complete it.
Could you please tell what will be the implications of missing it. Will I in anyway be able to cover up and pass in the subject doing future assignments and projects?
Thank you
PS: This isn’t any request to extend dates. I accept my fault and respect the dates provided by the team.
Sir I haven’t initaiated the podman earlier.
Now when i try to use podman using the wsl via the code “sudo apt install -y podman” it is asking for the password…
The problem is:

I haven’t set any password for podman earlier.
Though it is asking for password but it is not taking any input.(ie I am unable type anything there).
what should I am supposed to do…
Here\'s a detailed description of the image:\n\n**Overall:** The image depicts a terminal window (likely a PowerShell terminal within a development environment like VS Code) filled with command-line output. The background is black. \n\n**Key Elements & Content:**\n\n* **Terminal Window:** The main focus is a text-based terminal window.\n* **Command Output:** The terminal displays several lines of text, primarily indicating password requests (`sudo: password for mycodecoder2011:`) followed by messages like "Sorry, try again." and error messages indicating incorrect password attempts.\n* **Command History:** The image shows a series of commands that appear to be updating and installing software packages using `apt` (a package manager commonly used in Debian/Ubuntu Linux distributions). Specifically, the commands attempt to run `sudo apt update` and `sudo apt install -y podman`. \n* **VS Code Interface:** On the right edge, parts of the VS Code interface are visible including tabs labeled "PROBLEMS", "OUTPUT", "DEBUG CONSOLE", "TERMINAL", and "PORTS".\n* **File Path:** The commands in the terminal include a file path: `/mnt/c/WS/Projects`.\n\n**Summary:** The image shows a user attempting to update and install a software package (`podman`) on a Linux system via the command line, likely using WSL (Windows Subsystem for Linux) within VS Code, and experiencing issues with password authentication.image1612×359 21.3 KB

@s.anand @Jivraj I think the evaluation.py test case is broken for A8 because I can manually see more folders and markdown files than the expected case output of A8 evaluation. And also is there any evaluation file for Part B
password are not visible in wsl when typed, just type and enter if it matches, the process will continue
Sir If possible please extend the Project deadline.
same error the execution is correct but format.md file is not modified with correct markdown format
@carlton @Jivraj
can u please upload the video that was recorded on 12th Feb, as I am able to view only the video that was last recorded on 11th Feb (3 hrs 57 mins video). As I am doing the project completely from the recorded videos, please post those videos in youtube at the earliest.
Hi @23f2003413
Because of some technical issues we could not record 12 Feb session. That was doubt clearing session regrading project1.
Kind regards
Can we submit project number of times before deadline…
thanks for you feedbacak I have figured it out! Thanks it means a lot…
A silly Doubt though but still a doubt!
Could we create an image first of our project in initial stage(ie the my “app.py” is not completely ready) but I have build an docker image including the app.py and other dependencies.
Should I give the same url now and then carry on updating the app.py
Or, Should first complete and then upload in the form!
plz reply!!
Can you send the link for the video on 11th Feb?
How did you resolve the file cannot be found error?
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a command-line interface (CLI) displaying a series of failed requests and error messages, likely related to a process attempting to extract data from an image and write it to a file. The background is black, and the text is primarily white and red, indicating error states.\n\n**Key Elements & Details:**\n\n1. **Initial Task Description:** A line stating the task: "\'data/credit\\_card.png\' contains a credit card number. Pass the image to an LLM, have it extract the card number, and write it without spaces to \'/data/credit-card.txt\'."\n\n2. **First HTTP Request:** A "POST" request to "http://localhost:8000/run?task=%60%2Fdata%2Fcredit+card.png%60+contains+a+credit+card+number.+Pass+the+image+to+an+LLM%2C+have+it+extract+the+card+number%2C+and+write+it+without+spaces+to+%60%2Fdata%2Fcredit-card.txt%60" results in an "HTTP/1.1 500 Internal Server Error."\n\n3. **JSON Error Detail:** A JSON object detailing the 500 error, stating: "Error extracting credit card: Image file C:\\\\Users\\\\starb\\\\Desktop\\\\tds\\_p\\_1\\\\data\\\\credit\\_card.png does not exist."\n\n4. **Second HTTP Request:** A "GET" request to "http://localhost:8000/read?path=/data/credit-card.txt" returns an "HTTP/1.1 404 Not Found."\n\n5. **First A8 Failed:** An "A8 failed: Cannot read /data/credit-card.txt" message, accompanied by a red "X" indicating a failure.\n\n6. **Third HTTP Request:** A "POST" request to "https://aiproxy.sanand.workers.dev/openai/v1/embeddings" returns an "HTTP/1.1 401 Unauthorized."\n\n7. **Second A8 Failed:** An "A9 failed: \'data\'" message, accompanied by a red "X" indicating a failure.\n\n**In essence:** The image depicts a failed attempt to process an image to extract a credit card number, write it to a text file, and potentially use it in an OpenAI embedding request. The process fails because the image file is not found, the output file doesn’t exist, and there\'s an authentication issue when attempting the OpenAI request.image872×550 16.5 KB
pls help with this error
Sir, could you please mention the title of youtube videos in which the project session are covered?
Hi,
When yesterday’s recorded video will be uploaded in youtube?
Thanks for the prompt reply @Jivraj . I have done the project setup till whatever was covered on the 11th Feb session. I am not able to proceed further as I have no clue on how to work on this. Can you please help me out as it would mean a lot.
@carlton @23f1002382


Here\'s a detailed description of the image:\n\n* **Overall Composition:** The image is a graphic featuring text overlaid on a colorful, geometric patterned background. It appears to be a title card or a slide header.\n* **Text:** The text "WEEK 5" is displayed in large, bold, white letters. Below it, "SESSION 1" is written in a similar style. \n* **Background Pattern:** The background is divided into three horizontal bands, each with a unique geometric pattern consisting of colorful shapes (triangles, squares, circles) and various icons like globes, scissors, and abstract designs.\n* **Color Palette:** The color scheme is vibrant and diverse, including shades of blue, orange, red, green, and white.\n* **Style:** The design has a flat, modern, and somewhat playful aesthetic, likely intended for a digital presentation or infographic.\n* **Format:** The image has a widescreen aspect ratio with dark bands on the left and right sides.\n\n\n\n


Are you subscribed to the TDS channel? If you were it would notify you immediately when it was uploaded. (10am this morning).
Please subscribe to the channel. It was also on the main page for TDS.
https://tds.s-anand.net/#/README


YouTube


Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a brightly colored, vector-style illustration related to data science. It features a collage of icons and graphics representing tools and concepts within the field.\n\n**Key Elements:**\n\n* **Text:** The central text reads "TOOLS IN DATA SCIENCE" in a bold, stylized font. The text is displayed on a dark blue rectangle to emphasize its importance.\n* **Icons & Graphics:** The background is filled with various icons representing:\n * **Computing/Technology:** Laptops, circuit boards, computer screens, and a globe.\n * **Data Visualization:** Bar graphs, line graphs, and a variety of geometric shapes used for data representation.\n * **Connectivity/Networking:** Network diagrams, interconnected lines, and nodes, signifying data connections and relationships.\n * **Abstract Data Elements:** Scattered geometric shapes, circles, and other abstract designs that hint at complex data sets.\n* **Color Palette:** The illustration uses a vibrant and modern color scheme featuring:\n * **Primary Colors:** Red, blue, and green.\n * **Secondary Colors:** Teal, purple, and yellow.\n * **Neutral Tone:** A beige/cream background.\n* **Style:** The artwork has a flat, vector-graphic aesthetic. It appears to be a promotional graphic or infographic designed to visually communicate the concept of data science tools.\n\n**Overall, the image is a visually appealing and informative representation of the tools and concepts involved in data science, intended to be eye-catching and communicative.**
Tools in Data Science
Share your videos with friends, family, and the world





Kind regards
Thanks sir, Now I subscribed to the channel.
Hi @carlton sir! Is this video (Week-5 Session-3) the continuation video from the previous session (Week-5 Session-1), since the Session-2 video has not been recorded and uploaded. I am totally relying on these videos to complete the project sir. Please help me out!
offical answer is you dont, you let run it in docker and it would apparently work , im not there yet, bus as of of now , create your docker image and start testing there
The deadline is at 11:59 pm right Saturday? Feb 15th? Google Standard Time?
Yes feb 15 11:59 PM indian standard time.
Hi @23f2003413
Session 3 was continuation of session1.
Session 2 was DCS(doubts clearing session)
Kind regards
Got it. Thank you sir!
Hi @Jivraj, @carlton, @Saransh_Saini sir,
I’m getting the following error while post mapping, I couldn’t able to fix it.
I’m getting status code as 400 from the llm api response. How to fix it sir?
   "json": {
        "message": "Invalid JSON body: SyntaxError: Unexpected token 'm', \"model=gpt-\"... is not valid JSON"
    }

There is some problem with the json that you are using.
Try to debug it with GPT.
week5 session 1 and session3
Here\'s a detailed description of the image:\n\n1. **Screen Display:** The image captures a computer screen displaying a Visual Studio Code error message.\n2. **Error Message:** A pop-up window indicates "The window is not responding". The message suggests options to reopen, close, or keep waiting for the application. A checkbox "Don\'t restore editors" is also present.\n3. **Background:** The background is a dark-themed code editor window, likely Visual Studio Code itself, with visible lines of code.\n4. **Code Snippet:** A code snippet is partially visible in the background. It includes lines starting with "led", "10 == 0", and "EN: os.environ.get("AIPROXY".\n5. **Terminal:** A terminal window is visible at the bottom of the screen, displaying a PowerShell prompt.\n6. **Color Scheme:** The image utilizes a dark color scheme, common in coding environments.image929×427 11.7 KB
Is someone else are also getting this kind of error messages…
I have a low end system, then shifted to high one then again this popped up…
Does anyone know how to come over this…
Hello @carlton @Jivraj @Saransh_Saini sir, I have implemented the code for B3 &amp; B6 but unfortunately as per the instructions given in project for B3 &amp; B6 —


B6. Extract data from (i.e. scrape) a website


B3. Fetch data from an API and save it


They are almost similar and it’s getting confusing in both cases, it’s given output based on B3 and not reading the input for B6, so could you please help me out with this?
Is anyone else facing this or a similar issue?
Two solutions

give proper permissions.
use docker containers this is what we will test on.

I would prefer 2nd approach
For B tasks use LLM to write code on the fly and execute it, use better prompts. In evaluation script detailed task will be provided with what data needs to be scraped, endpoints, parameters, etc.
{‘error’: {‘message’: “Invalid ‘tools[6].function.description’: string too long. Expected a string with maximum length 1024, but got a string with length 4384 instead.”, ‘type’: ‘invalid_request_error’, ‘param’: ‘tools[6].function.description’, ‘code’: ‘string_above_max_length’}, ‘monthlyCost’: 0.08569882000000002, ‘cost’: 0, ‘monthlyRequests’: 82}
i cant send long prompts then what is the point?
local llm also we cant use you because you have some limit on file size, we send long prompt also it doesn’t work xD . What do we do?
@s.anand @carlton @Jivraj @anybodywhowouldatleastreplyONCE
Hi,
If you read these questions carefully then they are not similar, one is asking you to extract data from a webpage, meaning you have to do something related to the HTML code. And the other is simply sending a request to a given endpoint.
Hi @carlton @Saransh_Saini @Jivraj ,
In task A6
Find all Markdown (.md ) files in /data/docs/ . For each file, extract the first occurrance of each H1 (i.e. a line starting with #  ). Create an index file /data/docs/index.json that maps each filename (without the /data/docs/ prefix) to its title (e.g. {"README.md": "Home", "path/to/large-language-models.md": "Large Language Models", ...} ).
Here expected output JSON “key” is file name or file path without prefix /data/docs/ as prompt is bit confusing . when “path/to/large-language-models.md” is given in example is actually referring to file path or filename itself is “path/to/large-language-models.md”.
This can easily be checked by runing the evaluate.py file.
Anyways, a file present in data/docs/folder_a/folder_b/md_file should be folder_a/folder_b/md_file as key.
hey @23f2001975 did you find the solution to this problem ?
i am facing the exact same issue
@carlton
Sir, my token limit has crossed the $1 limit. Will I receive new limit or a fresh token ? I still need to complete my project.
Thank you
 /data/credit-card.txt
 EXPECTED:
30091429521159
 RESULT:
3009142952159
{‘role’: ‘assistant’, ‘content’: ‘3009142952159’, ‘refusal’: None} if LLM is giving wrong output. I hope y’all look into edge cases. Some people tried really hard. to prompt it xD   .
You can check the logs

(venv) @ANDIECOOLER2 ➜ /workspaces/TDS-Project-1/app (checking-with-open-ai) $ uv run evaluate.py 
🟡 Running task: Install `uv` (if required) and run the script `https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py`
with `23f1002382@ds.study.iitm.ac.in` as the only argument
HTTP Request: POST http://localhost:8000/run?task=
Install+`uv`+(if+required)+and+run+the+script+`https%3A%2F%2Fraw.githubusercontent.com%2FANdIeCOOl%2FTDS-Project1-Ollama_FastAPI-%2Frefs%2Fheads%2Fmain%2Fdatagen.py`
with+`23f1002382%40ds.study.iitm.ac.in`+as+the+only+argument
 “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/format.md “HTTP/1.1 200 OK”
 A1 PASSED
10.8.2
 Running task: Format the contents of /data/format.md using prettier@3.4.2, updating the file in-place
HTTP Request: POST http://localhost:8000/run?task=
Format+the+contents+of+`%2Fdata%2Fformat.md`+using+`prettier%403.4.2`%2C+updating+the+file+in-place
 “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/format.md “HTTP/1.1 200 OK”
 A2 PASSED
 Running task: The file /data/dates.txt contains a list of dates, one per line. Count the number of Wednesdays in the list, and write just the number to /data/dates-wednesdays.txt
HTTP Request: POST http://localhost:8000/run?task=The+file+`%2Fdata%2Fdates.txt`+contains+a+list+of+dates%2C+one+per+line.+Count+the+number+of+Wednesdays+in+the+list%2C+and+write+just+the+number+to+`%2Fdata%2Fdates-wednesdays.txt` “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/dates-wednesdays.txt “HTTP/1.1 200 OK”
 A3 PASSED
 Running task: Sort the array of contacts in /data/contacts.json by last_name, then first_name, and write the result to /data/contacts-sorted.json
HTTP Request: POST http://localhost:8000/run?task=Sort+the+array+of+contacts+in+`%2Fdata%2Fcontacts.json`+by+`last_name`%2C+then+`first_name`%2C+and+write+the+result+to+`%2Fdata%2Fcontacts-sorted.json` “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/contacts-sorted.json “HTTP/1.1 200 OK”
 A4 PASSED
 Running task: Write the first line of the 10 most recent .log file in /data/logs/ to /data/logs-recent.txt, most recent first
HTTP Request: POST http://localhost:8000/run?task=Write+the+first+line+of+the+10+most+recent+`.log`+file+in+`%2Fdata%2Flogs%2F`+to+`%2Fdata%2Flogs-recent.txt`%2C+most+recent+first “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/logs-recent.txt “HTTP/1.1 200 OK”
 A5 PASSED
 Running task: Find all Markdown (.md) files in /data/docs/.
For each file, extract the first occurrance of each H1 (i.e. a line starting with # ).
Create an index file /data/docs/index.json that maps each filename (without the /data/docs/ prefix) to its title
(e.g. {"README.md": "Home", "path/to/large-language-models.md": "Large Language Models", ...})
HTTP Request: POST http://localhost:8000/run?task=Find+all+Markdown+(`.md`)+files+in+`%2Fdata%2Fdocs%2F`.
For+each+file%2C+extract+the+first+occurrance+of+each+H1+(i.e.+a+line+starting+with+`%23+`).
Create+an+index+file+`%2Fdata%2Fdocs%2Findex.json`+that+maps+each+filename+(without+the+`%2Fdata%2Fdocs%2F`+prefix)+to+its+title
(e.g.+`{“README.md”%3A+“Home”%2C+“path%2Fto%2Flarge-language-models.md”%3A+“Large+Language+Models”%2C+...}`) “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/docs/index.json “HTTP/1.1 200 OK”
 A6 PASSED
 Running task: /data/email.txt contains an email message. Pass the content to an LLM with instructions to extract the sender’s email address, and write just the email address to /data/email-sender.txt
HTTP Request: POST http://localhost:8000/run?task=`%2Fdata%2Femail.txt`+contains+an+email+message.+Pass+the+content+to+an+LLM+with+instructions+to+extract+the+sender’s+email+address%2C+and+write+just+the+email+address+to+`%2Fdata%2Femail-sender.txt` “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/email-sender.txt “HTTP/1.1 200 OK”
 A7 PASSED
 Running task: /data/credit_card.png contains a credit card number. Pass the image to an LLM, have it extract the card number, and write it without spaces to /data/credit-card.txt
HTTP Request: POST http://localhost:8000/run?task=`%2Fdata%2Fcredit_card.png`+contains+a+credit+card+number.+Pass+the+image+to+an+LLM%2C+have+it+extract+the+card+number%2C+and+write+it+without+spaces+to+`%2Fdata%2Fcredit-card.txt` “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/credit-card.txt “HTTP/1.1 200 OK”
 /data/credit-card.txt
 EXPECTED:
30091429521159
 RESULT:
3009142952159
 A8 FAILED
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings “HTTP/1.1 200 OK”
 Running task: /data/comments.txt contains a list of comments, one per line. Using embeddings, find the most similar pair of comments and write them to /data/comments-similar.txt, one per line
HTTP Request: POST http://localhost:8000/run?task=`%2Fdata%2Fcomments.txt`+contains+a+list+of+comments%2C+one+per+line.+Using+embeddings%2C+find+the+most+similar+pair+of+comments+and+write+them+to+`%2Fdata%2Fcomments-similar.txt`%2C+one+per+line “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/comments-similar.txt “HTTP/1.1 200 OK”
 A9 PASSED
 Running task: The SQLite database file /data/ticket-sales.db has a tickets with columns type, units, and price. Each row is a customer bid for a concert ticket. What is the total sales of all the items in the “Gold” ticket type? Write the number in /data/ticket-sales-gold.txt
HTTP Request: POST http://localhost:8000/run?task=The+SQLite+database+file+`%2Fdata%2Fticket-sales.db`+has+a+`tickets`+with+columns+`type`%2C+`units`%2C+and+`price`.+Each+row+is+a+customer+bid+for+a+concert+ticket.+What+is+the+total+sales+of+all+the+items+in+the+“Gold”+ticket+type%3F+Write+the+number+in+`%2Fdata%2Fticket-sales-gold.txt` “HTTP/1.1 200 OK”
 HTTP 200 {
“status”: “success”,
“message”: “Task executed successfully”
}
HTTP Request: GET http://localhost:8000/read?path=/data/ticket-sales-gold.txt “HTTP/1.1 200 OK”
 A10 PASSED
 Score: 9 / 10 proof
EDIT CREDIT CARD NUMBERS are 16 digits, so even there is discrepancy
usage’: {‘prompt_tokens’: 1384,
‘completion_tokens’: 67,
‘total_tokens’: 1451,
‘prompt_tokens_details’: {‘cached_tokens’: 0, ‘audio_tokens’: 0},
‘completion_tokens_details’: {‘reasoning_tokens’: 0, ‘audio_tokens’: 0, ‘accepted_prediction_tokens’: 0, ‘rejected_prediction_tokens’: 0}},
‘service_tier’: ‘default’, ‘system_fingerprint’: ‘fp_13eed4fce1’,
‘monthlyCost’: 0.5243745800000005,
‘cost’: 0.004554000000000001
GPT-4o mini
Fine-tuning price
Input:--------------------------&gt; CALCUATION: (1384/10^6)*$0.30 = 0.0004152
$0.30 / 1M tokens
Cached input:
$0.15 / 1M tokens
Output:-------------------------&gt;  CALCUATION: (67/10^6)$1.20 = 0.0000804
$1.20 / 1M tokens
Training:
$3.00 / 1M tokens
TOTAL = 0.0004152 + 0.0000804 = 0.0004956
‘cost’: 0.004554000000000001 MAKE IT MAKE SENSE?
‘total_tokens’: 1451, so only input and completion tokens used?




INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:root:10
INFO:root:Inside run_task with task:
Install uv (if required) and run the script https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py
with 23f1002382@ds.study.iitm.ac.in as the only argument
INFO:root:PRINTING RESPONSE:::PRINTING RESPONSE:::PRINTING RESPONSE:::
{‘id’: ‘chatcmpl-B0pChhrBiCN8x8ueL2u57rwQiucl7’, ‘object’: ‘chat.completion’, ‘created’: 1739536527, ‘model’: ‘gpt-4o-mini-2024-07-18’, ‘choices’: [{‘index’: 0, ‘message’: {‘role’: ‘assistant’, ‘content’: None, ‘tool_calls’: [{‘id’: ‘call_ULCgfFzpEcnGNditwVwGwRIS’, ‘type’: ‘function’, ‘function’: {‘name’: ‘install_and_run_script’, ‘arguments’: ‘{“package”:“uv”,“args”:[“23f1002382@ds.study.iitm.ac.in”],“script_url”:“https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py”}’}}], ‘refusal’: None}, ‘logprobs’: None, ‘finish_reason’: ‘tool_calls’}], ‘usage’: {‘prompt_tokens’: 1384, ‘completion_tokens’: 67, ‘total_tokens’: 1451, ‘prompt_tokens_details’: {‘cached_tokens’: 0, ‘audio_tokens’: 0}, ‘completion_tokens_details’: {‘reasoning_tokens’: 0, ‘audio_tokens’: 0, ‘accepted_prediction_tokens’: 0, ‘rejected_prediction_tokens’: 0}}, ‘service_tier’: ‘default’, ‘system_fingerprint’: ‘fp_13eed4fce1’, ‘monthlyCost’: 0.5243745800000005, ‘cost’: 0.004554000000000001, ‘monthlyRequests’: 217}
@s.anand  How is the usage calculated? Just asking not implying
UPDATE:  ITS EVEN MORE CHEAPER, I gave benefir of doubt better its much cheaper? ???
Here\'s a detailed description of the image:\n\n**Overall:**\n\nThe image is a screenshot of the OpenAI pricing page for two of their GPT-4 models: GPT-4o and GPT-4o mini. The page has a dark background with white text and bordered sections.\n\n**Key elements and details:**\n\n* **GPT-4o section:**\n * Title: "GPT-4o"\n * Subtitle: "High-intelligence model for complex tasks | 128k context length"\n * Price:\n * Input: $2.50 / 1M tokens\n * Cached input: $1.25 / 1M tokens\n * Output: $10.00 / 1M tokens\n* **GPT-4o mini section:**\n * Title: "GPT-4o mini"\n * Subtitle: "Affordable small model for fast, everyday tasks | 128k context length"\n * Price:\n * Input: $0.150 / 1M tokens\n * Cached input: $0.075 / 1M tokens\n * Output: $0.600 / 1M tokens\n* **Website elements:**\n * The URL "openai.com/api/pricing" is visible at the top.\n * There is a "Log in" button in the upper right corner.\n * The left side of the screen contains a navigation bar with options for "on" and "rum".\n * There is a chatbot prompt, "Ask ChatGPT" on the bottom of the page.\n\n**Color scheme:** The dominant colors are dark shades of gray and white.\n\n**Overall impression:** The image conveys information about the pricing structure of OpenAI\'s GPT-4o and GPT-4o mini models, specifically detailing the costs per 1 million tokens for input, cached input, and output.Screenshot 2025-02-14 1838441695×879 52 KB
You can continue to $2. Then you would need to ask for a new token.
@carlton @Jivraj please upload recording of TDS Week 5 - Session 2. Only recordings of session 1 &amp; 3 have been uploaded.


github.com



Here\'s a detailed description of the image:\n\n* **Overall Impression:** The image appears to be a screenshot from a software repository platform, likely GitHub. It showcases a project named "ANdleCOO/TDS-Project-1."\n* **Project Name:** "ANdleCOO/TDS-Project-1" is prominently displayed in large, bold, black font on the left side.\n* **Repository Icon:** There is a square icon with a green and white pixelated tree design in the upper right corner.\n* **Metrics:** Beneath the project name are statistics:\n * **2 Contributors:** Represented by a person icon.\n * **0 Issues:** Shown with an issue icon.\n * **1 Star:** Marked by a star icon.\n * **0 Forks:** Depicted with a fork icon.\n* **Platform Logo:** The GitHub logo (Octocat) is visible in the bottom right corner.\n* **Color Scheme:** The background is a very light gray/white. The text and metrics use dark colors (black) for contrast.\n* **Horizontal Bar:** There is a dark blue horizontal bar at the very bottom of the image.\n\n\n\nIn essence, the image is a visual summary of a GitHub project, detailing its contributors, issues, stars, and forks.
GitHub - ANdIeCOOl/TDS-Project-1
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.






DONE WITH A TASK , you have to create DOCKER IMAGE THOUGH &lt; HAVE ENV file with keys , check the key value pair names, an cheers guy , we all get 9 marks hopefully
For as task description like this

Write the # of Thursdays in /data/extracts.txt into /data/extracts-count.txt

I have given the prompt in such detail to the LLM but it is still not able to understand the task because of the “#” symbol. The task is getting truncated even before it reaches to the LLM.
Can anyone help me on this because I have tried so many things to fix this but nothing seems to help.
Hi @Jivraj, @carlton sir,
I have created a docker file and run the application but it’s throwing error for
A2 task
No such file or directory: ‘npx’
Do i need give the node install in docker file?
Hash is just another way of writing “number”
@carlton @Jivraj
sir i have tried to solve the A1. when I want to check the solution we are asked for the datagen module as the evaluate.py have
’
''from datagen import (
    get_markdown,
    get_dates,
    get_contacts,
    get_logs,
    get_docs,
    get_email,
    get_credit_card,
    get_comments,
    get_tickets,
)
'''

so do we need to download the datagen.py in the local system first…
Or it should be the part of the automation only…
I am getting internal server error for task A1, I have been trying for a long time. It may be possible that i have issues with my ai_proxy token thus tell how to properly set the taken.
Yes I know that but LLM does not know that # indicates number. And no prompt is fixing this issue because the task has to be passed as query parameter and by the time LLM reads the task, it is already half gone due to #.
Where to find AIProxy token from?
what if we are out of token sir how do we complete our project then?
could u share your code once i think you should explicitly try to install npx in your code



 23f1002382:

ANDIECOOLER2


could you help me out with q2?
Can you tell me where to get the AIPROXY Token from and also are u able to execute docker image push command it keeps showing as an error to me
def format_with_prettier(file_path:str, prettier_version:str):
    if file_path and os.path.exists(file_path):
        print('Path exisit - will perform prettier')
        subprocess.run(["npx", f"prettier@{prettier_version}", "--write", file_path])
    else:
        raise FileNotFoundError()

This is my code
this isnt also working are you sure its right?
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image shows a code editor (likely VS Code) displaying Python code alongside a terminal output demonstrating a Markdown formatting process.\n\n**Code Section (Top):**\n\n* **File:** `main.py`\n* **Function:** `handle_task_A2` which accepts file path and prettier version as input.\n* **Logic:** The function checks for the existence of a file at the given path using `os.path.exists()`. If it exists, a message is printed, and a subprocess call to `npx` with arguments for `prettier` and writing to the specified `file_path` is executed. If the file doesn\'t exist, a `FileNotFoundError` is raised.\n\n**Terminal Output (Bottom):**\n\n* **Input File:** `/data/format.md`\n* **Expected Output:** The terminal displays the original Markdown content, labeled as "EXPECTED:". This Markdown includes a heading, a paragraph with intentional extra spaces and trailing whitespace, and a list of items (both ordered and unordered).\n* **Result:** The terminal shows the "RESULT:" of the markdown formatting. There\'s no change, indicating that the prettier formatting has not affected the markdown file.\n* **Command:** A `.py` file is being printed using `print("user@example.com")`.\n\n**Color Scheme:** The code editor has a dark theme with syntax highlighting. The terminal output uses standard console colors (e.g., red for errors/warnings, green for success).image1027×917 28.1 KB
okay but in my docker image when i tried to run that in local, its asking for npx and it doesnt work
@carlton could you please give a hint as to why this isnt working
im running locally first and then will use docker when i get a 10/10 score
Okay, actually when i tried with local, i’m facing path error
./data/format.md
[WinError 2] The system cannot find the file specified

So that’s why i moved to docker but there also i’m getting error for A2.
you should manually check if the file really exists or not because i think the code and the folder where datagen.py is downloading files(data folder) are different
yes yes i moved the folder to current working directory
If you are using the function calling approach, you could just parse the ‘#’ and change it to ‘number’ and then send the prompt to the llm for that particular task.
Or another approach is tell the llm,
If you ever see the phrase ‘count the # of’ in a task, please interpret it as ‘count the number of’. For example
Count the # of Fridays means
Count the number of Fridays
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image shows a screenshot of a code editor (likely Visual Studio Code) displaying a Python script with associated terminal output. The script appears to be designed to download and execute another Python file from a remote URL.\n\n**Detailed Breakdown:**\n\n1. **Code Editor Interface:**\n * The left sidebar shows a file explorer with a project structure. Key folders/files visible include:\n * `.env`\n * `lm.py`\n * `app.py`\n * `dockerfile`\n * `retlab`\n * The main window displays a Python script named `lm.py`.\n\n2. **Python Script (`lm.py`) Content:**\n * The script includes comments explaining its purpose: downloading and running a Python script from a URL.\n * It imports the `subprocess` module to execute commands.\n * The script defines a URL (`script_url`) pointing to a Python file on `raw.githubusercontent.com`. This URL specifically targets a file named `study.llm.ac.py`.\n * The script then attempts to download the file using `wget` and prepares it for execution with the argument "0".\n * Finally, it uses `subprocess.run` to execute the downloaded Python script with the provided argument.\n\n3. **Terminal Output:**\n * The terminal window at the bottom shows the output of running the script.\n * The output indicates that the script successfully downloaded the file `study.llm.ac.py`.\n * The output also shows the results from running the `study.llm.ac.py` script. There is a long line with numerous numeric values.\n\n**In summary:** The image depicts a Python script that automates the process of downloading a remote Python script and then running it with a specific argument. The terminal output shows evidence of the script completing its task successfully.Screenshot 2025-02-14 2018541919×1015 81.4 KB
@carlton @Jivraj this is showing while docker image is running
in project page, ctrl+F and search ai proxy, one link s.anandProxy or something, there it will validate you email and get you your token.
can you share your code for dynamic code generation, i dont have the base to start with , can you send me the code?
whatever this image is , llm_code,oy and etc
What file should we have while pushing it to git and making image
should datagen file and data be there or not?
Please read the deliverables and evalute section.
datagen.py and evaluate.py were for only for your testing purposes so that you have an idea of the workflow and how the evaluation works. They are NOT part of your project submission.
Only DO what the project page tells you in the deliverables and evalute sections.
Kind regards
sir i am getting this error by running the docker image
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a Python traceback error message in a command-line interface (CLI). The background is black with white text. \n\n**Specific Details:**\n\n* **Traceback Header:** The message begins with "Traceback (most recent call last):", indicating an error occurred during program execution.\n* **File and Line Number:** "File \\"/app/app.py\\", line 11, in " shows the error originates from the file `/app/app.py` on line 11.\n* **Import Statement:** "from fastapi import FastAPI" indicates that the code attempts to import the `FastAPI` class from the `fastapi` module.\n* **Error Message:** "ModuleNotFoundError: No module named \'fastapi\'" is the core error, indicating that the `fastapi` module is not installed or not found in the Python environment.\n\n**In essence, the image captures a Python error where the code tries to use the FastAPI framework, but the framework is not properly installed or accessible.**image656×116 3.28 KB
i tried troubleshooting this for hours but no luck could you please tell me what i did wrong here
i can help you up, if you need my help you can email me
@s.anand Sir please tell me this I am not using podman i am using docker for building and hosting is it fine sir ?
Hey @carlton @Jivraj , I actually submitted the project already in the morning,
I included all the deliverables and things mentioned in the evaluation section.
But since I was actively testing with the - datagen.py and evaluate.py, I forgot to remove them before submission.
However these files do not play a role in my project execution in any way, they just sit idle. Will there be any issue?
when trying to use function call way of open api
tools = [
    {
        "type": "function",
        "function": {
            "name": "extract_email_sender",
            "description": "Extract sender email from a specific file in directory",
            "parameters": {},
            "strict": True
        }
    },
    {
        "type": "function",
        "function": {
            "name": "count_day_of_week",
            "description": "To count the occurances of a specific day of a week in a file with various dates",
            "parameters": {
                "type": "object",
                "properties": {
                    "day_of_week": {
                        "type": "string",
                        "description": "day of week"
                    }
                },
                "required": ["day_of_week"],
                "additionalProperties": False
            },
            "strict": True
        }
    }
]

    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "user", "content": user_input},
                
        ],      
	"tools": tools,
    "tool_choice": "auto",
    "max_tokens": 500,
    "temperature": 0.7
    }

facing the below issue
ror’: {‘message’: “Invalid type for ‘tools[0]’: expected an object, but got an array instead.”
when i run POST request t is showing output “HTTP/1.1 200 OK” but when i give GET request it is showing HTTP/1.1" 404 Not Found. Can you please say how can it be solved
These files are inside a separate folder - evaluation in my project root directory. Since I already submitted please do consider.
Thanks &amp; Regards
Pradeep
This indicates your task execution returns  “HTTP/1.1 200 OK” but the execution doesn’t creates the required file in the given location that the evaluation script is requesting.
If have doubts in building DOCKER stuff can you help me debug
PLEASE SENPAI

sure!! how can I help?
+1
SENPAI is right 
not yet maybe in an hour, im building, but after that running in docker is different ball game, thats why , i need quick debugs in a meeting, other people also can join, maybe tomorrow, i have an exam tomorrow, so preferably , collectively before project submission . IF YOU HAVE TIME



 23f1002382:


Sure tell me I would try, if I am online then otherwise tomorrow if it’s late
I am getting this error while pulling docker image
ansh@Lenovo:~/llm_project$ podman pull docker.io/ansh205/llm_project:final
Trying to pull docker.io/ansh205/llm_project:final…
Error: parsing image configuration: Get “https://docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com/registry-v2/docker/registry/v2/blobs/sha256/07/079f65bc553514a8f38a08fd959e932ca984894a64eed71fca406f3353b71d3b/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=f1baa2dd9b876aeb89efebbfc9e5d5f4%2F20250214%2Fauto%2Fs3%2Faws4_request&amp;X-Amz-Date=20250214T172706Z&amp;X-Amz-Expires=1200&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=073575bf08338fcdda378b997ebe749b15a6b676ed7b80fbf4c3f8080a791152”: dial tcp: lookup docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com on 10.255.255.254:53: server misbehavingPreformatted text
@carlton @Jivraj @s.anand @Saransh_Saini
sir please provide me other api key. My current request cost is full.
Full LLM Response: {‘message’: ‘On 2025-02 you used $2.000143640000001, exceeding $2’}
 curl -X POST http://localhost:8001/run?task=Extract%20sender%20email
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    36  100    36    0     0      9      0  0:00:04  0:00:03  0:00:01     9{"results":"wrighttara@example.net"}

is this expectation of having %20 for blanks in query string fine ?
docker run -e OPEN_AI_PROXY_TOKEN=your_token_value 
-e OPEN_AI_PROXY_URL=your_proxy_url 
-e OPEN_AI_EMBEDDING_URL=your_embedding_url 
-p 8000:8000
how do we get out urls inside, hardcode?
Can you help with docker size image?
is it 2 GB?
I want to reset my aiproxys i have used them all if i could even buy some would work i need it to test my app or could iitm help in resetting it please tell
could u help me in q9 thats the one left
@carlton my aiproxy is also exhausted please help me out
sir my api tokens limit reached to one dollar , hiw to reset it
bro can you help me with q2
How to handle task a8 ? I tried pytesseract but gave wrong results.EasyOCR is giving the exact answer so tried in docker but some Model download is interrupting the flow of evaluate.py resulting in error .
I appreciate any help/procedure or code to handle taska8.
Thanks in advance.
Did you get any solution to this
u can use groq api groq api is compatible with openai
whats up?
/////////////////////
bro can please check my repo i am only able to do 7 tasks.
repo url: GitHub - 23f2005593/tds-project-1: TDS Project 1
got the docker working?
@carlton @Jeeveash.k
sir i submitted the wrong docker image file while submitted the form. Can you please let me change it, or make it such that we can reupload it
thank you.
22f3001011 I’ve enabled “Allow response editing” on the form. I think that means you can edit your response… but since you had submitted it before it was enabled, I’m not sure what the procedure is. Worst case, please submit again.
Please make this change in evaluation.py
In evaluation script url of datagen.py is different than actual one please change it
evaluation.py line 72
Install uv (if required) and run the script https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py
change this to
Install uv (if required) and run the script https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py
very true there is too much confusion Id like to ask if you know that evaluate.py is mean to run only for user@example.com or our own mail too  because there was written You MUST use your Student Id (eg. 22f3xxxxxx@ds.study.iitm.ac.in) to do the Project, otherwise your score will not be considered for evaluation.
Hi any one have any idea on the below,
SyntaxError: illegal target for annotation

I’m getting this error only when i run the evaluate.py but in with postman it works as expected.
Anyone please help on this
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a screenshot of the Visual Studio Code (VS Code) Integrated Development Environment (IDE). It shows a Python script ("datagen.py") open in the editor, alongside a terminal window displaying the output of the script\'s execution.\n\n**Key Elements & Details:**\n\n1. **VS Code Interface:** The top portion shows the typical VS Code layout:\n * **Activity Bar:** On the left, with icons for Explorer, Search, Source Control, Run, and Extensions.\n * **Editor Window:** Displays the contents of the "datagen.py" file.\n * **File Explorer:** Lists the files and folders within the project. Files/folders visible include: ".env", "app.py", "web", "datagen.py", "Dockerfile", and "README".\n * **Menu Bar:** At the very top, containing standard menu options (File, Edit, Selection, View, Go, Run, Terminal).\n\n2. **"datagen.py" Code Snippet:** The open Python file ("datagen.py") appears to contain code related to data generation. Key lines are visible including:\n * `import os` and `import subprocess`\n * Comments indicating the script receives a URL as an argument.\n * Code that downloads a script from the provided URL using the `subprocess` module.\n * Execution of the downloaded script.\n\n3. **Terminal Output:** The lower portion of the image displays the output from the terminal. It\'s a long, scrolling stream of text representing the script\'s execution process.\n * The output indicates a web server process is started.\n * It shows the successful creation of a directory ("data/datasets").\n * It prints the total number of files received (3 files), indicating the script likely downloaded data.\n * There are numerous lines detailing the process of receiving and processing data, including file names and sizes.\n\n4. **File Paths:** The file paths visible in the terminal indicate the script is operating within a directory structure including "app", "data", and "data/datasets".\n\n**In essence, the image captures a developer working on a Python script that downloads a resource from a URL, processes it, and saves the output (likely data files) to a specified directory.**Screenshot 2025-02-15 0719101919×1021 71.3 KB
sir why the datagen.py in not created in the tree and the data folder please help me @s.anand @Jivraj @carlton
created in toot, cd /data in docker will take you there.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a code editor interface, specifically Visual Studio Code (VS Code), open with a `Dockerfile` and terminal output visible. The theme appears to be dark mode.\n\n**Key Elements & Details:**\n\n1. **VS Code Interface:** The screenshot shows the core components of VS Code including the:\n * **Activity Bar:** On the far left, with icons for various functionalities like Explorer, Search, Source Control, Run & Debug, etc.\n * **Explorer Panel:** Displaying a file/folder structure (likely a project directory). We can see folders like `.env`, `app`, `data`, and files like `requirements.txt` and `Dockerfile`.\n * **Editor Panel:** The central area with the `Dockerfile` currently open and highlighted. The Dockerfile contains instructions for building a Docker image, starting with `FROM python:3.11-slim-bookworm`.\n * **Output/Terminal Panel:** At the bottom, showing terminal output from a running process (presumably building or running the Docker container).\n\n2. **Dockerfile Content:** The Dockerfile is visible with commands like:\n * `FROM` specifying a base image (Python 3.11).\n * `RUN` executing shell commands (updating the package list, downloading, and running an installer).\n * `WORKDIR` setting the working directory.\n * `COPY` copying files into the image.\n * `RUN pip install` installing Python packages from `requirements.txt`.\n * `CMD` specifying the command to run when the container starts.\n\n3. **Terminal Output:** The terminal output shows:\n * A process starting a server ("Started server process").\n * Application configuration/status details.\n * A message indicating successful completion ("Application completed").\n * Some verbose logging information about components/arguments and memory usage.\n\n4. **Overall context**: The image likely depicts a developer working on a Python application that is being containerized using Docker. The developer has a project open in VS Code, and is actively building and/or running the application using Docker.\n\n\n\nIn essence, it\'s a snapshot of a software development workflow using VS Code, Docker, and Python.Screenshot 2025-02-15 0758431919×1017 70.9 KB
is changes is required in Dockerfile
i too got the same error you can change the the tools part in your payload to
"tools": [{"type": "function", "function": schema} for schema in function_schema]

i think you have to run the following command
uv run datagen.py &lt;your_email&gt; --root ./data

try to include --root ./data in your code
sorry i forgot the change the name of function_schema to tools please you do that
@carlton @Jivraj
Hello,
just a silly question, if my code runs well in docker environment with /data in root directory, will it be fine ?
or should i keep the relative ./data directory like in the lecture ?
Thanks
The reason in the lecture they were using ./data was because they were debugging in their local machine not in the docker.
For the docker image (the official submission) you must use /data.
It is a clear requirement mentioned in the project page.
Thats why it works fine when you use it in the docker image.
Kind regards
Here\'s a detailed description of the image:\n\n**Overall:** The image is a screenshot of a form or interface, likely part of a web application or setup process. It contains two input fields with accompanying instructions and validation messages.\n\n**Top Section:**\n* **Question:** "What is the link to your GitHub repository which has the code for Project 12?"\n* **Instruction:** "It should look like https://github.com/user-name/repository-name"\n* **Input Field:** The field contains the text "https://github.com/Atimanas-Biswal421/proj1"\n\n**Bottom Section:**\n* **Question:** "What is the name of the image published on DockerHub?"\n* **Instruction:** "It should look like user-name/image-name"\n* **Input Field:** The field contains the text "atimanasbiswal/proj1-tds.final"\n* **Validation Message:** A red error icon and text "Must match pattern" appear next to the input field, indicating the entered value does not conform to the expected format.\n\n**Color Scheme:** The interface uses a light background with peach/orange accents for headers and borders. Red is used to indicate errors.\n\n**Overall Impression:** The image captures a form requiring specific input from the user, with a focus on GitHub and DockerHub integration. The error message suggests a formatting issue with the DockerHub image name.Screenshot 2025-02-15 101818858×521 24.4 KB
@Jivraj @carlton
hello sir i need help here. I have pushed my image into a docker repo and trying to submit it on ht google form. but it is not accepting it and asking to remove the tag .
What do i do ?
Alright sir.  Thank you very much for your help.
Are multiple submissions allowed for project?
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image shows a computer screen displaying a code editor interface (likely VS Code) along with an error message. The editor is open to a directory structure showing Python files and text files. A bluish image appears within the editor, seemingly a visualization of a credit card, with some numerical data overlaid.\n\n**Detailed Breakdown:**\n\n* **Code Editor:** The interface shows a directory structure on the left, listing files like `comments.txt`, `contacts-sorted.json`, `contacts.json`, `credit-card.png`, `email-sender.txt`, and various Python files (task1.py through task10.py, and others like `datagen.py`, `evaluate.py`, etc.).\n* **Image Visualization:** The main part of the editor displays a predominantly blue image that resembles a credit card. A string of numbers (990652220367260) is overlaid on the image.\n* **Error Messages:** At the bottom, there are several error messages displayed in red:\n * "/data/credit-card.txt" - `AI FAILED`\n * An HTTP Request error pointing to `https://alproxy.second.workers.dev`\n * Another `AI FAILED` message.\n* **Interface Elements:** At the very bottom is a search bar. Along the bottom edge are tabs labeled "PROBLEMS," "OUTPUT," "DEBUG CONSOLE," "TERMINAL," and "PYTHON". \n\n**In summary:** The image depicts a coding environment where a script is attempting to process an image of a credit card. The AI model used for processing is failing, resulting in error messages. It appears to be an analysis related to a credit card image.A8720×1280 85.1 KB
@carlton @Jivraj
please check this one…
Hi @carlton @Jivraj  sir,
For A2 do i need to install node in the docker? I’m getting error with npx.
please suggest some way sir?
if i have two repo on docker , is there any problem in that
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a response from a server, likely a web API. It appears to be an error message.\n\n**Key Elements:**\n\n* **Status Code:** The top line indicates a "500 Internal Server Error".\n* **Size and Time:** The response size is 184 Bytes and the request took 792 milliseconds.\n* **Tabs:** There are tabs labeled “Response”, “Headers”, “Cookies”, “Results”, and "Docs". The "Response" tab is currently selected.\n* **JSON Response:** The main part of the image displays a JSON (JavaScript Object Notation) formatted error message.\n * **"detail"**: Contains a message indicating an error with the code 401, with the message "Your authentication token is not from a valid issuer."\n * **"error"**: Nested within "detail", it specifies the type of error as "invalid\\_request\\_error," with no parameter and code "invalid\\_issuer."\n\n**Color Scheme:** The image has a dark background with green text for the status information and white text for the JSON response.\n\n**In summary:** The image displays a server error message, specifically an authentication issue where the provided token is not from a recognized or valid issuer.image684×316 12.7 KB
why do i get this error? can someone please help me out @Jivraj @carlton…Anyone pls help
can u please share the base proxy url
I’m also getting the same error. I have used a proxy URL and token. Before, it was working, but now it’s not.
sir or anyone can you please provide what should be the content inside the docker file … i am getting confuse like /data or python-slim etc
… i am done with locally testing and only this thing left.
yes please explain somebody. What should be inside the dockerfile
Hi ,
Anyone completed Task B, I don’t know how to combine task A (function calling) and task B (self creating python code)
can anyone suggest how to do that? It will be really helpful
“http://aiproxy.sanand.workers.dev/openai/v1” use this as proxy URL. its working for me now!
How to resolve this?
sarvan108@SURIYA:/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro$ uv run app.py
Traceback (most recent call last):
File “/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro/app.py”, line 10, in 
from fastapi import FastAPI
ModuleNotFoundError: No module named ‘fastapi’
sarvan108@SURIYA:/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro$ pip show fastapi
WARNING: Package(s) not found: fastapi
sarvan108@SURIYA:/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro$ pip install fastapi
error: externally-managed-environment
× This environment is externally managed
╰─&gt; To install Python packages system-wide, try apt install
python3-xyz, where xyz is the package you are trying to
install.
If you wish to install a non-Debian-packaged Python package,
create a virtual environment using python3 -m venv path/to/venv.
Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make
sure you have python3-full installed.

If you wish to install a non-Debian packaged Python application,
it may be easiest to use pipx install xyz, which will manage a
virtual environment for you. Make sure you have pipx installed.

See /usr/share/doc/python3.12/README.venv for more information.

note: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.
hint: See PEP 668 for the detailed specification.
sir,
It is a humble requests from my side, to plz extend the deadline.
Because student like who come from non technical background, are unable to come up with this project…
though we have somehow comeup with the GAs taking the helps of groups, seniors and sessions.
Moreover I am Dual Degree student. It is very hectic for me.
Sir you won’t believe but I am continuously trying since last week. Specially after the release of the sessions… Whole day and night have gone like nothing, infront of the computer…
Plz sir understand the situation and extend the deadline…



 23f2003413:

http://aiproxy.sanand.workers.dev/openai/v1


For me it says invalid path
Here\'s a detailed description of the image:\n\n* **Content:** The image displays a text snippet resembling a JSON object.\n* **Text:** The text reads: `"message": "On 2025-02 you used $2,0037491399999996, exceeding $2"`\n* **Format:** The text is formatted as a key-value pair within curly braces, indicating a JSON structure. The key is "message" and the value is the textual statement.\n* **Context:** The message appears to be a notification related to usage or spending. It indicates that $2,0037491399999996 was used on February 2025, which exceeded a $2 limit.\n* **Background:** The background is a pale grey.
@carlton @Jivraj
same issue happening with me even though working for last whole week only got 4 correct . please extend some time so we can complete the project as weekends are the time when we get a day off from our primary college and can work with full attention on this project.
it usually happens in some GNU/Linux OS. since you are using some distribution based on Debian namely Ubuntu or whatever try doing sudo apt install python-packagename (replace package name with fastapi for fastapi)
then it works. It usually happens due to manual intervention with pip3 the user might break some system dependencies which require some python3 package. No need to worry about it.
Another Fix: try using a virtual environment which is highly suggested since there is no chance for you to interfere with the system packages.
create a venv using python3 -m venv name_of_venv
add this line to your .bashrc in ~ folder as source /path/to/your/venv/location
and run source .bashrc. This time no error occurs as you do everything in your virtual environment you can install anything python3 package using pip3 install package name.
It even happened for me
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a terminal or command-line interface with a series of text-based outputs. It appears to be a user attempting to install the NumPy package in a Python environment.\n\n**Key Details:**\n\n1. **Initial Error:** The initial lines indicate an error message: "This environment is externally managed." This suggests that the user is trying to install a Python package within a system where the Python environment is pre-configured or managed by another system (like a package manager).\n2. **Instructions:** Following the error, there are instructions directing the user to use a package manager like \'pacman\' if they wish to install packages system-wide, or to create a virtual environment using \'python -m venv\' for isolated package management.\n3. **Virtual Environment Activation:** The prompt "jafreeparcilaux > source /home/jafreep/python3/venv/activate" shows that the user attempted to activate a virtual environment located at `/home/jafreep/python3/venv/`.\n4. **Successful Installation:** Following the activation, the command "pip install numpy" was executed, and the output "Requirement already satisfied: numpy in /usr/lib/python3.11/site-packages (1.23.2)" indicates that the NumPy package was already installed in the system’s or the virtual environment’s site-packages directory (version 1.23.2).\n5. **Prompt:** The final line shows the prompt "jafreeparcilaux >", indicating the user is ready to execute another command.\n\n**In essence, the image documents a user\'s attempt to install the NumPy package, encountering an initial message about an externally managed environment, then successfully finding that the package is already installed.**Screenshot_20250215_1433573841×1009 237 KB
Most of your questions and doubts will be solved in todays sessions. First 20 mins will be a clear overview of the logic and workflow and how evaluation actually works.
Rest of the session will be bug fixing and doubts.
Kind regards
 EXPECTED:
Everybody significant bank herself them process build body. Price live size. Assume begin better language east like machine.
New customer green strategy.
Feeling stock experience certainly history talk buy. Quality perform appear human general religious feeling. Kid indicate fear word win carry.
During professional sport growth citizen glass great student. Exactly receive cause. Couple off current between role natural.
Wind develop world next. Impact appear capital cold stock we. Quality get run case huge that.
Use century general above more region. Radio him quality stage. Truth least military dinner growth.
Study maybe source. For expect imagine.
Analysis remain voice dog sit part. Safe them store spring life girl.
House bring challenge. Tell but rock able great.
Mouth president worker common Mr billion.
 RESULT:
“Everybody significant bank herself them process build body. Price live size. Assume begin better language east like machine.\nNew customer green strategy.\nFeeling stock experience certainly history talk buy. Quality perform appear human general religious feeling. Kid indicate fear word win carry.\nDuring professional sport growth citizen glass great student. Exactly receive cause. Couple off current between role natural.\nWind develop world next. Impact appear capital cold stock we. Quality get run case huge that.\nUse century general above more region. Radio him quality stage. Truth least military dinner growth.\nStudy maybe source. For expect imagine.\nAnalysis remain voice dog sit part. Safe them store spring life girl.\nHouse bring challenge. Tell but rock able great.\nMouth president worker common Mr billion.”
it is the error i am facing but when i am opening manually, i am not getting any error, what should I do?
this same issue is with 3-4 questions
when will the session be conducted and how can we join it sir?
Hi Thanks.
Yes. it works when venv is created. But I see that it was working find in Week 5-Session 1 video without creating virtual environment.
I will not submit project.
Get authentication token from this AI Proxy and usage and follow documentation for sending requests.
sanand0/aiproxy: Authorizing proxy for LLMs
No Problems, just fill form with correct image name in google forms.
yes npx will require node to be installed.
@Jivraj when would today’s live session be conducted and how can we attend it sir
evaluate.py is not working sir.
What if you run out of credits during or just before final evaluation?
This is only for testing on local machine.
In docker image keep /data.
One session is going live right now (from 3 to 5 pm).
It will be visible from calendra.
sir,
It is a humble requests from my side, to plz extend the deadline.
Because student like who come from non technical background, are unable to come up with this project…
though we have somehow comeup with the GAs taking the helps of groups, seniors and sessions.
Moreover I am Dual Degree student. It is very hectic for me.
Sir you won’t believe but I am continuously trying since last week. Specially after the release of the sessions… Whole day and night have gone like nothing, infront of the computer…
Plz sir understand the situation and extend the deadline…
Sir, I have put my AIPROXY_TOKEN in .env file should I need to push the .env file also in the github
yes sir do we have to put env file also @carlton sir @Jivraj sir
In the evaluation.py there is an import require named from datagen import some stuff.
which means inorder to run the evaluation.py we need to manually bring the datagen.py in the working directory…
Because in order to run the evaluation.py we need the datagen. plz help…
can someone send the meet link for the live session happening now
Everytime I run datagen.py for the A1 task, the data file gets downloaded in the C drive instead of the current project folder. I even tried to set the current project folder as the root directory but it still downloads the files in C drive and I cant seem to find a workaround this. Can someone please help with this issue. Thanks!
Can you please make the changes in the datagen.py file
config = {“root”: “/data”}
This is where I have been facing the issue.
The only solution I can think of is moving the /data folder from the root to the project directory. which I am not sure is a good way to solve this issue.


Here\'s a detailed description of the image:\n\n* **Overall Impression:** The image features a simple, minimalist design with a central orange circle against a completely black background.\n* **Central Element:** Within the orange circle is a white letter "T". The letter is centered and appears to be a sans-serif font.\n* **Color Scheme:** The image uses a high-contrast color scheme - bright orange and white against black.\n* **Branding:** A "Google Meet" logo is visible in the top right corner, suggesting the image is related to or a part of a Google Meet video call interface.\n* **Text:** "TELVIN VARGHESE" is written in white at the bottom of the screen. This is likely the name of the user.


@carlton
please tell do we have to put this url in a variable for A1 task ?
https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py
Task A9 fails.

HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings “HTTP/1.1 401 Unauthorized”
 A9 failed: ‘data’
 A9 FAILED

If I run
curl -X POST http://aiproxy.sanand.workers.dev/openai/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer $AIPROXY_TOKEN" -d '{"model": "text-embedding-3-small", "input": ["king", "queen"]}'

I get
{
  "message": "Missing Authorization: Bearer header. See https://github.com/sanand0/aiproxy"
}

@carlton @Jivraj @s.anand
@carlton sir @Jivraj sir  do i have to put env file in docker
you have to give the AIPROXY_TOKEN to the evaluate.py by either
bash - export AIPROXY_TOKEN="your token"
or
powershell - $env:AIPROXY_TOKEN="your token"
the evaluate.py file takes the token to send request to embedding end point for processing.
so you have to set AIPROXY_TOKEN in both terminals
i.e. app.py and evaluate.py teminals
when I run the evaluation file, i get the following error -  Running task: Install uv (if required) and run the script https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py with user@example.com as the only argument  A1 failed: All connection attempts failed  A1 FAILED
I am getting the following error when running the evaluation scripts, can someone help me understand what this error is?
Humble request to extend the deadline please. Finding it extremely difficult and having time atleast till Sunday will be really helpful for working professionals like me
All my tasks are running except A9. I have created a .env file and added my token. Despite that I ran commands in both the terminals. A9 still fails.
I second this, have been trying to debug the project for the past 1 week, spending over 4 hours daily and yet facing issues everytime I reopen. An extension of even 24 hours would be extremely appreciated. Please consider this. Thanks.
same issue on my side as well
how u did A2
could u please share ?
@s.anand @jivraj @carlton
AIPROXY_TOKEN=$AIPROXY_TOKEN
what abt m url stuff?
Sir, I request you to Please  extend the deadline, Because it is time consuming  and regular Students and Working professionals  have only saturday and sunday to complete this project.
Thanks
also, in evaluate.py file, the embedding url is wrong and the AIPROXY_TOKEN is changed to OPENAI_API_TOKEN or something. i could send you edited evaluate.py… check your messages on discourse
On bash it gives below output. On PowerShell it says missing authorization. A9 is failed.
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a terminal or command-line interface with a series of text-based outputs. It appears to be the result of a command executed to retrieve an embedding for the words "king" and "queen" from an OpenAI API.\n\n**Key Elements & Details:**\n\n1. **Terminal Prompt:** The top line indicates the user is "Nelson" and working on a project called "1-LLM."\n2. **Environment Variable:** The first line within the terminal is an export command, setting an environment variable called "AIPROXY\\_TOKEN" to a long alphanumeric string. This token likely serves as authentication for accessing the API.\n3. **cURL Command:** The next line shows a cURL command used to send a POST request to an OpenAI API endpoint (`http://aiproxy.sanand.workers.dev/openai/v1/embeddings`). The command specifies:\n * A content type of "application/json".\n * A model of "text-embedding-3-small".\n * An input of a list containing the words "king" and "queen".\n4. **Transfer Statistics:** The lines below the cURL command show transfer statistics, indicating that 100% of the data has been received (63 bytes) with an average download speed of 16 bytes/second and a total transfer time of 00:00:03.\n5. **JSON Response:** The remaining portion of the screen displays a JSON (JavaScript Object Notation) response from the API. The response includes:\n * An "object" type of "list."\n * A "data" array containing a single "embedding" object.\n * An "index" value of 0.\n * A lengthy "embedding" array, which is a list of floating-point numbers representing the vector embedding of the input text "king" and "queen." Each number in the embedding represents a dimension in the vector space.\n\n**In summary,** the image shows a record of a user accessing an OpenAI API to obtain an embedding for the terms "king" and "queen" using a cURL command. The JSON response provides the numerical representation of these words in a vector space.image907×661 26.5 KB
In PowerShell
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image shows a screenshot of a PowerShell command-line interface. It depicts a `curl` command execution and its resulting JSON response.\n\n**Key Elements:**\n\n1. **PowerShell Window:** The background is a dark-themed PowerShell window, indicated by the title bar reading "PS C:\\Users\\Nelson>".\n2. **`curl` Command:** A `curl` command is displayed, used for making HTTP requests.\n * **Method:** The command uses the `POST` method.\n * **URL:** The URL being requested is `http://aiproxy.sanand.workers.dev/v1/embeddings`.\n * **Headers:** The command includes headers:\n * `Content-Type: application/json`\n * `Authorization: Bearer $AIPROXY_TOKEN`\n * **Data:** A JSON payload is being sent with the following structure:\n * `model`: "text-embedding-3-small"\n * `input`: `["king", "queen"]`\n3. **JSON Response:** The output is a JSON object with a single key-value pair:\n * `message`: "Missing Authorization: Bearer header. See https://github.com/sanand08/ai-proxy"\n4. **Command Prompt:** The command prompt "PS C:\\Users\\Nelson>" is visible at the top and bottom of the screenshot, signifying an active command-line session.\n\n**Summary:** The image displays an attempt to make an API call to an embedding service, which failed due to a missing or incorrect `Authorization` header. The response directs the user to a GitHub repository for further information.image967×292 16.5 KB
My data is getting generated -
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image shows a screenshot of a web browser displaying a JSON (JavaScript Object Notation) data structure.\n\n**Key Elements & Details:**\n\n* **JSON Data:** The central focus is a JSON object, which is a human-readable format for data interchange.\n* **"files" Array:** Within the JSON, there\'s an array named "files" containing a list of strings representing filenames. These include:\n * "comments.txt"\n * "contacts.json"\n * "credit\\_card.png"\n * "dates.txt"\n * "docs"\n * "email.txt"\n * "format.md"\n * "logs"\n * "ticket-sales-gold.txt"\n * "ticket-sales.db"\n* **"message" Key:** There is a key labeled “message” with the value “Data generation complete”.\n* **Browser Interface:** The screenshot shows elements of the web browser’s interface, including the address bar ("127.0.0.1:8000/run?task=Install%20") and a "Pretty-print" checkbox.\n* **Color Scheme:** The background is light-colored, with black text, and the overall aesthetic is typical of a code or data display.\n\n**In essence:** The image illustrates the output of a data generation process, with a list of generated files and a completion message displayed in JSON format within a web browser.image459×454 12.7 KB
despite this I am getting an error when evaluating the file with no explanation of the error. Can someone please help with this.
 Running task: Install uv (if required) and run the script https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py
with user@example.com as the only argument
 A1 failed:
 A1 FAILED
Here is a detailed description of the image:\n\n**Overall Impression:** The image depicts a code editor window displaying a Markdown file ("format.md") along with a Python code snippet. The editor has a dark theme.\n\n**Specific Details:**\n\n1. **File Structure:** The top bar shows the project structure with files: ".env", "app.py", "evaluate.py", and the currently open file "format.md".\n2. **Markdown Content:** The "format.md" file contains:\n * A level 1 heading: "#Unformatted Markdown"\n * A paragraph with extra spaces and trailing whitespace.\n * An unordered list with various formatting inconsistencies:\n * "- First item"\n * "- Second item"\n * "+Third item"\n * "* Fourth item"\n3. **Python Code:** Below the Markdown content, there\'s a short Python code snippet:\n * `print("user@example.com")`\n4. **Line Numbers:** Line numbers are visible along the left side, indicating the lines of the file.\n5. **Theme:** The code editor uses a dark color scheme, with text and syntax highlighting visible against a dark background.\n\n**In summary,** the image illustrates a file ("format.md") with unformatted Markdown content and a Python print statement within a code editor, likely for testing or demonstration purposes.image820×404 12.3 KB
Even the markdown file shows the correct email. What are the possible issues that I could be facing with this one.



github.com


GitHub - ANdIeCOOl/TDS-Project-1
main
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.





ATLEAST 6 minimum score use at own risk(MIT LICENCE xD)

BUILD TIME TAKES 2 mins
WITH DOCKER FILE
@ANdIeCOOl ➜ /workspaces/TDS-Project-1/tds-project-1 (main) $ docker build -t tds-project-1 .
[+] Building 123.9s (13/13) FINISHED                                                                       docker:default
 =&gt; [internal] load build definition from Dockerfile                                                                 0.0s
 =&gt; =&gt; transferring dockerfile: 1.18kB                                                                               0.0s
 =&gt; [internal] load metadata for docker.io/library/python:3.11-slim                                                  2.2s
 =&gt; [auth] library/python:pull token for registry-1.docker.io                                                        0.0s
 =&gt; [internal] load .dockerignore                                                                                    0.0s
 =&gt; =&gt; transferring context: 2B                                                                                      0.0s
 =&gt; [internal] load build context                                                                                    0.1s
 =&gt; =&gt; transferring context: 34.30kB                                                                                 0.0s
 =&gt; [1/7] FROM docker.io/library/python:3.11-slim@sha256:42420f737ba91d509fc60d5ed65ed0492678a90c561e1fa08786ae8ba8  8.7s
 =&gt; =&gt; resolve docker.io/library/python:3.11-slim@sha256:42420f737ba91d509fc60d5ed65ed0492678a90c561e1fa08786ae8ba8  0.0s
 =&gt; =&gt; sha256:2c2c44fb54acb184dbedee948d7ba6460b1075a60a014d66857ce46543d4d840 5.29kB / 5.29kB                       0.0s
 =&gt; =&gt; sha256:c29f5b76f736a8b555fd191c48d6581bb918bcd605a7cbcc76205dd6acff3260 28.21MB / 28.21MB                     0.7s
 =&gt; =&gt; sha256:73c4bbda278d9a2b5133d6dabfac3eec43a92b8c8c15da914f298b4c966bea53 3.51MB / 3.51MB                       0.9s
 =&gt; =&gt; sha256:acc53c3e87ac87c98e44b79e0d2a6293146650f5cba576f424dab77f8c0a4335 16.20MB / 16.20MB                     1.6s
 =&gt; =&gt; sha256:42420f737ba91d509fc60d5ed65ed0492678a90c561e1fa08786ae8ba8b52eda 9.13kB / 9.13kB                       0.0s
 =&gt; =&gt; sha256:a66bd09b8d35bb52cd106a94c23a94ba22e6fde6bd13d6c5912ec4f5888a7f14 1.75kB / 1.75kB                       0.0s
 =&gt; =&gt; extracting sha256:c29f5b76f736a8b555fd191c48d6581bb918bcd605a7cbcc76205dd6acff3260                            2.2s
 =&gt; =&gt; sha256:ad3b14759e4f8c9a73d51c897a8b96f022ec96ffc237502ad3f1f12b0b0e361f 249B / 249B                           1.9s
 =&gt; =&gt; extracting sha256:73c4bbda278d9a2b5133d6dabfac3eec43a92b8c8c15da914f298b4c966bea53                            0.2s
 =&gt; =&gt; extracting sha256:acc53c3e87ac87c98e44b79e0d2a6293146650f5cba576f424dab77f8c0a4335                            1.4s
 =&gt; =&gt; extracting sha256:ad3b14759e4f8c9a73d51c897a8b96f022ec96ffc237502ad3f1f12b0b0e361f                            0.0s
 =&gt; [2/7] WORKDIR /app                                                                                               0.2s
 =&gt; [3/7] RUN pip install --upgrade pip setuptools wheel                                                             8.7s
 =&gt; [4/7] RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends     gcc     g++     make     libffi-dev  84.5s
 =&gt; [5/7] RUN npm install -g prettier                                                                                1.5s
 =&gt; [6/7] COPY app /app                                                                                              0.1s
 =&gt; [7/7] RUN pip install uv                                                                                         4.5s
 =&gt; exporting to image                                                                                              13.4s
 =&gt; =&gt; exporting layers                                                                                             13.4s
 =&gt; =&gt; writing image sha256:39add91710bc7970d44dae04b3f4a0c4f227d1471fac4df7b01cec86ce7af3cf                         0.0s
 =&gt; =&gt; naming to docker.io/library/tds-project-1                                                                     0.0s

@ANdIeCOOl ➜ /workspaces/TDS-Project-1/tds-project-1 (main) $ docker images
REPOSITORY      TAG       IMAGE ID       CREATED          SIZE
tds-project-1   latest    39add91710bc   31 seconds ago   923MB
if this cause any issues please notify  @s.anand @carlton @Jivraj
in phase B tasks are we supposed to create files to store the output or return it in the response ???
Please answer ASAP sir.
@s.anand
Respected Sir,
I sincerely request you to kindly consider granting a one-day extension for Project 1. Many key clarifications were provided in today’s session, and we need just one additional day to effectively implement them. This extension would be immensely helpful in ensuring a more refined submission.
I truly appreciate your time and consideration.
Thank you.
@all can everyone please test my image and let me know PLEASE. THIS IS THE MOST YOU ALL CAN DO FOR ME. I WILL BE BERY GRATEFUL


github.com


GitHub - ANdIeCOOl/TDS-Project-1
main
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.





hey I have a few doubts, if something was said about this please say so.

in Phase be tasks do we have to store the output in files or just return it in the response
When I call my some of my endpoints using post man or CURL they work but if I run the evaluate.py it throws an error, this I think is a bug in the eval.py file.

any idea about these ?
facing the issue on submission
Here\'s a detailed description of the image:\n\n**Overall:** The image is a screenshot of a form or input fields likely from a software application or web page. It appears to be requesting information related to code repositories and image publishing.\n\n**Content Breakdown:**\n\n1. **First Input Field:**\n * **Label:** "What is the link to your GitHub repository which has the code for Project 1?"\n * **Example Format:** `https://github.com/user-name/repository-name` (presented as a hyperlink)\n * **User Input:** `https://github.com/rsjay1976/TDS-Project1-Ja` \n\n2. **Second Input Field:**\n * **Label:** "What is the name of the image published on DockerHub?"\n * **Example Format:** `user-name/image-name` \n * **User Input:** `rsjay1976/tds-project1-Jan25`\n\n3. **Validation Indicator:**\n * There’s an exclamation mark in a yellow triangle icon, along with the text "Must match pattern". This suggests the user\'s input is being validated against a specific pattern.\n\n**Overall Impression:** This image depicts a data entry or configuration step in a software setup process, most likely related to version control (GitHub) and containerization (DockerHub). The form is asking the user to provide the links and names of specific resources.image942×521 28.7 KB
please ignore the above… there was a upper case issue  in image name… now fine
Is it import to use python 3.13?
It is not stable yet
Here\'s a detailed description of the image:\n\n**Overall:** The image displays a text-based error message likely originating from a Python program. The background is black, and the text is white.\n\n**Specifics:**\n\n* **File Paths:** The error message references two file paths: `"app/app.py"` and `"/usr/local/lib/python3.12/site-packages/openai/__init__.py"`. This indicates an error occurred while running the script `app.py`, and the error originated from the OpenAI library.\n* **Error Type:** The error is a `OpenAIError`. \n* **Error Message:** The specific error message states, "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable." This suggests the program is trying to use the OpenAI API, but an API key has not been provided.\n* **Line Numbers:** The error references specific line numbers within the files: line 35 in `app.py`, and line 109 in `openai/__init__.py`.\n* **Code Snippet:** There is a code snippet `client = Openai(` with a series of seemingly irrelevant characters following it.\n* **Context:** This error is common when working with the OpenAI API and indicates a missing or improperly configured API key.\n\n\n\nIn essence, the image captures an error encountered while running a Python program that uses the OpenAI API, indicating that an API key has not been set up correctly.image1831×146 7.91 KB
can someone help me fix this error @Jivraj @carlton
for the datagen script is it ok to hardcode the scripts url and my email id? I understand the script itself may change but can I count on the link remaining the same? Also is it necessary to pass the email as argument?
from dotenv import load_dotenv
load_dotenv()
yahh i have it in my code…still facing the issue
@Jivraj @carlton [filler to extend length]
whats the image’s name on Docker?
just completed my sem exams started worrking on the project from 2 days please give extension of deadline for the project sir
dont we have to add the data folder or folder like datagen in the repo?
thats confidential, im not an idiot xD, that will get me definitely  in trouble
no, not really . Just your app
in your project,in the app folder you have the data folder which is empty so should I keep that or remove it
and also will u be making any chnages in the repo
File “/app/app.py”, line 35, in 
client = OpenAI(
^^^^^^^
File “/usr/local/lib/python3.12/site-packages/openai/_client.py”, line 110, in init
raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable                                                                              some pls help me fix this error!!
Blunder in your main.py.
You are using API_KEY = os.getenv(“AI_PROXY_TOKEN”) but it should be AIPROXY_TOKEN.
Btw what you using for phase B?
yes i will change that
nothing i think, i’ll import those generic functions and use tool usage only probably if can’t crack dynamic code generation
i don’t have that


github.com


TDS-Project-1/tds-project-1/app at main · ANdIeCOOl/TDS-Project-1
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.





What we expect in project.

server running inside docker container at 8000.
And all files will be accessed from data folder in root directory.

Apart from these two you can have anything extra.
model='gemma3:27b' created_at='2025-06-13T09:16:51.668128203Z' done=True done_reason='stop' total_duration=61410215168 load_duration=17943061 prompt_eval_count=323 prompt_eval_duration=19745660210 eval_count=414 eval_duration=41645764955 message=Message(role='assistant', content="Here's a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a command-line interface (CLI) screenshot, specifically a Docker build process that has encountered errors. The background is black with green text indicating the progress and status of the build.\n\n**Key Elements & Details:**\n\n1. **Command Line Prompt:** The prompt shows the current directory: `PS C:\\projects\\tds_project>`. It indicates that the user is running commands within a PowerShell environment.\n\n2. **Docker Login & Build:** Initial lines show a successful Docker login and the initiation of a build process using `docker build -t pratik087hala/automation-agent .`.\n\n3. **Build Progress:** Lines show stages of the build process (e.g., transferring Dockerfile, pulling the base image).\n\n4. **Error Message:** A prominent error message is displayed in red, indicating a failure to resolve the source metadata for the `python:3.12-slim-bookworm` base image. The error cites a `http` request failure, specifically a failure to get from `ps://docker-images-prod.goo8.azure.com/registry/v2/docker/library/python/3.12-slim-bookworm`. It also mentions an issue with the host.\n\n5. **Dockerfile Snippet:** The lower part of the image shows a snippet of the `Dockerfile`:\n * Line 1: `FROM python:3.12-slim-bookworm` - Specifies the base image for the Docker container.\n * Line 3: `# Install essential system dependencies` - A comment describing the intent of the subsequent commands.\n\n6. **Build Details:** The final lines indicate the build details including the Docker version and the build context.\n\n**In essence, the image showcases a failed Docker build due to network or connection issues when attempting to pull the base Python image.**", thinking=None, images=None, tool_calls=None)Screenshot 2025-02-15 2128261903×492 32.1 KB
how to fix this error ?
What problem you facing with that dynamic code generation part?
I have exhausted my api limit of $2. I need to test my project. Can you please provide some more credits? @Jivraj @carlton @s.anand
no problem but im losing steam slowly, i need to buckle up and PUSH @Jivraj
Subject: Request for Project Deadline Extension
Dear Sir,
This project is highly complex, and we need additional time to ensure its successful completion. We kindly request an extension of the deadline to allow for thorough testing and proper implementation. An extension would greatly help us deliver the best results.
Thank you for your understanding  @Jivraj @carlton @s.anand
This might be problem with network settings(unstable internet, firewall, VPN interference)
try to debug it with help of chatgpt.
You can also use codespaces for trying another network.
Streamlining setup with GitHub Codespaces
Push push @23f1002382
@Jivraj is it fine if i have my AIPROXY_TOKEN in my code instead of getting it as environment variable?
if you do that then during evaluation, it would use your credit limit. if it gets exhausted, you may face problems. @23f2003413
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a file directory structure, likely within a code editor or file explorer. It displays a hierarchical view of files and folders within a project named "TDS-Project-1". \n\n**Detailed Breakdown:**\n\n* **Root Directory:** The topmost level is "TDS-Project-1", which contains several subdirectories and files.\n* **`.venv`:** A virtual environment directory, commonly used for Python projects to isolate dependencies.\n* **`app`:** A directory, containing a subdirectory named `data`.\n* **`data` Directory:** Contains:\n * `__init__.py`: An empty file used to mark a directory as a Python package.\n * `funtion_tasks.py`: A Python script file.\n * `main.py`: A Python script file, likely the main entry point of the application.\n * `task_to_embed.txt`: A text file.\n * `.gitignore`: A text file specifying intentionally untracked files that Git should ignore.\n * `datagen.py`: A Python script file.\n * `evaluate.py`: A Python script file.\n * `Dockerfile`: A text file containing instructions for building a Docker image.\n* **`README.md` and `LICENSE`:** These files likely contain project documentation and licensing information.\n* **Indicators:** Some files and directories have small indicators to the right of them, suggesting they may be modified or untracked in a Git repository. For instance, files `datagen.py` and `evaluate.py` both have "2, U" and "3, U" next to them which likely means they have 2 and 3 uncommitted changes respectively.\n\n**Overall, the image depicts the file structure of a Python project, potentially involving data processing, model evaluation, and containerization using Docker.**image266×559 12.5 KB
this is what i am doing first using the podman given in the portal and then running the evaluate.py file
ahhh okay, but i am getting an error while trying to fetch the token as an environment variable. any suggestions to fix this issue?
you can use python-dotenv. check that out.
tried that still not getting T_T anyways thanks mate!
No don’t do that, just follow the procedure.
Two problems with keeping token in file.

It will become public after you push to github.
While running evaluation script after submission your token might run out of credits.

ohh yes, didn’t think it through xD
I am facing the same error. and I have checked for solutions and found none. Did you resolve it? If yes can you please guide me through it?
{
“detail”: “Error code: 401 - {‘error’: {‘message’: ‘Your authentication token is not from a valid issuer.’, ‘type’: ‘invalid_request_error’, ‘param’: None, ‘code’: ‘invalid_issuer’}}”
}          getting this error sir



github.com


TDS-Project-1/tds-project-1/app at main · ANdIeCOOl/TDS-Project-1
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.






i keep updating, check this
Please extend deadline by 1 day. i just got discharged from hospital today, was suffering from liver problem since some days and got high heart beat due to a medicine unrelated to liver and made me got admitted@Jivraj
11:59 + 5 hours atthe most, @s.anand ?   
11 posts were split to a new topic: Project 1 - Casual banter
@Jivraj sir   @carlton    sir do have to add datagen in the docker container?
As when I’m running it locally, it gives 9/10, but when I pull it from Hub and run eval, it says:detail": “[Errno 2] No such file or directory: ‘/data/datagen.py’”
Here\'s a detailed description of the image:\n\n**Overall:**\n\n* The image displays a code snippet, likely a JSON response from an API or web service. It\'s presented in a dark-themed code editor or terminal window.\n\n**Content:**\n\n* **JSON Structure:** The snippet is formatted as a JSON object with a key called "detail".\n* **Error Message:** The "detail" key contains an error message indicating an issue with authentication. Specifically, it states: "Error code: 401 - { \'error\': \'Your authentication token is not from a valid issuer\' }".\n* **Error Details:** Within the error message, there\'s another nested JSON object with the following keys:\n * `error`: The human-readable error message.\n * `type`: `invalid_request_error` (describes the type of error).\n * `param`: `None` (no parameter is associated with the error).\n * `code`: `invalid_issuer` (the specific error code).\n* **Line Numbers:** The code snippet is numbered starting from line 1.\n* **Navigation bar:** The top of the image displays a navigation bar with the options Response, Headers, Cookies, Results and Docs.\n* **Copy button:** A "Copy" button is present in the top right corner of the image.\n\n**In summary:** The image shows an error response indicating that the provided authentication token is invalid because it originates from an unrecognized issuer.image706×193 6.15 KB
someone please help me fix this error
@carlton can you pl merge this

github.com/sanand0/tools-in-data-science-public








Update evaluate.py with correct link of datagen.py for task `A1`


tds-2025-01 ← rohitxiitm:patch-1



          opened 10:56AM - 15 Feb 25 UTC




            rohitxiitm
          



+1
-1










ppl are facing issues in evaluate.py for task A2
folks, need a confirmation. i don’t know but i heard it from someone or somewhere.
we cannot send json in response, if it is success ? need to send text
is that really the case ?
@rohitgarg - thanks for this. Merged your PR pointing to the correct link for evaluate.py
Sir from which session to which session is about tds project?
week-5 session-1 &amp; week-5 session-3
Here is  a Bruno collection (open source alternate for postman) for API testing A1 to A6
bruno collection
On my system evaulate.py is throwing an error on A2 trying to execute npx on format.md before the llm is even invoked. However running the command directly on the command line works.
evaluate.py:
 A2 failed: Command ‘[‘npx’, ‘prettier@3.4.2’, ‘–stdin-filepath’, ‘data/format.md’]’ returned non-zero exit status 2.
 A2 FAILED
bash:
npx prettier@3.4.2 --stdin-filepath data/format.md
bash works as expected. Can someone help?
@carlton
Is there a maximum size limit for the Docker Image?
Thanking you
@carlton @Jivraj
Hi ,
I am trying to build using both docker and podman but it failed on both. I have watched many videos trying to resolve this adn also chatgpt in order to resolve the issue but it seems to persist. I even uninstalled and reinstalled both podman and doceker multiple times but no help.
When i run command docker build -t ___________ .
the error that comes is :
Dockerfile:2
1 |     # Use a lightweight Python image
2 | &gt;&gt;&gt; FROM python:3.12-slim
3 |
4 |     # Set the working directory in the container
ERROR: failed to solve: python:3.12-slim: failed to resolve source metadata for Docker Hub Container Image Library | App Containerization failed to copy: httpReadSeeker: failed open: failed to do request: Get “https://docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com/registry-v2/docker/registry/v2/blobs/sha256/6f/6f3c6367c5a38963f84310cbb24dfcfbddab1dad40cff18afb8fe89098891f08/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=f1baa2dd9b876aeb89efebbfc9e5d5f4%2F20250215%2Fauto%2Fs3%2Faws4_request&amp;X-Amz-Date=20250215T192245Z&amp;X-Amz-Expires=1200&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=ed37cf0c346e2ed440f29638ec43ce66640bdc7d285e7be7bf25c308c46fd6b1”: dialing docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com:443 container via direct connection because static system has no HTTPS proxy: connecting to docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com:443: dial tcp: lookup docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com: no such host
Even tried getting python:3.12-slim separatly and trying again but that also didn’t work.
I think there is some problem in getting python:3.12-slim as the build always stops at this.
on asking ChatGPT it shows that some DNS or network issue is there. I even tried all the remedy that was provided on creating custom network etc. but this was also of no use
Kindly help me finding solution to this and pls mention any other assistance I may require to get this running
Thank You.
Regards,
Aagman
i am getting this error, I have tried many times but still the error persists:
“message”: “Bearer YOUR_AIPROXY_TOKEN is invalid: JWSInvalid: Invalid Compact JWS”
someone please help!!!
@carlton needed a confirmation on this task
A8 * `/data/credit-card.png` contains a credit card number. Pass the image to an LLM, have it extract the card number, and write it without spaces to `/data/credit-card.txt - in this task i assume prompt can ask for credit card number or other details like cvv and name.
My question is, whether my system should allow prompt that CVV or or such info ? or should give it ?


Previously I asked for some more credits to test my project. I got an email stating I have been provided with a new token but I think I got that same token again, not a new one. I still cant send request to the AIPROXY. Please help.


Do I need to submit the docker image name with the tag or without the tag? I submitted it before without the tag. Now i see that I have tagged the image with as v1 but I cant submit the form due to pattern matching problems. Should i submit again after tagging it with :latest ?


@s.anand @carlton @Jivraj
@Jivraj @carlton  sir in the phase B will the input and output path will be given ?
@carlton @Jivraj @Saransh_Saini
When I run my docker image using
podman run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000 $IMAGE_NAME
Task A2 fails as the podman container is unable to find npx.
Running the same image using
docker run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000 $IMAGE_NAME
works fine and Task A2 passes. I can’t understand why this is happening.
I also ran the image in both docker and podman in interactive mode as show in the below snippet from terminal.
When run using docker, which node gives /usr/bin/node as output but when run using podman, nothing.
shiva@shiva:~/Desktop/tdsp1$ sudo podman run --rm -it docker.io/myusername/myreponame /bin/sh
# echo $PATH
/root/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
# which node
# exit
shiva@shiva:~/Desktop/tdsp1$ sudo docker run --rm -it docker.io/myusername/myreponame /bin/sh
# echo $PATH
/root/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
# which node
/usr/bin/node
# exit
shiva@shiva:~/Desktop/tdsp1$ sudo podman run --user=root --rm -it docker.io/myusername/myreponame /bin/sh
# which node
# which node
# exit

Here’s how to prompt folks. Just do what @carlton mentioned in today’s live session (the 5 hour marathon) and you should be good for Project-1!


x.com



Aakash Gupta
@aakashg0

Most people are still prompting wrong.

I've found this framework, which was even shared by OpenAI President Greg Brockman.

Here’s how it works: pic.x.com/2MMcEqBeIJHere\'s a detailed description of the image:\n\n**Overall Impression:** The image is a graphic outlining the anatomy of an AI prompt, specifically focusing on how to structure a request for optimal results. It utilizes a dark background with white and teal text for emphasis.\n\n**Key Elements & Breakdown:**\n\n1. **Title:** At the very top, in bold white text, reads "The Anatomy of an AI Prompt".\n2. **Prompt Text (Left Side):** A block of text presents a sample AI prompt requesting information about hikes near San Francisco. This detailed prompt is the core of the example.\n3. **Sections with Labels (Right Side):** The prompt is broken down into four sections, each labeled with a teal bar and white text. These sections explain the core components of an effective prompt:\n * **Goal:** ("Each hike should provide a cool and unique adventure, and be lesser known.") Defines the desired outcome.\n * **Return Format:** (“For each hike, return the name of the hike as I’d find it on AllTrails, then provide the starting address of the hike, the ending address of the hike, distance, drive time, hike duration, and what makes it a cool and unique adventure.”) Specifies how the information should be presented.\n * **Warnings:** (“Be careful to make sure that the name of trail is correct, that it actually exists, and that the time is correct.”) Highlights potential errors or conditions to avoid.\n * **Context Dump:** (“For context: my girlfriend and I hike a ton! we’ve done pretty much all of the local SF hikes, whether that’s presidio or golden gate park. we definitely want to get out of town…we did mount tam pretty recently, the whole thing from the beginning of the stairs to stinson - it was really long and we are definitely in the mood for something different this weekend! ocean views would still be nice. we love delicious food. one thing I loved about the mt tam hike is that it ends with a celebration (Arriving in town to breakfast!) The old missile silos and stuff near Discovery point is cool but I’ve just done that hike probably 20x at this point. We won’t be seeing eachother for a few weeks (she has to stay in LA for work) so the uniqueness here really counts.”) Provides background information and preferences to guide the AI’s response.\n\n**Color Palette:** The image uses a dark background (black or very dark gray) with white text and teal accents to highlight key sections.\n\n**Overall Purpose:** The graphic is designed to illustrate a structured approach to crafting effective prompts for AI models, aiming to improve the quality and relevance of the generated responses.


8:06 PM - 14 Feb 2025


      5.5K
    


      360
    






Same issue. Got the same token. Can’t use it since 2 dollar limit has been crossed. Please help. @carlton @Jivraj
Yes I also need the answer of this.
Is there any way of figuring what is the usage of my token and if yes then how…
Plz some peers help…
It will be corrected soon by @jkmadathil
He is in charge of our budget for TDS and the tokens are being issued by him.
Please tag him for any token related issues.
New token assigned to the students.  Emails are also sent.
sir I am noticing a pattern, that when I am running the datagen first. And then using the evaluate.py, then I am getting the A2 right.
But running the evaluation.py for the 2nd time cause the A2 to fail…
Probabbly Because the file in the data folder gets upated should I worry for that…
in the phase B, we have no idea about how many arguments are there, so should we make every function mapping with 2 arguments ( 1 containing the input location and other containing output location) or should we take the parameters in some other way
There has been an outage in some parts of the country related to cloudflare servers. What helped some students (and us) is using a completely different network eg. instead of using your home wifi, use mobile internet, since they go through a different DNS and this sometimes works.
Kind regards
We have not specified a size limit for the docker image, so in theory there is not a limit to the docker image size.
Kind regards
Hello  @carlton Sir,
While running evaluate.py , I have observed that the expected  and actual output is having difference like “\n” then also it marks task as fail.
eg:
 EXPECTED:
Cover west give likely individual though question inside. System many human plant card among provide. Large former seek mouth there long.
Attention officer successful. Us population the true show.
Real cold if play side wind affect. Street cause investment receive have miss page station.
Cold rest term her conference. Animal sure campaign new.
Meeting back page exactly itself book forward. Decision western series under from shoulder. Pay during feeling newspaper human. Professional old recent beyond girl three human.
Difficult yourself build increase back put others.
Although artist operation thing skin lead. Billion deep measure down adult suggest. Anything action start artist when first.
Whole way know down. Music machine trip father rather.
Must medical bad law issue.
Someone explain seven maintain wrong day factor property.
 RESULT:
“Cover west give likely individual though question inside. System many human plant card among provide. Large former seek mouth there long.\nAttention officer successful. Us population the true show.\nReal cold if play side wind affect. Street cause investment receive have miss page station.\nCold rest term her conference. Animal sure campaign new.\nMeeting back page exactly itself book forward. Decision western series under from shoulder. Pay during feeling newspaper human. Professional old recent beyond girl three human.\nDifficult yourself build increase back put others.\nAlthough artist operation thing skin lead. Billion deep measure down adult suggest. Anything action start artist when first.\nWhole way know down. Music machine trip father rather.\nMust medical bad law issue.\nSomeone explain seven maintain wrong day factor property.\n”
 A5 FAILED
Will this be considered as failure in actual evaluation as well or will this be taken care in actual evaluation?
Here\'s a detailed description of the image:\n\n**Overall:** The image is a screenshot of a web browser window displaying code output.\n\n**Details:**\n\n* **Browser:** The browser appears to be Chrome, indicated by the address bar and tab features.\n* **Address Bar:** The address bar shows `127.0.0.1:8888/run/task-install/%26py%26/required/%26l%26tasks%26ol%26http%3A%2F%2Fraw.githubusercontent.com%2Fsanand0%2Ftools-in-data-science-public%2Ftds-2025-01%2Fproject%2F1%2Fdatagen.py`\n* **Code Output:** The main content displays a JSON object.\n* **JSON Content:**\n * It contains a single key-value pair.\n * The key is `"success"` with the value being a string: `"Executed https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project/1/datagen.py with email trial@mail.com."`\n* **Pretty-Print:** A `Pretty-Print` button is shown.\n\nIn summary, the image shows a successful execution message, in JSON format, indicating that a Python script (`datagen.py`) from a GitHub repository was executed with a specified email address.image1412×248 16.3 KB
Im able to execute the query succesfully.
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a Windows File Explorer window displaying the contents of a folder named "data" located on the C: drive. \n\n**Key Elements:**\n\n* **File Explorer Interface:** The standard Windows File Explorer interface is visible, with navigation buttons (back, forward, up), address bar, and a ribbon at the top.\n* **Navigation Pane (Left):** The left pane shows the folder structure, including folders like "Pictures," "Desktop," "Downloads," "Documents," "Music," "Videos," "TDS assignments 4," and "llm-automation-agent".\n* **Content Pane (Right):** The right pane displays the files and folders within the "data" folder.\n* **Files and Folders:** The following files and folders are visible within the "data" folder:\n * "docs" (Folder)\n * "logs" (Folder)\n * "comments" (Text File - 10 KB)\n * "contacts" (JSON File - 9 KB)\n * "credit\\_card" (PNG File - 5 KB)\n * "dates" (Text File - 15 KB)\n * "email" (Text File - 1 KB)\n * "format" (Markdown File - 1 KB)\n * "ticket\\_sales" (Data File - 32 KB)\n* **File Information:** The file list includes columns for "Name," "Date modified," "Type," and "Size." All files were modified on February 16, 2023, at 11:56 or 11:58.\n\n**Overall, the image shows a data folder containing a mix of text files, JSON, PNG, Markdown and a database file.**image1109×570 40.3 KB
But the data gets downloaded to C drive instead of the project folder
The datagen.py file is in the project folder itself.
Here\'s a point-by-point description of the image:\n\n* **Type:** The image displays a snippet of code, likely Python, presented in a dark-themed text editor or terminal.\n* **Code Function:** The code snippet defines variables and a function call related to directory management. \n* **Variable Definitions:**\n * `PROJECT_ROOT` is assigned the absolute path of the current working directory using `os.path.abspath(os.getcwd())`.\n * `DATA_DIR` is assigned the path to a "data" subdirectory within the project root, constructed using `os.path.join(PROJECT_ROOT, "data")`.\n* **Function Call:** The code includes a call to `os.makedirs(DATA_DIR, exist_ok=True)`. This creates the directory specified by `DATA_DIR`, ensuring that if the directory already exists, no error is raised due to the `exist_ok=True` argument.\n* **Comments:** The code includes comments explaining the purpose of the operations: ensuring that all files are accessed from a "data" folder within the project root and that the "data" directory exists.\n* **Color Coding:** The code is color-coded for readability. Keywords like `os`, `True` are colored orange, variables are colored cyan, strings/paths are colored green, and operators/symbols are colored white.\n* **Line Numbers:** The lines of code are numbered, starting from line 35.\n\n\n\nimage821×149 9.61 KB
am I making any error when setting the directories?
Please help, have been facing this issue since the beginning of this project, initially tried to move the files from C drive to project folder but that does not seem like a viable solution.
Here\'s a detailed description of the image:\n\n**Overall:**\n\nThe image displays a snippet of Python code, likely part of a larger program. It\'s a function definition named `run_datagen` that appears to download and execute a Python script based on information provided in a task description.\n\n**Code Breakdown:**\n\n1. **Function Definition:**\n * The code starts with a function definition: `def run_datagen(task_description):`\n\n2. **URL and Email Extraction:**\n * The code uses regular expressions (`re.search`) to extract a script URL and a user email from the `task_description` input.\n * It stores the extracted URL in the `script_url` variable and the email in `user_email`.\n * There\'s error handling: if either the URL or email is not found in the task description, the function returns an error message.\n\n3. **Script Download:**\n * The code attempts to download the script from the extracted `script_url` using the `requests` library.\n * It saves the downloaded content to a file named "datagen.py" in a directory specified by `PROJECT_ROOT`.\n * Error handling is present to ensure the download was successful by checking the response status.\n\n4. **Dependency Check (uv):**\n * The code checks if the `uv` package is installed using `subprocess.run`.\n * If `uv` is not found, it attempts to install it using `pip`.\n\n5. **Script Execution:**\n * The code executes the downloaded "datagen.py" script using `subprocess.run`.\n * It passes the `script_path` and `user_email` as arguments to the script.\n\n6. **Return Value:**\n * The function returns a success message including the executed script URL and used email upon successful execution.\n\n**Libraries Used:**\n\n* `re`: Regular expression operations\n* `os`: Operating system related operations.\n* `requests`: For making HTTP requests (downloading the script).\n* `subprocess`: For running shell commands (checking/installing dependencies and executing the script).\n\n**Overall Purpose:**\n\nThis code snippet automates the process of downloading, preparing, and running a Python script based on information provided in a task description, including the user\'s email. It demonstrates a system for dynamically executing scripts and passing parameters to them.image1123×760 42.8 KB
I am also running datagen.py in the project directory, yet data folder is created in C drive.
@jkmadathil
sir plz renew my token…
Showing,
{‘message’: ‘On 2025-02 you used $2.0041067399999912, exceeding $2’}
Sorry sir!..
use PlainTextResponse for /read
Plz do someone reply.
@carlton @s.anand @Jivraj
Please review the code and help me fix the error in order to proceed further. Thanks.


github.com/ANdIeCOOl/TDS_CLUTCH_PROJECT_1


README.md

main

# TDS_CLUTCH_AT_6AY







using code generation, getting 6/10 or * if lucky, similar comments needs a tool function call for sure, maybe someone can implement and create pull request, if you all can get 10/10 fine tuning with tool functions
@Jivraj @carlton Please help if it meets deliverables
Sir I need a help, In hte B portion where no any destination and source files are given…
There we need to ask the user to povide the source and destination files or does we should store it in any default file locations…
As the statement is very vauge saying the “agent should handle this”…
Thanks Sir!!
@jkmadathil @carlton @Jivraj
Sir earlier my code was running fine, but after the assigment of the new token,
it is now showing 400 bad request, which simply implies there is something wrong with the token…
plz do something sir…
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of what appears to be a server log or console output. It\'s characterized by lines of text, likely representing requests made to a web server. The background is black, with the text displayed in a light gray or white color. \n\n**Key Elements:**\n\n* **IP Addresses:** Lines begin with IP addresses (e.g., 172.21.0.5) followed by a timestamp.\n* **Request Paths:** Long strings represent URLs or request paths, including "/@daticket/data/ticket-sales-gold/backoff." \n* **HTTP Status Codes:** Several lines end with HTTP status codes in red, indicating errors. Specifically:\n * "400 Bad Request"\n * "404 Not Found"\n* **File names**: several file names are present like "thumbnail" and "ticket"\n\n**In summary**: The image depicts server errors, likely related to requests for data files or resources via a web application or API. The 400 and 404 errors suggest either malformed requests or requested resources that are unavailable.
I have do have cross verified the new token been correctly been assigned to the system variable…
More Particularily the failure occurs in the response portion…
def get_completions(prompt: str):
    print("Inside get_completions")#Debug
    with httpx.Client(timeout=20) as client:
        response = client.post(
            f"{openai_api_chat}",
            headers=headers,
            json=
                {
                    "model": "gpt-4o-mini",
                    "messages": [
                                    {"role": "system", "content": "You are a function classifier that extracts structured parameters from queries."},
                                    {"role": "user", "content": prompt}
                                ],
                    "tools": [
                                {
                                    "type": "function",
                                    "function": function
                                } for function in function_definitions_llm
                            ],
                    "tool_choice": "auto"
                },
        )

    print("DId suceessful llm calll")#Debug

INFO:     127.0.0.1:52108 - "POST /run?task=The+SQLite+database+file+%60%2Fdata%2Fticket-sales.db%60+has+a+%60tickets%60+with+columns+%60type%60%2C+%60units%60%2C+and+%60price%60.+Each+row+is+a+customer+bid+for+a+concert+ticket.+What+is+the+total+sales+of+all+the+items+in+the+%22Gold%22+ticket+type%3F+Write+the+number+in+%60%2Fdata%2Fticket-sales-gold.txt%60 HTTP/1.1" 400 Bad Request

is there any limit on the size of the docker image @Jivraj @carlton ? because mine is about 5.6Gb
bhai nhi hai…
koi size limit
uv run https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/evaluate.py
Installed 13 packages in 543ms
Traceback (most recent call last):
File “/tmp/evaluateF6zgG9.py”, line 20, in 
from datagen import (
…&lt;9 lines&gt;…
)
ModuleNotFoundError: No module named ‘datagen’
I am getting this error when I try to run evaluate.py
when I run the evaluate.py by having datagen.py in same folder , it is running perfectly. But my doubt is only after task a1 runs the datagen.py will be downloaded into the /data folder right ?
@carlton @Saransh_Saini @Jivraj
Kindly help me with this issue
Use following as first parameter of subprocess.run() to create data/ directory inside your project instead of C: drive
["uv", "run", script_url, user_email, "--root", "./data"]

Also, you don’t need to download to script, you can directly run it from the url.
The reason for error is evaluate.py is trying to import datagen.py which doesn’t exist in your system. I’ll suggest download both the files, keep them in same folder and run evaluate.py from your computer
Yes actually Thats my doubt , when I run both in same folder it is working , but only after task a1 runs datagen.py will be downloaded in /data folder  right ?,
or did I misunderstood something??
Generation-Based Automation Agent (No Hard Coding)
Repository Link: GitHub - 23f2005593/tds
Currently, it can complete 7 out of 10 tasks. In reality, it can complete 9 out of 10 tasks, but the expected results are not flexible in evaluate.py file.
If we can extract credit card numbers, it will be able to complete 10 out of 10 tasks.
Please contribute to this repository. We will win together.
{
“message”: “On 2025-02 you used $2.0041388599999848, exceeding $2”
}
What to do?
facing same error, have you fouind any solution?
sir for this task- A6 Find all Markdown (.md ) files in /data/docs/ . For each file, extract the first occurrance of each H1 (i.e. a line starting with #  ). Create an index file /data/docs/index.json that maps each filename (without the /data/docs/ prefix) to its title (e.g. {"README.md": "Home", "path/to/large-language-models.md": "Large Language Models", ...} )   …I am getting correct result for all files but for the very first file budget.md it shows wrong.
my result- { “budget.md”: “Success easy same main modern doctor.”,
“build.md”: “Shoulder follow own never above.”,
and in the data files there is different heading in budget.md.-  # Series dog who make specific agree between.
my question is this if it works for all the files then why not for this file budget.md    @Saransh_Saini @Jivraj @carlton
do you able to do this task * A5. Write the first line of the 10 most recent .log file in /data/logs/ to /data/logs-recent.txt, most recent first …
i am also doing using prompt no hard-coded.
yes doing this only but finding correct for most of the files.
yes i am able to do task a5.
so you directly using prompt for doing this task.
yes i am only using prompt based method
If filename has number in its name then extract the number from the filename and convert it to an integer before sorting .Ensure numbers inside filenames are compared as integers, not as strings, to maintain proper order. Sort filenames in said in task. Avoid any lexicographical sorting issues.    i am using this extra info for doing this but still it does not give accurate result. can you help me in this
i already shared my repo u can check there.
you have pushed data,datagen and evaluate files…do we have to submit them as well??
(also send the docker file)
Check the file once, there is a possibility that it’s either fetching a comment or the second heading. Refactor your prompt to search only for the First Heading, specify it explixitly.
okay let me check once.
one more thing sir {“first_name”: “Crystal”, “last_name”: “Wilson”, “email”: “delgadorebecca@example.com”}   then what will be the sorted-contact for this as in email there is no first and lastname present. @Saransh_Saini
Hey, I submitted the project links in the google form yesterday but, today in the portal it shows that I have not submitted the project.
I am getting this error while running evaluate.py on task A9
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"

🔴 A9 failed: 'data'

There were no authentication issues till yesterday.
please guide @carlton @Jivraj @Saransh_Saini
This is happening because evaluate.py is unable to fetch your API Key from the environment variables. Create a new variable and set it’s value to your API Key then try.
Hi everyone,
I’m running into an issue with the AI Proxy embeddings endpoint while executing the A9 task. Every time I send a POST request to:
bash
Copy
https://aiproxy.sanand.workers.dev/openai/v1/embeddings

I receive a 401 Unauthorized response. This, in turn, causes my code to fail with a KeyError: 'data' because the expected JSON response doesn’t include the "data" key.
What I’ve Tried

Token Verification:


I’m using the AIPROXY_TOKEN obtained by logging in at aiproxy.sanand.workers.dev with my IITM email.
The token is passed in the header as follows:

python
Copy
"Authorization": f"Bearer {AIPROXY_TOKEN}"


I added debug prints to confirm that the token is being used correctly (printing the first few characters).


API Request Details:


The request includes the correct Content-Type: application/json header.
The payload is set as:

json
Copy
{"model": "text-embedding-3-small", "input": ["Test"]}


Despite this, the response status is consistently 401 Unauthorized.


Debug Output:
Here’s a snippet of the debug output:

bash
Copy
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"
🔴 A9 failed: 'data'

This confirms that the issue is with the authentication rather than our processing logic.
What I Suspect

The token may be invalid, expired, or misconfigured.
There could be changes in the token permissions or endpoint requirements that I’m not aware of.
Alternatively, there might be an issue on the server side with token validation.

Request for Help
Has anyone else encountered this issue recently? Could someone verify if there are any changes to the authentication requirements for the embeddings endpoint? Any insights or updated instructions on how to ensure the token is valid and has the proper permissions would be greatly appreciated.
Thanks in advance for your assistance!
B5. Run a SQL query on a SQLite or DuckDB database
Should I ask for the SQL data base. Or the agent should be smart enough to find the required database…
Moreover in the data folder there is only one database is it should be robust to handle multiple databases…
same issue i also face                   pls sir help us fix this issue and provide us more  token
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings “HTTP/1.1 429 Too Many Requests”
 A9 failed: ‘data’
@Jivraj @carlton @Saransh_Saini
I had a question on evaluation by the course team. To test that my application would run everywhere, I first deleted all images from my local machine using podman rmi -a and then ran podman run --rm -p 8000:8000 -e AIPROXY_TOKEN=$AIPROXY_TOKEN $IMAGE_NAME with the appropriate variables set. This is as per the instructions provided here. But this gave me the following error:
Error: short-name "freshbash/dataworks-agent" did not resolve to an alias and no unqualified-search registries are defined in "/etc/containers/registries.conf

The above is the format in which we have to provide the image name in the Google form. So, I was confused whether this would succeed during actual evaluation.
The only way its working right now is when I specify the image name to be docker.io/freshbash/dataworks-agent
I’m not yet very good with how containers work so some insights would be very helpful. Thanks!
Nice bro, if its getting 8 you are sorted, probably get more later. But Prompting seems a little less info
BUT





Structured Outputs
JSON Mode




Outputs valid JSON
Yes
Yes


Adheres to schema
Yes (see supported schemas)
No


Compatible models
gpt-4o-mini, gpt-4o-2024-08-06, and later
gpt-3.5-turbo, gpt-4-* and gpt-4o-* models


Enabling
response_format: { type: json_schema, json_schema: {strict: true, schema: …} }
response_format: { type: json_object }



    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            response_format={"type": "json_object"}
        )



github.com/23f2005593/tds


app.py

main


      
          prompt = (
              f"The Python code generated for the task '{task}' produced the following error when executed:\n"
              f"{error_message}\n\n"
              f"Here is the original code:\n{original_code_data['code']}\n\n"
              "Please provide a corrected version of the code that fixes the error. Return only a JSON object with:\n"
              "- code: the corrected Python code as a string\n"
              "- function_name: name of the main function\n"
              "- required_libraries: list of required pip packages\n\n"
              "Make sure the code is simple, direct, and error-free this time. And try not to mess it up like before."
          )
          try:
              response = client.chat.completions.create(
                  model="gpt-4o-mini",
                  messages=[{"role": "user", "content": prompt}],
                  temperature=0,
                  response_format={"type": "json_object"}
              )
          except Exception as exc:
              logger.error("Error connecting to OpenAI API for auto-fix: %s", exc)
              raise HTTPException(status_code=500, detail="Connection error during auto-fix. Maybe it's time to admit defeat?")
          
      
    





you are taking a chance on that format
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a dashboard displaying usage statistics for "Codespaces," likely a cloud-based development environment service. It shows two key metrics: Usage Hours and Storage.\n\n**Detailed Breakdown:**\n\n1. **Header:**\n * A blue header with a Codespaces logo (a bracket-like symbol) and the text "Codespaces."\n * Underneath, it states "Included quotas reset in 10 days. See billing documentation" with a link.\n\n2. **Usage Hours:**\n * A row displaying "Usage hours" with a progress bar.\n * It indicates "172.37 of 180.00 included core hours used"\n * A red progress bar fills most of the row, representing the amount used.\n * The cost is displayed as "$0.00"\n\n3. **Storage:**\n * A row displaying "Storage" with a progress bar.\n * It indicates "9.21 of 20.00 included GB-month used"\n * A blue progress bar fills a portion of the row.\n * The cost is displayed as "$0.00"\n\n4. **Footer:**\n * A message at the bottom states "$0.00 monthly spending limit | Set up a spending limit" with a link.\n * A cost of "$0.00" is also displayed.\n\n**Color Scheme:** The dashboard uses a dark background with blue and red progress bars to indicate the usage of allocated resources.\n\n**Overall:** The image presents a clear snapshot of resource usage within the Codespaces platform, emphasizing allocated and used amounts, along with associated costs.Screenshot 2025-02-16 0913411315×404 24.2 KB
Here\'s a detailed description of the image:\n\n* **Overall Impression:** The image is a screenshot of a dashboard displaying usage statistics for "Codespaces." The background is dark, typical of many software interfaces.\n* **Header:** A header shows the term "Codespaces" with a blue icon that resembles `<>`. Below it is text stating "Included quotas reset in 13 days. See billing documentation" with a hyperlink.\n* **Usage Hours:**\n * A section titled "Usage hours" displays a progress bar filled in red. \n * The text indicates that 120.00 of 120.00 included core hours have been used. \n * To the right, the cost is shown as "$0.00."\n* **Storage:**\n * A section labeled "Storage" shows a progress bar filled in blue.\n * The image indicates that 1.46 of 15.00 included GB-month have been used.\n * The cost is also indicated as "$0.00."\n* **Visual Style:** The dashboard uses a clean and minimalist design, focusing on clear indicators and numerical values. The use of progress bars visually communicates the degree to which allocated resources have been consumed.Screenshot 2025-02-16 0911011351×292 13.3 KB
Hardest i ever worked in my life. Thank you @s.anand



 TheVishal:

If we can extract credit card numbers, it will be able to complete 10 out of 10 tasks.


have tried function calling? with open code generation ?
not yet… but i have another problem when i am running this by using docker it is giving error “datagen module not found”
bro please help by contribute please
come off on one meet
what should we push in the github repo @Jivraj @carlton ??
is it enough if we just push the Dockerfile, app.py, datagen.py and the LICENSE. Someone pls help!
bro i used all my codespaces credits xD
i am nitpicking and editing from website and running not exceed limit XD
someone pls help T_T
submit image and github  repo link, evalhaters will handle the rest im assuming
yeaa i got that but what should we add in the github repo…like should we add the generated data folder?
or is it enough if we just add the code and the Dockerfile to the repo
doesn’t matter they use only image
use local editor naa bro
and run my code xD i have one crazy setup XD give me some time, at 9:30 we’ll hop on eachother
which repo u submitting yesterday one or todays.
i am unable to run the yesterday one
this one new one only xD
and what do they mean by image-name in the gform…is it the repo name in dockerhub?
what evil have u done xd
why? ///////////// O—O
dockerhub image name
ur words are saying something else 
image name as in i dont get it lol.
(general) [shubham@laptop data]$ curl https://api.openai.com/v1/models -H "Authorization: Bearer $AIPROXY_TOKEN"
{
  "error": {
    "message": "Your authentication token is not from a valid issuer.",
    "type": "invalid_request_error",
    "param": null,
    "code": "invalid_issuer"
  }

pls help
push ur image to docker hub that it will be available for them to use
(use chatgpt on how to push to docker hub 2 3 steps to flw)
yeah i hv pushed the image to dockerhub but i exactly dont get what image name is
like is it the name of my repo
ur docker-username/image-name
check if u have exported the AIPROXY_TOKEN properly in your environment
anyone check my repo

github.com



Here\'s a detailed description of the image:\n\n**Overall:** The image is a screenshot of a GitHub repository page. \n\n**Key Elements:**\n\n* **Repository Name:** "Tusharisme/TDS\\_Project\\_1" is displayed prominently in a large, bold font. This indicates the username ("Tusharisme") and the repository name ("TDS\\_Project\\_1").\n* **Repository Icon:** A square icon with a blue patterned design is visible to the right of the repository name.\n* **Statistics:** Below the repository name, there\'s a row displaying the following statistics:\n * **1 Contributor:** Indicates one person has contributed to the project.\n * **0 Issues:** No open issues are reported.\n * **0 Stars:** The project has no stars yet.\n * **0 Forks:** The project has not been forked by anyone.\n* **GitHub Logo:** A small GitHub logo is visible in the bottom right corner, indicating the platform.\n* **Background:** The background is a light, neutral gray color.\n* **Blue Bar:** A solid blue bar is positioned at the very bottom of the image.\n\n**In essence, the image shows a newly created GitHub repository with no activity (no stars, forks, or issues) and one contributor.**
GitHub - Tusharisme/TDS_Project_1
Contribute to Tusharisme/TDS_Project_1 development by creating an account on GitHub.






yes i have the same key which is provided on ai proxy website for my login
and yes i have that key properly exported
check if u have used the correct ai proxy url then
An email I just received says my license doesn’t have “MIT” in it. Although it does have it. I don’t know what I am missing. Someone help (if you didn’t get this mail). @carlton @Jivraj
@carlton @Jivraj @Saransh_Saini
Hi,
I received a mail saying that my submission has no Dockerfile. But git repo has a dockerfile.
even if i am to submit again, i have submit the same repo.
what should i do?
Hey I just got a mail saying that my github repo has no Dockerfile present. and im confused .
It doesnt mention anywhere that the dockerfile must be present in the root directory as a requirement/prerequisite of the project.
In my case its present inside the app directory. Could the team help clarify on this issue.
@Jivraj @carlton
What is expected repo structure ?
I have a folder in my repo and dockerfile and license are present in that folder but I still received a mail regarding missing License and Dockerfile.
do we need to have data folder in repo no right?
No, it is not needed
We see that your submission GitHub - 22f3001011/project-1  has a result of FAIL due to the below reasons:
No “MIT” in LICENSE
Hello sir, i got this mail despite having added the mit license as stated in the project problem statement. I cant figure out what the issue is, and help me out here.
@carlton @Jeeveash.k


github.com


GitHub - 22f3001011/project-1
main
Contribute to 22f3001011/project-1 development by creating an account on GitHub.






Thank you
Regards
Shashank J Shetth
22f3001011
Yeah. Same issue. Someone who didn’t get this error, please share the MIT license.
https://github.com/saniyanz/tds-p1new
check my repo. whats wrong. Ive also got the mail but I`ve included the MIT License and the Dockerfile
Rename LICENSE.txt to LICENSE
I got a mail saying my Dockerfile is missing. However I have a dockerfile already in my github repository. Is it an issue with the spelling of dockerfile since I have submitted it in all small case as ‘dockerfile’. It was showing the score when I checked with the evaluate.py that was provided by iitm.
Shall I just change the name of the file from ‘dockerfile’ to ‘Dockerfile’ in github repository of mine or is there anything else that is needed to detect the Dockerfile?
Hey team, I just moved my Dockerfile to the root level on my Github repo. Hope this solves the issue.
Small doubt: Do i need to submit the google form again?
I ran out of tokens. Please help me. Please its urgent.
@carlton sir @s.anand sir please provide me more tokens, I am out of tokens i don’t knwo what happened i hade 151 requests use and 0.09 usd and suddenly i check it was 300 requests and 2 usd i don’t knwo what happened can you provide me more tokens.
Dear @s.anand , @carlton , @Jivraj , and @Saransh_Saini
Thank you all for this wonderful project. Coming from a non-coding background, I have learned a lot new things throughout this project building process.
@carlton Sir, yesterday’s session provided valuable insights into Method 1 (prompt engineering) for dynamically handling tasks. I was able to develop an application using this approach; however, due to submission time constraints, I could not verify all tasks (my bad). While I tested some tasks and found the results to be highly accurate, I was unable to validate everything thoroughly.
Therefore, I submitted the function-calling approach (Method 2) instead.
I sincerely appreciate everyone’s guidance and support.
Did you ran out of tokens suddenly like me ?
How many requests have you sent in total ?
can u share ur repo
i really need it
Thanks @lakshaygarg654 for this feedback. Glad to know you learned from our efforts, it means a lot. This proves that even a person from non-tech background with determination can achieve it.
sir pls provide more token   @Saransh_Saini @Jivraj @s.anand                              sir pls , give any reply we have only 2 hr left
Change the name of your dockerfile to “Dockerfile”
yes sir please provide more tokens to me also @s.anand @Jivraj @carlton @Saransh_Saini
i hope i get 1 mark xD
im getting tasks only maybe 3 / 10
i have done many attempt but it is not working please show  my environment saying fastapi is not installed but i have installed and it is showing on checking but no running file it is saying no module i have installed in both virtual and system
please help
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a screenshot of a Visual Studio Code (VS Code) editor window. It appears to be a programming environment focused on Python development, likely for a project involving a FastAPI application. \n\n**Detailed Breakdown:**\n\n* **VS Code Interface:** The screenshot showcases the standard VS Code layout, including the:\n * **Explorer Sidebar:** Lists project files and directories. Files like `database.py`, `main.py`, `handler.py`, `tasks.py`, and a `data` folder are visible.\n * **Editor Window:** Displays the code for the currently open file, `main.py`. The code appears to be defining a FastAPI application.\n * **Terminal Window:** At the bottom, a terminal is open, showing the output of a `pip install` command.\n * **Menu bar:** Standard menu bar with options for File, Edit, View, etc.\n * **Tabs:** Tabs at the top for different open files.\n* **Code Snippet (`main.py`):** The visible code defines a simple FastAPI application:\n * Imports `FastAPI` and `app.tasks`.\n * Creates a `FastAPI` instance.\n * Defines a root endpoint (`/`) that returns a message "LLM-based Automation Agent is Running!".\n* **Terminal Output:** The terminal shows the output of a `pip install` command, installing required packages like `fastapi`, `uvicorn`, `starlette`, and potentially others. It indicates that some requirements are already satisfied and that it\'s upgrading `pip` itself.\n* **Files and Directories:** The file structure suggests the project involves:\n * A database module (`database.py`).\n * Task handling (`tasks.py`).\n * A `data` folder for data storage.\n * A `glagow` folder.\n * A `docker-compose.yml` file, indicating the project may be containerized using Docker.\n\n**In summary:** The image illustrates a developer working on a Python project, potentially an LLM-based automation agent, using VS Code, with Docker integration, and installing necessary dependencies using `pip`.image1919×1016 117 KB
this problem occuring sir since two days
How long does it take to make a docker image, I’ve been doing it for the past 25 minutes and it’s still not completed.


Your LLM app should be designed like it can give desire result based on task desc at run endpoint, and that result should be accessible at read endpoint.


Evaluation file just for reference to check how things works and it works for phase A tasks only. Also ensure datagen.py file and evaluation.py file are latest. There is one issue in evaluation.py file for task A1,  link of datagen.py file not correct, rectify that link. Even it corrected in GitHub repo file but when I download that raw file in local system it takes back previous link.


I WONDER HOW MANY API REQUESTS THE SERVER IS PROCESSING . It’s too slow
too much in the last few hours it feel
I guess what is done is done. I should have maintained my version history properly. I am getting 4 correct but with minor formatting issues so only 1 correct I guess.
It was tough… I will probably not score much but I enjoyed it a lot. Thank you for pushing us so hard. At least I am not scared of docker now and function calling feels easier than before.
Well done, everyone! This is not an easy project. This is the kind of work our clients are asking us for.
I will keep you posted on the evaluation on this thread, it progresses.

2025-02-16T18:31:00Z Google Form closed
2025-02-16T18:35:00Z Validating submissions. Will post results shortly

Sir i have missed the submission deadline  by 5  minutes, can you give permission for the google form to accept the response for half an hour more.
Sir, due to time panic, I mistakenly named the Docker image incorrectly.
Sir can you please allow submission for 5 more minutes?
A post was merged into an existing topic: Project 1 - Casual banter
@s.anand @carlton
Dear Sir,
I am writing to you in a state of distress and humility. An unfortunate mistake on my part has led to the upload of an incorrect Docker image link. When I checked the authenticity of the link, it showed an error, even though the GitHub repository link is functioning perfectly.
I have poured my heart and soul into this project, dedicating countless hours and sleepless nights to ensure its success. The project has successfully passed both Test A and Test B, and I was thrilled to see my hard work paying off. However, this single error has left me devastated.
I am pleading with you, with all my heart, to allow me to correct this mistake by updating the Docker image link. Alternatively, I humbly request that my application be reviewed directly through GitHub. Please consider this an exception, as I have worked tirelessly over the past two weeks to create an application that is 890 lines long.
I beg for your understanding and leniency in this matter. This project means the world to me, and I am genuinely sobbing over this setback.
Thank you for considering my heartfelt request.
Sincerely,
Rishit Jain
(24F2004595)
Although couldn’t complete handling every task, but really enjoyed working on this project and learned a lot throughout the process. I appreciate the opportunity to work on such an engaging project. For Project 2, I’ll make sure to allocate sufficient time and approach it with even greater commitment.
Sorry @s.anand @carlton @Jivraj
Sir, due to time panic, I mistakenly named the Docker image incorrectly.
Just push the latest image to docker asap. Hopefully the team considers it.
True. Same here. Just giving 2 days for this project was definitely a big mistake on my part… but I couldn’t really give more time due to work commitments.
@s.anand @carlton @Jivraj
Sir, due to time panic, I mistakenly named the Docker image incorrectly.
I am not 100% sure but i guess i used “ii” instead of “i” in “thevixhal/tdsvishal”… is there any way to check this ?
Can the submissions open just for some time? In minutes?
Many students did silly mistakes due toh nervousness, we can just correct it.
I don’t think the project is too difficult to implement—it’s essentially a simple HTTP API for an AI agent that reads a task, converts it into parameters, and passes those parameters to specific functions to complete the task. However, the instructions in the project question aren’t very clear. Before the session, I am unable to fully understand the question. It took me almost an entire day just to understand what we need to do.
Sir Could you provide test cases or a sample answer for Phase B?
@s.anand
@carlton sorry to disturb you, project1 deadline is over.
I made a mistake in my project. In my call llm function i set some payload instead of default for open ai api call like max token, temp. , n, stop etc.
Due to this, some tasks may fail especially credit card image task will fail 100%, if possible can i just remove that payload from git hub repository . or you can check this call llm function present in my task_handler.py file of my repository.
I found this issue after deadline. If possible consider this request. I never engaged in a project or course like for this one. I love this project genuinely.
my github repo : GitHub - 21f3001076/TDS_Project_1: This is IITM Data Science TDS Course Project 1 Repository
Thankyou
Lakshay
student id: 21f3001076@ds.study.iitm.ac.in
Dear @s.anand @carlton @Jivraj ,
Thank you so much for this wonderful project! We have learned so many things from this experience, especially the power of prompts. The team has put in tremendous effort, extending a few sessions and patiently clearing all our doubts. We truly appreciate the dedication and support
Regards,
Arjun
I would like to sincerely thank the course faculty @carlton @Jivraj @Saransh_Saini for their support on the project throughout the week. They were so patient in listening to our issues and helping us resolve them, even if the issues were repeated.
I was not able to complete some or maybe many of the tasks but overall, it was a very good learning for me, and I thoroughly enjoyed it.
Thanks very much again for your guidance and support.
Regards,
Swati
Thanks for your compliments Swati. It’s always nice to know our efforts paid off.
Happy Learning 
I have received a mail that my project has ""No “MIT” in LICENSE;No Dockerfile " which I saw today. My project has MIT licence and Dockerfile was also there… but to reconfirm I pulled my dockerfile from dockerhub to github only . NOw am not sure will that be considered now in my project submission or not. Requesting to kindly consider current state of my project in submission for my project.
WOMP WOMP should i call a wambulance?
(post deleted by author)
@all those who didn’t submit, its ok EVEN I did NOT submit. Even though i get zero, i am happy with the learning i did. Once again thank you sir @carlton @s.anand . This a been awesome experience , i haven’t been this alive in forever. Cheers.
I noticed something quite funny. The project never specified the required tech stack, so one could have done this entirely with JavaScript as well, assuming the necessary libraries are installed.
@TheVishal
EDIT: Create a new docker image with the mistaken image name , so when they pull image from repo, that image with the wrong name also gets pulled.
what to do

push a new image with the mistaken name, so in your repo there will be two images
how will this help?
since you are unsure, which image link you posted, you can be sure that even you had a mistake in link, a new image will exist with the wrong name after you push another image

@all
use this to update your image even after submission, as now they only validate the images, they do not pull it so you can edit your project and add more functionality if they release the code solutiion
CHEERS
Andrew OUT.
I didn’t submit the google form, I have made the github repo and docker image for TDS project 1. I, mistakenly, thought that I had submitted the google form but actually it was saved as a draft and closed my laptop. As soon as I realized my mistake, I hit the submit button but this was shown then,
“The form TDS Jan 2025 - Project 1 Submission is no longer accepting responses.”
I apologize for this. I have been working on this project for weeks.
This was my first TDS project. I would highly appreciated, if you could help me.
Thankyou
GitHub repo:GitHub - Sagankaur/TDS_project1: LLM-based automation agent
Docker : sagandeep/tds_project1
Sir, can we get the evaluation script now
@carlton @s.anand
If I am not wrong you were getting 9/10 in task A when many of us were stuck  and you didn’t submit… unbelievable 
Thank you, sir, for giving us this amazing opportunity! Honestly, I learned more in the last week than I did throughout the three modules.
The project was a rollercoaster ride—especially with all the errors that kept popping up—but overall, the experience was incredibly enriching. The amount of knowledge I gained was truly valuable.
A huge thanks to @Carlton, @Saransh_Saini, and @Jivraj sir for their guidance and support. Without the last week’s lectures, the project couldn’t have been completed.
i couldn’t my code space ran out of compute and then it was just lagging before i found out what happened , i just submitted old code repo and the image the we created in week 2 or week1 when had to create docker image for graded assignments
EDIT:
Here\'s a detailed description of the image:\n\n* **Overall Impression:** The image is a screenshot of a dashboard displaying usage statistics for "Codespaces." The background is dark, typical of many software interfaces.\n* **Header:** A header shows the term "Codespaces" with a blue icon that resembles `<>`. Below it is text stating "Included quotas reset in 13 days. See billing documentation" with a hyperlink.\n* **Usage Hours:**\n * A section titled "Usage hours" displays a progress bar filled in red. \n * The text indicates that 120.00 of 120.00 included core hours have been used. \n * To the right, the cost is shown as "$0.00."\n* **Storage:**\n * A section labeled "Storage" shows a progress bar filled in blue.\n * The image indicates that 1.46 of 15.00 included GB-month have been used.\n * The cost is also indicated as "$0.00."\n* **Visual Style:** The dashboard uses a clean and minimalist design, focusing on clear indicators and numerical values. The use of progress bars visually communicates the degree to which allocated resources have been consumed.Screenshot 2025-02-16 0911011351×292 13.3 KB
Here\'s a detailed description of the image:\n\n* **Overall:** The image is a screenshot of a user interface, specifically a notification bar from a software or web application.\n* **Background:** The background is dark, likely black, with a modern, minimalist design.\n* **Notification Bar:** A prominent red notification bar spans the width of the screenshot.\n* **Icon:** There\'s a warning icon (a circle with an exclamation mark) on the left side of the notification bar.\n* **Text:** The text within the bar reads: "You\'re at 100% of your included usage for this billing period. For more information, view your [billing settings]." The phrase "billing settings" is hyperlinked.\n* **Top Bar:** In the upper right corner, there are two buttons: "Go to docs" and "New codespace", the latter highlighted with a green color.\n* **Title:** The title above all the elements is "Your codespaces".\n\n**In summary:** The image depicts a usage alert in a software environment, likely a development platform, indicating that the user has reached their allocated usage limit for the current billing cycle.Screenshot 2025-02-17 2004141338×200 18.2 KB
Here\'s a detailed description of the image:\n\n* **Overall**: The image shows a screenshot of a dashboard related to "Codespaces" usage. It displays the current usage of core hours and storage.\n* **Header**: "Codespaces" is displayed with a description "Included quotas reset in 8 days. See billing documentation".\n* **Usage Hours**:\n * Label: "Usage hours"\n * Value: "180.00 of 180.00 included core hours used"\n * Visual: A red progress bar is filled to 100%.\n * Cost: "$0.00" is displayed on the right side.\n* **Storage**:\n * Label: "Storage"\n * Value: "9.60 of 20.00 included GB-month used"\n * Visual: A blue progress bar indicates approximately 48% usage.\n * Cost: "$0.00" is displayed on the right side.\n* **Background**: The background color is dark, likely a dark blue or black.\n\nThe image communicates that the user has fully utilized their included core hours for Codespaces, while storage usage is less than 50%. Both usage categories currently have a cost of $0.00.Screenshot 2025-02-17 2005251312×321 18.5 KB
Wait we had limits in codespace…I didn’t thought much of it but now that I see… …even mine is not so far from the limit…thanks for reminding…gotta be careful in next project
@carlton @Jivraj Is there something like peer-review in the project, I found this in the grading document.
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image is a screenshot of a data analysis or coding environment, likely a Jupyter Notebook or similar platform.\n\n**Key Elements:**\n\n* **Code Snippet:** A line of code is visible, starting with "if plot2D.KillWave".\n* **Arrow:** A right-pointing arrow (">") separates the code from subsequent text.\n* **Text Output:** The text following the arrow indicates that "Subnodes has plan to reserve full weight @bag202".\n* **Background:** The background is a light gray, typical for coding environments.\n* **Font:** A monospaced font is used for the code, and a standard font for the output text.\n\n**Context & Interpretation:**\n\nThe snippet suggests a conditional statement within a program controlling a visualization (likely the "plot2D" object). The output indicates that a data processing action related to "subnodes" is occurring, and the system has planned to allocate the full weight of a feature or parameter labeled "@bag202". It\'s likely part of a machine learning, signal processing, or data analysis workflow.\n\n\n\n
Here is a point-by-point description of the image:\n\n* **Layout:** The image depicts a three-row table-like structure.\n* **Top Row:** The top row contains the text "Peer Review Date".\n* **Middle Row:** The middle row displays a dash symbol ("-").\n* **Bottom Row:** The bottom row features the text "Tuesday, February 25, 2025".\n* **Background:** Each row is set against a light gray background.\n* **Purpose:** This appears to be a field or label in a form, likely used to input or display the date of a peer review.Screenshot 2025-02-18 at 1.00.50 PM126×226 2.02 KB
This project is one of the best experiences I had in the entire degree program. I could say this without any hesitation that what I learnt in the past 10 days &gt;&gt; last 3 months.
I really appreciate the idea of open internet type of evaluations, wherein, you implement things without any constraints, learning for the sake of implementing.
Doing this project, I also found many new ideas wherein function calling can be used to solve new problems. I also learned many new things from enthusiastic peers like @23f1002382 and also got the chance to help a few.
I thank the entire TDS team - @s.anand sir, @carlton , @Jivraj for their support throughout this amazing experience.
Regards,
Pradeep Mondal
sir using prompt method also i am having the error please provide a step wise solution so then i can make functions accordingly.
#/// Scirpt
# requires-python = "&gt;=3.13"
# dependencies = [
#     "fastapi",
#     "uvicorn",
#     "requests",
# ]
#///

from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

import requests
import os
import json
from subprocess import run

app = FastAPI()

response_format = {
    "type": "json",
    "json_schema": {
        "name": "taks_runner",
        "schema": {
            "type": "object",
            "required": ["python_dependencies","python_code"],
            "properties": {
                "python_code": {
                    "type": "string",
                    "description": "Python code to perform the task"
                },
                "python_dependencies": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "module": {
                                "type": "string",
                                "description": "Name of the python module"
                            }
                        },
                        "required": ["module"],
                        "additionalProperties": False
                    }
            }
        }
    }
}
}

primary_prompt = """
                You are an automated agent, so generate python code that does the specified task.
                Assume that uv and python are pre-installed.
                Assume that code you generate will be executed inside a docker container.
                Inorder to perform any task if some python package is required to install, provide name of those modules. 
"""

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

AIPROXY_TOKEN = os.getenv("AIPROXY_TOKEN")
headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {AIPROXY_TOKEN}"
}

@app.get("/")
def home():
    return {"welcome to the task runner"}
@app.post("/run")
def task_runnner(task: str):
    url = "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
    data = {
        "model": "gpt-4o-mini", 
         "messages": [
             {
              "role": "user", 
              "content": task
              },
              {
                "role": "system",
                "content": f"""{primary_prompt}"""
            }
         ],
         "response_format": response_format
    }

    response = requests.post(url=url, headers=headers, json=data)
    r = response.json()

    return r

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

Here\'s a detailed description of the image:\n\n**Overall Impression:** The image shows a screenshot of a Postman window, a popular application used for API testing. It appears a POST request was made to a local server, and the response indicates an error.\n\n**Key Elements & Details:**\n\n1. **URL Bar:** The URL `http://localhost:8000/run?task=The file /data/dates.txt co...` is visible, showing the endpoint being accessed.\n2. **Request Method:** The request type is "POST".\n3. **Parameters:** There\'s a parameter named "task" with the value "The file /data/dates.txt co...".\n4. **Response Status:** The response indicates a "200 OK" status code, which is usually for successful requests, but the body of the response shows an error.\n5. **Response Body:** The response body is in JSON format and contains an "error" object.\n * **Error Details:** The "error" object has the following:\n * "message": "Invalid value: \'json\'. Supported values are: \'json_object\', \'json_schema\', and \'text\'." indicating the server does not accept json as a value.\n * "type": "invalid_request_error".\n * "param": "response_format_type".\n * "code": "invalid_value".\n6. **Other fields:** The body also includes “monthlyCost”: 0.07081907999999999, "cost": 0, "monthlyRequ" and “Postbot”.\n\n**Overall, the image depicts a POST request to a local server that was successful in terms of the HTTP status code, but failed due to an invalid response format specified in the request.**Screenshot 2025-02-14 1858201945×1484 229 KB
@carlton , @Saransh_Saini , @Jivraj



 Sakshi6479:

{
    "type": "json",
    "json_schema": {
        "name": "taks_runner",
        "schema": {
            "type": "object",
            "required": ["python_dependencies","python_code"],
            "properties": {
                "python_code": {
                    "type": "string",
                    "description": "Python code to perform the task"
                },
                "python_dependencies": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "module": {
                                "type": "string",
                                "description": "Name of the python module"
                            }
                        },
                        "required": ["module"],
                        "additionalProperties": False
                    }
            }
        }
    }
}
}



It clearly says in your error message:
Invalid value: ‘json’
if you look at the “type” key in your response_format variable at the top,
the value cannot be “json”
The error is telling you what the supported values are
‘json_object’, ‘json_schema’, and ‘text’
Since you are defining a schema the correct value should be ‘json_schema’
So therefore you should change
"type": "json"

to
"type": "json_schema"

If you have trouble constructing Json schemas,
either feed it to gpt and have it correct it (along with your error) or please go over Module 3, in particular
https://tds.s-anand.net/#/llm-text-extraction
There is a clear example you can use as a template. We use the same one as a template when we do it in the sessions. That way you will make less errors.
Kind regards
Thanks @21f2000709 for kind words
Tagging Saransh for his efforts to project @Saransh_Saini.
@23f1002382 most active student on this post thanks to you too.
Kind regards



 21f2000709:

@carlton @Jivraj Is there something like peer-review in the project, I found this in the grading document.


Anyone having any idea on this?
No human peer reviews. The peer will be an LLM that has been given the rubrics and fine tuned.
Kind regards



 carlton:

The peer will be an LLM that has been given the rubrics and fine tuned.


May the peer give me good marks 
@carlton Would the scores of project 1 be released tomorrow?
@Yogesh1
We do not have an ETA on Project 1 scores yet. Might have more clarity soon.
Project 1 scores will be available roughly second week of March.
Kind regards
@lakshaygarg654
I know this is a late reply, but its not possible for us to consider changes to your project after the deadline for academic integrity purposes.
If we were to allow it, we would have to allow everyone to make changes to their project as well for it to be fair.
Kind regards
We will soon provide a complete solution for Project 1 because of its valuable learning.
Alright, @Carlton. No problem at all, and thank you for your response.
I just wanted to bring a small limitation in my project’s LLM function to your attention, which I discovered after submission. It may impact one or two tasks. However, no concerns—this has been a great learning experience.
And if possible, just add one line in your Evaluation LLM prompt: “Give loose marking for effort!”—because, you know, creativity deserves some extra credit! 
I am not able to see my project marks please look into the problem
Its not been evaluated yet.
We are still processing them.
Kind regards
So will the solution be based on New MCP style or will they use the same function calling?
Definitely MCP style. Its the most elegant solution and it works beautifully. As soon as evals are done we will showcase it.
@carlton Any ETA on project 1 scores?
I would like to request some bonus like 0.5 bonus mark for each day of delay from the original expected date of receiving score for Project 1 (will be life-saving for us and will be an incentive for team to release scores quickly; or request to TAs if you had better ideas for helping us score more in Project 1)! 
Any Updates? Can we expect it to be out before P2 deadline?
Here\'s a detailed description of the image:\n\n* **Content:** The image shows a list of checks or tests related to a software project, likely a coding project designed to be containerized using Docker and hosted on GitHub.\n* **Checks:** The checks evaluate whether certain criteria are met:\n * "Is Docker image present in dockerhub AND is public": Fails.\n * "Is Github repo present AND public": Passes.\n * "Is Dockerfile present in root of github repo": Passes.\n * "Is MIT license present at root of github repo": Passes.\n* **Status Summary:** \n * "Prerequisites" are marked as "FAIL". \n * "Project 1 Score" is 0.\n* **Visuals:** The text is presented on a light green background. The failed check is circled in red. There\'s also a question mark and three periods ( "?..") next to the third PASS. \n* **Inference:** This likely represents the results of automated testing or quality assurance for a coding project, where certain prerequisites (Docker image on Docker Hub) are not met, resulting in a failing score.\n\n\n\nimage412×167 4.49 KB
Here is a detailed description of the image:\n\n* **Layout**: The image displays a table or list with three columns: "Last Pushed," "Contains," and "Visibility."\n* **Data**: The table contains two rows of data.\n * The first row shows "about 2 hours ago" in the "Last Pushed" column, "IMAGE" in the "Contains" column, and "Public" in the "Visibility" column.\n * The second row shows "2 months ago" in the "Last Pushed" column, "IMAGE" in the "Contains" column, and "Public" in the "Visibility" column.\n* **Visual Style**: The text is white on a dark (likely black) background. \n* **Highlighting**: "Public" is circled in red.image439×204 7.25 KB
This docker image has outlived many students’ hopes, dreams and ambitions of passing this course.
Why is it still not being detected properly on the docker hub?
What in the April Fools is this 

It hasn’t even been morning yet!

PS ( @carlton @Jivraj ): My P1 submission had passed all the basic sanity checks on 15th February. No breaking modifications to the Github repo nor the DockerHub image have been made since then. There’s something bugged in your scripts. Kindly check.
same issue here
i have my git repo public but its saying i don’t have public git repo, also i have dockerfile in my root folder but its also said fail, same for mit license
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a GitHub repository page, specifically for a project named "TDS_Project_1". The page displays the project\'s file structure, recent commits, and information details. \n\n**Key Elements:**\n\n1. **GitHub Interface:** The screenshot clearly shows the standard GitHub interface with top navigation (code, issues, pull requests, actions, projects, wiki, security, insights, settings) and a search bar.\n2. **Repository Name:** The repository\'s name is prominently displayed as "TDS_Project_1".\n3. **File Structure:** The left-hand side lists the files and folders within the repository. Some visible files include:\n * 231000079\n * .gitignore\n * data\n * Dockerfile\n * LICENSE\n * README.md\n * api.py\n * data_prep.py\n * evaluate.py\n * tasks.py\n * train.py\n4. **Recent Commits:** The central part of the screenshot displays a list of recent commits with their dates (e.g. "2 months ago") and commit messages (e.g. "Completed final", "Implemented API for automation agent", "Added Dockerfile").\n5. **Repository Information:** On the right-hand side, there\'s a section labeled "About" which includes details such as: \n * No description, website, or topics provided.\n * Stars, Watching and Forks (0 stars, 1 watching, 0 forks)\n * License: MIT License\n * Languages used (Python)\n6. **Suggested Workflows:** A section with suggested workflows related to building and testing is visible.\n7. **Browser Details:** The screenshot appears to be taken in a web browser (likely Chrome) with numerous tabs open, indicating a busy workspace.\n\n**Color Scheme:**\n\nThe overall color scheme is dark mode, with the GitHub interface primarily using shades of gray and black, with some lighter text for contrast.\n\n**Overall, the image is a snapshot of a developer\'s workflow within a GitHub repository, showing the codebase, commit history, and project information.**image1889×1022 122 KB
yes sir same problem
Here\'s a detailed description of the image:\n\n1. **Display:** The image shows a screenshot of a command-line interface (CLI), likely a terminal or shell window.\n2. **Prompt:** The prompt indicates the user is \'hsent\' on the machine \'DESKTOP-89FBVHS\' using the \'MINGW64\' environment, currently in the \'~/\' directory and then navigating to the \'/hello\\_world\' directory.\n3. **Commands:** A series of commands were entered and executed.\n * `cd hello_world`: This command changes the current directory to \'hello\\_world\'.\n * `ls -l Dockerfile`: This command attempts to list the \'Dockerfile\' with a long listing format.\n * The first attempt at `ls -l Dockerfile` throws an error "command not found".\n * The second attempt works and produces an output indicating a file named "Dockerfile" exists.\n4. **File Information:** The file information shows the following details for the "Dockerfile":\n * **Permissions:** \'-rw-r--r--\' indicating read and write permissions for the owner, and read-only for group and others.\n * **Owner:** \'hsent\' is the owner.\n * **Size:** The file size is 197609 bytes or approximately 193KB.\n * **Last Modified:** Feb 16 18:50 is the last modification timestamp.\n * **Filename:** The filename is "Dockerfile".\n\nIn summary, the image demonstrates a user navigating to a directory, attempting to list a "Dockerfile", encountering an error, and then successfully listing the file along with its details.image885×346 15.3 KB
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a GitHub repository interface. It showcases the file structure, commit history, and basic repository information.\n\n**Key Elements & Details:**\n\n* **Repository Name:** The repository is named "hello\\_world" and is marked as "Public".\n* **User/Organization:** It\'s located under the GitHub username "Harish018S".\n* **Navigation Bar:** A top navigation bar includes options like "Code", "Issues", "Pull Requests", "Actions", "Projects", "Wiki", "Security", "Insights", and "Settings."\n* **Branch Information:** The repository is currently on the "main" branch with 2 branches and 0 tags. A search bar is also present.\n* **File Structure:** The file structure shows three files:\n * LICENSE\n * README.md\n * app.py\n* **Commit History:** A commit history list is visible, showing:\n * "Create app.py" by Harish018S, 2 months ago, with 4 commits.\n * "Create LICENSE", 2 months ago.\n * "Initial commit", 2 months ago.\n* **Bottom Bar:** Displays the README and MIT license.\n\n**Color Scheme:** The interface has a dark theme with predominantly black and grey colors, with white text for clarity.\n\n**Functionality:** The image shows a standard view of a GitHub repository, allowing a user to navigate files, view commit history, and manage the project.image1330×718 54.7 KB
please check and say sir.
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a File Explorer window in a dark mode theme on a Windows operating system. The window is open to a directory named "hello_world" within a user\'s directory.\n\n**Key Elements & Details:**\n\n* **File Explorer Window:** The primary focus is a File Explorer window.\n* **Directory Structure:** The window shows the file structure within the "hello_world" directory.\n* **Files & Folders:** The following files and folders are visible:\n * `.git` (Folder)\n * `app.py` (Python Source File, 1 KB)\n * `Dockerfile` (File, 1 KB)\n * `LICENSE` (File, 2 KB)\n * `README.md` (Markdown Source File, 1 KB)\n * `requirements.txt` (Text Document, 1 KB)\n* **File Details:** The window displays file names, date modified, type, and size.\n* **Navigation Pane:** The left pane shows a typical Windows file system navigation structure (This PC, Downloads, Documents, etc.).\n* **Dark Mode:** The File Explorer and system icons are presented in a dark theme, providing high contrast.\n* **System Tray:** The bottom-right corner displays the system tray with icons indicating various system processes and time.\n* **Search Bar:** A search bar is visible at the top of the window.\n\n**Inference:**\n\nThe directory structure suggests that this is likely a project directory for a Python application, possibly a simple "Hello, World!" program, developed using tools like Docker for containerization.image1918×1078 187 KB
sir it seems like there was a problem when i pushed this files to the repo but i defenitely did correctly. PLease allow me to add docker file alone with your permission. As you can see i haven’t opened the dockerfile since the last date of project 1. Kindly allow this sir. and i have MiT license in my repo but still showing fail . kindly check that also sir.
@carlton @s.anand @Jivraj
yes sir same problem
Here\'s a detailed description of the image:\n\n1. **Display:** The image shows a screenshot of a command-line interface (CLI), likely a terminal or shell window.\n2. **Prompt:** The prompt indicates the user is \'hsent\' on the machine \'DESKTOP-89FBVHS\' using the \'MINGW64\' environment, currently in the \'~/\' directory and then navigating to the \'/hello\\_world\' directory.\n3. **Commands:** A series of commands were entered and executed.\n * `cd hello_world`: This command changes the current directory to \'hello\\_world\'.\n * `ls -l Dockerfile`: This command attempts to list the \'Dockerfile\' with a long listing format.\n * The first attempt at `ls -l Dockerfile` throws an error "command not found".\n * The second attempt works and produces an output indicating a file named "Dockerfile" exists.\n4. **File Information:** The file information shows the following details for the "Dockerfile":\n * **Permissions:** \'-rw-r--r--\' indicating read and write permissions for the owner, and read-only for group and others.\n * **Owner:** \'hsent\' is the owner.\n * **Size:** The file size is 197609 bytes or approximately 193KB.\n * **Last Modified:** Feb 16 18:50 is the last modification timestamp.\n * **Filename:** The filename is "Dockerfile".\n\nIn summary, the image demonstrates a user navigating to a directory, attempting to list a "Dockerfile", encountering an error, and then successfully listing the file along with its details.image885×346 15.3 KB
Here\'s a detailed description of the image:\n\n**Overall Impression:** The image displays a GitHub repository interface. It showcases the file structure, commit history, and basic repository information.\n\n**Key Elements & Details:**\n\n* **Repository Name:** The repository is named "hello\\_world" and is marked as "Public".\n* **User/Organization:** It\'s located under the GitHub username "Harish018S".\n* **Navigation Bar:** A top navigation bar includes options like "Code", "Issues", "Pull Requests", "Actions", "Projects", "Wiki", "Security", "Insights", and "Settings."\n* **Branch Information:** The repository is currently on the "main" branch with 2 branches and 0 tags. A search bar is also present.\n* **File Structure:** The file structure shows three files:\n * LICENSE\n * README.md\n * app.py\n* **Commit History:** A commit history list is visible, showing:\n * "Create app.py" by Harish018S, 2 months ago, with 4 commits.\n * "Create LICENSE", 2 months ago.\n * "Initial commit", 2 months ago.\n* **Bottom Bar:** Displays the README and MIT license.\n\n**Color Scheme:** The interface has a dark theme with predominantly black and grey colors, with white text for clarity.\n\n**Functionality:** The image shows a standard view of a GitHub repository, allowing a user to navigate files, view commit history, and manage the project.image1330×718 54.7 KB
please check and say sir.
Here\'s a detailed description of the image:\n\n**Overall Impression:**\n\nThe image displays a File Explorer window in a dark mode theme on a Windows operating system. The window is open to a directory named "hello_world" within a user\'s directory.\n\n**Key Elements & Details:**\n\n* **File Explorer Window:** The primary focus is a File Explorer window.\n* **Directory Structure:** The window shows the file structure within the "hello_world" directory.\n* **Files & Folders:** The following files and folders are visible:\n * `.git` (Folder)\n * `app.py` (Python Source File, 1 KB)\n * `Dockerfile` (File, 1 KB)\n * `LICENSE` (File, 2 KB)\n * `README.md` (Markdown Source File, 1 KB)\n * `requirements.txt` (Text Document, 1 KB)\n* **File Details:** The window displays file names, date modified, type, and size.\n* **Navigation Pane:** The left pane shows a typical Windows file system navigation structure (This PC, Downloads, Documents, etc.).\n* **Dark Mode:** The File Explorer and system icons are presented in a dark theme, providing high contrast.\n* **System Tray:** The bottom-right corner displays the system tray with icons indicating various system processes and time.\n* **Search Bar:** A search bar is visible at the top of the window.\n\n**Inference:**\n\nThe directory structure suggests that this is likely a project directory for a Python application, possibly a simple "Hello, World!" program, developed using tools like Docker for containerization.image1918×1078 187 KB
sir it seems like there was a problem when i pushed this files to the repo but i defenitely did correctly. PLease allow me to add docker file alone with your permission. As you can see i haven’t opened the dockerfile since the last date of project 1. Kindly allow this sir. and i have MiT license in my repo but still showing fail . kindly check that also sir.
@carlton @s.anand @Jivraj
same issue with me , my repo has both the dockerfile , license and is public. Please look into this . @carlton sir . GitHub - veershah1231/tds_proj_1: Tds project and i have made them 2 months ago and is not a new commit.
Here is a detailed description of the image:\n\n**Overall Impression:**\n\nThe image is a screenshot of a text message conversation. It presents the results of prerequisite checks for "Project 1."\n\n**Content Breakdown:**\n\n* **Header:** The message is from "22t1" at 1:27 am.\n* **Initial Message:** The message starts with "Dear Learner" and explains that Project 1 requires passing prerequisite checks.\n* **Prerequisite List:** A numbered list outlines the five prerequisites:\n 1. GitHub repository existence and public accessibility.\n 2. Presence of a LICENSE file with the MIT license.\n 3. Valid Dockerfile in the repository.\n 4. Publicly accessible Docker image executable via a specific `podman run` command.\n 5. Docker image using the same Dockerfile as the GitHub repository.\n* **Warning:** A statement explains failure to meet these requirements will result in a non-evaluated submission.\n* **Evaluation Results:**\n * "Is Docker image present in dockerhub AND is public: PASS"\n * "Is Github repo present AND public: FAIL"\n * "Is Dockerfile present in root of github repo: FAIL"\n * "Is MIT license present at root of github repo: FAIL"\n* **Final Summary:**\n * "Prerequisites: FAIL"\n * "Project 1 Score: 0"\n\n**Overall Tone:**\n\nThe message has a formal and instructional tone, delivering a status update on the project requirements.10001053861072×1787 256 KB
I came pretty close, but too close(double entendre) to the deadline. Classic ICARUS stuff
0/20 